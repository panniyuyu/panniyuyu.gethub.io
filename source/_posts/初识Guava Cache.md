title: 初识Guava Cache
author: YyWang
date: 2020-05-11 19:37:37
tags: Java
categories: Java
---

#### 背景
随着系统的膨胀，数量越来越大，统计报表的相关SQL会非常慢，代表的SQL是这样，需要统计两张表中不重复的ip，大概是2000w两级，只能两张表分别distinct，最后union的时候再distinct一下，没想到更好的办法，只能加缓存了

* 考虑过使用Redis，这是常规的做法，可是要缓存的数据很少，结构简单，访问量不大通常是管理员来查看统计一下产品的使用情况，使用Redis逻辑复杂，还要考虑缓存击穿，缓存雪崩的情况，还依赖于Redis的可用性，所以决定舍弃该方案，使用Guava Cache来做缓存，并在时间间隔内进行缓存数据的更新
	* Guava Cache虽然提供缓存的过期时间，但是只有在过期之后的一次get才会进行缓存的更新，而且如果获取缓存的时间很长会造成阻塞，这样缓存的意义就没了；
	* 如果设置成异步刷新缓存，可以解决阻塞的问题，但是得到的时上一个时间周期的数据，缓存的实时性不能保证；
	* 最终采用开启定时的线程，在每个时间周期内异步刷新缓存数据，最坏的情况是得到上一个时间周期的数据，但是可以解决上一条中多次点击才会刷新的点，这里还有一个风险点，如果多个服务器在同一时间启动，就会在相同的时间间隔去请求数据库计算数据并更新，可能造成数据库CPU忙碌状态，我的环境是4台服务器，并发的去请求数据库是没问题的，而且通常都是滚动更新，所以不会出现这个问题，综合评估后采用该方案
* 实现
	* 在Spring容器启动完毕的时候（这里有个坑，因为spring容器没有启动完成是不能与数据库建立连接的，所以在spring容器启动过程中就加载缓存是不行的），开启线程统计数据（要查从库避免锁表）
	* 再通过定时任务异步去刷新数据

#### Guava Cache
* 编码过程中那个通常缓存的实现是定义一个全局变量，多个线程都可以访问到，并可以对该变量进行修改；当然需要用到线程安全的数据结构，比如ConcurrentHashMap，但是缓存的更新删除，这些逻辑的自己实现，而我理解的Guava Cache就是封装了这些逻辑并提供出API的一个工具
* 缓存过期的设置方式
* 设置缓存的大小，超过阈值的删除（这里指的是缓存的数量，key的数量）
* 设置缓存的时间，超过时间的删除
	* 不是定时去判断的，而是get的时候会判断是否超时，超时就重新加载，这样如果刷新key的用时很长的话会阻塞；Guava Cache也提供了异步刷新key的方式，这样如果对缓存更新实时性要求高的话，在缓存刷新后重新get才能获得最新的缓存值；或者用一个定时任务异步刷新key
* 设置弱引用，让垃圾收集器来回收
* 显式的删除key
* 可以添加key被删除的监听器

使用了类似jdk1.7中ConcurrentHashMap的Segment的结构，降低锁的粒度提高并发的吞吐量；再通过两次hash找到value的位置

#### 相关知识

* 强引用
	* 通过 new 关键字产生，不会被JVM回收；如果是局部变量，引用保存在线程栈中，方法结束引用被依赖的数量为0，将会被JVM回收掉；如果是全局变量，引用将一直会存在，可以将引用设置为null被JVM回收
* 软引用
	* 内存充足时不会被回收，当内存空间不足会被回收
* 弱引用
	* JVM进行垃圾回收的时候就会被回收掉，如果长时间不进行垃圾回收就会一直存在
* 虚引用
	* 必须与引用队列一起使用，在JVM进行垃圾回收之前，虚引用会被加入到引用队列中
* 引用队列
	*	可以和软引用，弱引用，虚引用联合使用，在JVM进行垃圾回收之前，要被回收的引用会被加入到队列中，用来查看JVM垃圾回收情况 

#### ConcurrentHashMap

* HashMap
* jdk1.7 数组+链表的结构 当有hash冲突的时候链表会很长，查询一个节点效率很低，时间复杂度为O(N)
* jdk1.8 数组+红黑树的结构 链表中节点大于8时会转成红黑树，查询时间复杂度为O(logN)
	* put 
		* 判断是否需要扩容（resize）或者初始化（懒加载）
		* 通过hash找到桶，没有冲突直接放入；
		* 有hash冲突，a.判断是否和第一个Node的key相同，相同则覆盖value；b.判断是否是红黑树，插入value相同key覆盖 c.判断是否需要转红黑树，需要则红黑树插入，否则插入链表末尾，相同key覆盖value，
		* 插入value后判断是否需要扩容
	* get 根据hash值找到桶，从桶中找key对应的value，没有返回null
	* resize 1.8不会进行重新hash，而是看hash值新增的那个bit位是1还是0，0位置不变，1的话位置是原位置+扩容前容量 索引中的位置，由于hash值新增的那个bit为可以认为是随机的，所以可以将原来桶中的链表或者红黑树均匀的拆分成两个链表或者红黑树
* 线程不安全问题
	* 1.7 可能丢失key，还会出现循环链表，当get一个不存在的key出现死循环
	* 1.8 由于table中size变量没有加volatile关键字，多线程++size时可能覆盖以前的记录
	* 线程不安全主要是由于resize方法导致，1.7先rehash转移数据在改数组的引用，而且转移数据后链表会反转多线程并发修改引用会造成循环链表的现象；1.8先改数组的引用再转移数据，并且转移数据不会修改链表的结构，理论上不会造成循环引用，但当多线程并发操作会出现数据丢失的现象
* concurrentHashMap
* 1.7 引入segment的概念，将整个table划分成若干个segment，对segment加锁减小锁的粒度提高吞吐量，get的时候先通过hash找到segment，再找到对应的table中的位置
* 1.8 对Node加锁进一步减小了锁的粒度提高吞吐量，加入多线程扩容的逻辑加速扩容的过程，put操作时发现正在扩容可以帮助扩容，而不是阻塞起来傻等
	* 扩容的逻辑很复杂，整理一下大概的逻辑吧，首先将CAS操作将table扩容，根据原来table的大小将扩容工作拆成多个任务，每个任务最少迁移16个桶，当线程完成扩容任务会继续领取下一个任务进行扩容
	* 多线程领取任务开始扩容，安装索引从大到小的顺序开始，扩容过程中get操作，会get到ForwardNode，转发到新的table中查找value；扩容过程中put操作，如果当前扩容的线程数量小于最大限制的数量就加入扩容的队列中，否则阻塞
	* put 使用synchronized关键字对Node加锁；当Node中的链表大于8，如果当前容量没有超过64先进行扩容，否则才转红黑树；扩容过程中红黑树节点小于6个转链表

