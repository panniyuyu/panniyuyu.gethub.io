<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[iptables是个啥]]></title>
    <url>%2F2021%2F07%2F13%2Fiptables%2F</url>
    <content type="text"><![CDATA[前言iptables 是 Linux 中经常使用的防火墙，还记得之前部署 Tomcat 服务到一个 web 服务器需要配置新的 iptables 规则，开放8080端口，否则无法访问自己的服务，当时满脑子只想完成任务，网上 copy 命令改改改直接敲，甚至直接粗暴的关闭防火墙 🤐 现在 k8s 中的服务发现以及 service mesh 中的流量劫持都使用到了 iptables。so 今天我来还债了 概述iptables其实不是防火墙，真正的防火墙是 netfilter 字面意思就是网络过滤器，可以过滤进出 Linux 网络协议栈的数据包，通过指定各种自定义的规则对进出的数据包进行拦截修改等操作，netfilter 在内核空间处于内核态，而 iptables 是对 netfilter 的配置工具，通过 iptables 可以配置 netfilter 的过滤规则，iptables 在用户空间处于用户态。这么看 iptables 可以理解成”控制面”，netfilter 可以理解成”数据面” 原理netfilter 在数据包进出 Linux 网络协议栈的不同节点上设有 hooks （可以理解为回调函数），当满足了匹配条件就会出发回调进行后面的操作，hooks 主要在 PRE_ROUTING、LOCAL_IN、FORWARD、LOCAL_OUT 和 POST_ROUTING 5个位置上，覆盖了数据包进出 Linux 协议栈的整个生命周期，来整一张图看下这5个位置（图中橙色的圆型就是） PRE_ROUTING 在数据包进入被路由前进入这个节点，这个节点之后会进行路由 LOCAL_IN 在数据包被路由之后，判定目的地址是本机，会进入这个节点，这个节点之后会将数据包传递给应用程序 FORWARD 在数据包被路由之后，判定目的地址不是本机，会进入这个节点，这个节点之后会重新路由，将数据包传递出去 LOCAL_OUT 应用程序发出数据包，还没有路由前，这个节点之后会进行路由 POST_ROUTING 在应用程序，或者 FORWARD 发出的数据包路由之后进入这个节点，这个节点后会将数据包发送出去 iptables 表和链iptables 有”四表五链”来管理数据包的规则和动作 五链，对应上图中五个橙色的 hooks， PREROUTING 对应 PRE_ROUTING hooks INPUT 对应 LOCAL_IN hooks FORWARD 对应 FORWARD hooks OUTPUT 对应 LOCAL_OUT hooks POSTROUTING 对应 POST_ROUTING hooks 四表，将链上的动作按照不同的类别分成了4张表，优先级依次是 Raw-&gt;Mangle-&gt;NAT-&gt;Filter Raw，决定数据包是否被状态跟踪机制处理 Mangle，用来修改数据包的 TOS、TTL 配置 NAT，用来修改数据包的 Ip 地址和端口等信息，做网络地址转换（SNAT、DNAT） Filter，用来过滤数据包，决定数据包的去留，接受或者拒绝 表和链的关系表和链属于多对多的关系，”表中有链，链中有表” PREROUTING INPUT FORWARD OUTPUT POSTROUTING Raw ✅ ✅ ✅ Mangle ✅ ✅ ✅ ✅ ✅ Nat ✅ ✅ ✅ Filter ✅ ✅ ✅ 按链的维度来看，不同的链中包含的表不同，说明每个链的功能不一样，比如 PREROUTING 链只包含 Raw、Mangle、Nat 三个表也就是说只能配置这三个表的动作；按表的维度来看，不同的表中的链不是相同的，也就是说表所配置的动作只能在特定的链上，比如说要做 ip 地址转（即 Nat 表）只可以在 PREROUTING、OUTPUT、POSTROUTING 三 个链上进行；那么数据包在进入网络协议栈的过程就变成了这样（其中 hooks 换成了链） 配置1iptables [-t 表名] COMMAND [要操作的链名] [匹配规则] -j [目标动作] COMMAND -A ：append 新增加一条规则，该规则增加在原本规则的最后面。不显式指定表默认为filter表 -D ：delete 删除一条规则 -I ：insert 插入一条规则，如果没有指定顺序默认插入成第一条规则 -R ：replace 替换一条规则 -L ：list 查看规则 匹配规则 -p ：指定匹配的协议 tcp、upd、icmp、all -s ：指定匹配来源 IP 或者网段 -d ：指定匹配目的 IP 或者网段 –sport ：指定匹配源端口 –dport ：指定匹配目的端口 目标动作 ACCEPT、DROP、REJECT、LOG 这篇文章最后有些例子可以参考一下 参考 https://xie.infoq.cn/article/b0cfe588251d024d9114c84f3 https://cloud.tencent.com/developer/article/1619659 https://www.huaweicloud.com/articles/3abf0cf9743f2f582f45e320452596f6.html]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hexo 迁移到 hugo 方案-续]]></title>
    <url>%2F2021%2F05%2F13%2Fhexo%E8%BF%81%E7%A7%BB%E5%88%B0hugo%E6%96%B9%E6%A1%88-%E7%BB%AD%2F</url>
    <content type="text"><![CDATA[前面一篇将博客从 hexo 迁移到 hugo 在本地已经跑通了，这篇将跑通的环境打包到云上。 1.将文件上传到 git 仓库这一步可以说是先做个备份，有几个坑点需要注意，我的地址是 https://github.com/panniyuyu/blog-hugo.git。还有一个原因就是如果没有 git执行 hugo server 命令会报错 ERROR 2021/03/05 06:10:33 Failed to read Git log: fatal: not a git repository (or any of the parent directories): .git 我使用了 LoveIt 的主题，在 /themes 目录下，需要在 git 仓库中关联子模块，不然的话 git push 不会将主题相关的文件 push 上去的 由于要关联子项目，为了不受后续主题仓库的影响，最好先 fork 到自己仓库中一份，子模块引用自己仓库的就可以了 2.创建 DockerfileDockerfile 也很简单了，把大象装冰箱只需要3步，1.找一个 golang 的镜像 2.安装 hugo 3.git clone 第一步上传的文件运行起来 123456789101112131415161718FROM golang:1.16WORKDIR /go/src/# install hugoRUN git clone https://github.com/gohugoio/hugo.git --progress --verbose &amp;&amp; \ cd hugo &amp;&amp; \ go install# init blogWORKDIR /usr/local/blog# --recursive 包含子模块一起cloneRUN git clone --recursive https://github.com/panniyuyu/blog-hugo.git --progress --verboseWORKDIR /usr/local/blog/blog-hugoCMD sh run.sh 附上 run.sh 12#!/bin/shhugo server -p 1313 3.上云这里我使用的阿里云镜像服务，打好的镜像上传上去再到云服务器上拉下来，然后再把第一步中上传到 git 的仓库拉下来做文件映射，最后运行容器 1docker run -di -p 1313:1313 -v /usr/local/blog/blog-hugo:/usr/local/blog/blog-hugo --name=&apos;blog-hugo&apos; blog-hugo:2021-05-10 踩坑坑1 mac 上宿主机和容器见网络不通上述步骤完成后，首先再上云之前所有步骤都在本地搞，启动容器之后 curl ${dockerIp}:${port} 是没有反应的，随后进入容器 curl localhost:${port}这是没问题的有HTML页面，所以问题就出在宿主机和容器网络不通，退出容器在 mac 上 ping 容器的 ip 果然是不通的。mac 端的 docker desktop 默认是不使用网桥的，所以默认与容器间网络是不通的 这里 有详细的说明，解决方法自行搜索，我比较懒没有解决，手动狗头 坑2 hugo server 参数踩到第一个坑以后，跳过本地部署的阶段，直接上云，在运行容器后 ping 容器 ip 网络是通的，即验证了坑1的问题所在，接着进行 curl ${dockerIp}:${port} 后还是没有响应，进入容器 curl 是正常的，这个坑浪费了很多的时间，其实很简单，就是 hugo server 命令的一个参数指定 hugo 绑定的主机，即默认只有本地才可以访问，命令如下 1--bind string interface to which the server will bind (default &quot;127.0.0.1&quot;) 坑3 nginx上面两个坑填完后，之前 hexo 的博客有 Nginx 容器做转发，就计划原有的域名加一个 /hugo 的 path 就可以两个容器都可以用了，还能省下买域名的钱，理想很丰满，也确实达到了 想要的效果，但是，但是，但是，当我看某一篇文章时，url 是会变的呀，且不说两个容器中文章的 url 格式不一样，就算文章的 url配置成一样的，可 Nginx 不知道当前请求是来自 hugo 还是 hexo 怎么转发？或者可以配置公网 ip host 和域名区分，又或者按照有没有 www 前缀来进行转发，这也太挫了，还是老实买个域名通过主机名路由吧。 最后这三个坑都填上后 hugo 博客就可以用了，再发新的文章就可以直接上传到 git 上（文章在 content/posts/ 目录，图片在 static/images/ 目录），再在服务器上 git pull 然后 hugo 就热更新了，比 hexo 还需要 docker restart 一下简直太爽了。再展望一下，后续打算 hugo 和 hexo 一起维护，再写文章就先不写头信息，因为两者头的格式不一样，可以新建一个仓库只写 md 文件，push 到仓库后触发一个 pipeline 将 md 文件添加不同格式的头信息，分别更新到各个仓库中（这就是 ci），再触发一个 webhook 访问服务器上一个 http 服务，将更新的 hugo 和 hexo 的 文章下载下来，hexo容器需要重启（这步是cd），这样 cicd 都有了，就做到了全自动，哈哈，后面有时间]]></content>
      <categories>
        <category>hugo</category>
      </categories>
      <tags>
        <tag>hugo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[没有实践就不算入门 Istio]]></title>
    <url>%2F2021%2F05%2F08%2FIstio%E6%B5%81%E9%87%8F%E7%AE%A1%E7%90%86%E7%AE%80%E5%8D%95%E5%AE%9E%E8%B7%B5%2F</url>
    <content type="text"><![CDATA[简述Istio 是如何使用网关进行流量控制的呢？经过两天的实验和研究，有了一个简单的认识，记录一下子 Istio 作为服务网格的控制面通过一些自定义的 CR，通过对这些 CR 的配置，并对这些 CR 和 k8s 中部分资源 listAndWatch 生成配置并下发（xds协议）到数据面，数据面接收到这些配置实时调整对流量的处理逻辑，这是大致的流程。在原生的 k8s 中，Service 可以通过筛选 label 将应用的多个实例暴露出去提供服务，Service 还可以服务发现和负载均衡，在此基础上 Istio 定义了一些 CR 来扩展 Service 的功能，本文就 Istio 针对 Http 协议的流量 控制进行实践，对 Istio 有一个简单的认识。 Demo 结构 从右往左看 通常使用 Deployment 来部署应用的多个实例即业务 Pod，对应图中 business Pod 创建 Service 将业务 Pod 暴露提供服务，同时可以服务发现和负载均衡 到这只是使用了 k8s 中的 CR，用户可以通过访问 Service 的 ClusterIp 和端口来访问服务，但是没有更细致的流量控制的功能，下面就开始使用 Istio 需要创建 VirtualService 和 DestinationRule 来配置流量控制规则 VirtualService 可以配置不同维度的路由规则将流量传递给指定的 Service DestinationRule 可以配置路由规则的不同子集(理解为 k8s Service 中 Endpoint 分组)，以及子集的复制均衡策略，还能配置异常检测 还可以创建网关来进行流量控制，Istio 默认使用 Envoy 做网关，同样使用 Deployment 部署多个实例，（图中 gateway Pod）创建 Service（图中gateway service）提供服务，Gateway 是 Istio 的 CR 通过筛选 label 关联到创建好的网关，Gateway 规定能够通过网关的流量，并绑定 VisualService和 DestinationRule 的规则 Istio 通过 ListAndWatch 这些 CR 感知到它们的变化通知给数据面（sidecar 或者 Gateway） 实践准备工作 首先用 Deployment 部署一个 HttpServer 的 Demo，有两个实例 123NAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATEShttp-sample.default-24tqt 1/1 Running 2 8d 10.0.76.95 op-arsenaldevk8s-03 &lt;none&gt; 1/1http-sample.default-crkvp 1/1 Running 4 8d 10.0.76.102 op-arsenaldevk8s-07 &lt;none&gt; 1/1 给 Demo 创建 Service 暴露服务， 123NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGEhttp-sample--default ClusterIP 10.0.75.60 &lt;none&gt; 8386/TCP 7d19h 创建 Gateway CR 用来接收所有 host 的请求 123456789101112131415apiVersion: networking.istio.io/v1alpha3kind: Gatewaymetadata: name: httpsample-gatewayspec: selector: istio: ingressgateway # use Istio default gateway implementation 使用 envoy servers: - port: number: 80 name: http protocol: HTTP hosts: - &quot;*&quot; // 被网关管理 host，这里配置了所有； Istio 默认在 istio-system 下创建了网关的 Deployment 和 Service，同样 Service 通过筛选 label 关联 Deployment 的实例 12345678kubectl get deployment -n istio-systemNAME READY UP-TO-DATE AVAILABLE AGEistio-ingressgateway 2/2 2 2 28dubectl get svc -n istio-systemNAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGEistio-ingressgateway LoadBalancer 10.0.75.173 &lt;pending&gt; 15021:31214/TCP,80:30611/TCP,443:32529/TCP,15012:32583/TCP,15443:31725/TCP 28d 创建 VirtualService 绑定网关 12345678apiVersion: networking.istio.io/v1beta1kind: VirtualServicespec: gateways: - httpsample-gateway // 绑定网关，被绑定的网关使用该 VirtualService 配置的规则进行流量控制 hosts: - &apos;*&apos; // 针对某个 host 的应用路由规则，必须包含在被绑定的网关 hosts 范围中，配置成一样的就可以 创建 DestinationRule 划分两个子集不同版本的子集， 1234567891011121314apiVersion: networking.istio.io/v1beta1kind: DestinationRulespec: host: http-sample--default subsets: // 通过筛选 label 划分不同的子集，label 是在业务 Pod 的 Service 中 Label Selector 基础上增加版本的标签 - labels: app: http-sample // Service 中筛选标签的条件 version: v1 // 新增的筛选标签的条件 name: v1 - labels: app: http-sample version: v2 name: v2 最后，给 Demo 的两个实例分别打上 version 标签，本文规定10.0.76.95的 IP 是v1，10.0.76.102的 IP 是v2，准备工作完成 路由配置12345678910111213141516apiVersion: networking.istio.io/v1beta1kind: VirtualServicespec: gateways: - httpsample-gateway hosts: - &apos;*&apos; http: - route: - destination: host: http-sample--default // 路由的目标 Service，流量会被路由到的 Service port: number: 8386 // 路由的目标 Service 端口 subset: v2 // 路由的目标子集，DestinationRule 中定义的子集 weight: 100 // 流量分配权重 验证 12345// 访问网关的 Servicecurl http://10.0.75.173// Demo 程序返回时间，host，IP 信息可以看到流量被路由到了 v2 子集上hello!Sat, 08 May 2021 05:58:10 UTC,host:http-sample.default-crkvp,ip:10.0.76.102 匹配规则1234567891011121314151617181920212223242526272829303132333435363738apiVersion: networking.istio.io/v1beta1kind: VirtualServicespec: gateways: - httpsample-gateway hosts: - &apos;*&apos; http: - match: - headers: // 匹配请求头 还支持前缀匹配(prefix)和正则匹配(regex) userpin: exact: jason - uri: // 匹配 uri 还支持精确匹配(exact)和正则匹配(regex) prefix: /tov1 route: // match 的请求路由规则 - destination: host: http-sample--default port: number: 8386 subset: v1 - match: - headers: // 匹配请求头 还支持前缀匹配(prefix)和正则匹配(regex) userpin: exact: yywang // 这里如果是 jason 会优先匹配到上条规则 uri: prefix: /tov2 route: - destination: host: http-sample--default port: number: 8386 subset: v2 - route: // 默认路由规则，即上面没有 match 到会直接路由到 http-sample--default 的 Service (Demo 暴露的 Service)上 - destination: host: http-sample--default port: number: 8386 match 中的匹配规则，在不同的数组下是或的关系如v1的配置，相同数组下是且的黄兴如v2的配置 验证 1234567891011121314151617181920// 路径匹配curl http://10.0.75.173/tov1hello!Sat, 08 May 2021 06:15:25 UTC,host:http-sample.default-24tqt,ip:10.0.76.95// header 匹配curl -H &quot;userpin:jason&quot; http://10.0.75.173/hello!Sat, 08 May 2021 06:15:05 UTC,host:http-sample.default-24tqt,ip:10.0.76.95// 优先匹配v1curl -H &apos;userpin:jason&apos; http://10.0.75.173/tov2hello!Sat, 08 May 2021 06:19:48 UTC,host:http-sample.default-24tqt,ip:10.0.76.95// v2是且的关系，最后走了默认路由两个实例随机访问curl http://10.0.75.173/tov2hello!Sat, 08 May 2021 06:19:08 UTC,host:http-sample.default-24tqt,ip:10.0.76.95curl http://10.0.75.173/tov2hello!Sat, 08 May 2021 06:19:09 UTC,host:http-sample.default-24tqt,ip:10.0.76.95curl http://10.0.75.173/tov2hello!Sat, 08 May 2021 06:19:09 UTC,host:http-sample.default-crkvp,ip:10.0.76.102// 匹配v2curl -H &apos;userpin:yywang&apos; http://10.0.75.173/tov2hello!Sat, 08 May 2021 06:26:17 UTC,host:http-sample.default-crkvp,ip:10.0.76.102 流量镜像123456789101112131415161718192021222324252627282930313233343536apiVersion: networking.istio.io/v1beta1kind: VirtualServicespec: gateways: - httpsample-gateway hosts: - &apos;*&apos; http: - match: - uri: prefix: /tov1 mirror: host: http-sample--default // 流量镜像的目标 Service subset: v2 // 流量镜像的目标 子集 mirror_percent: 100 // 流量镜像的比例 route: - destination: host: http-sample--default port: number: 8386 subset: v1 - match: uri: prefix: /tov2 route: - destination: host: http-sample--default port: number: 8386 subset: v2 - route: - destination: host: http-sample--default port: number: 8386 验证，curl http://10.0.75.173/tov1 在v2的 Pod 上查看日志 CORS 策略12345678910111213141516171819202122apiVersion: networking.istio.io/v1beta1kind: VirtualServicespec: gateways: - httpsample-gateway hosts: - &apos;*&apos; http: - route: - destination: host: http-sample--default port: number: 8386 subset: v2 weight: 100 corsPolicy: allowOrigin: - new.com // 允许浏览器跨域访问的地址 allowMethods: - GET // 允许浏览器跨域访问的请求方法 maxAge: &quot;2m&quot; // 跨域请求缓存的时间 目前没有遇到这个策略的场景，就没有做验证，据了解 CORS 会给原请求添加头信息，可以查看请求头验证，参考 重定向123456789101112131415161718192021222324apiVersion: networking.istio.io/v1beta1kind: VirtualServicespec: gateways: - httpsample-gateway hosts: - &apos;*&apos; http: - match: - uri: prefix: /tov1 redirect: uri: /tov2 // 重定向的路径 authority: 172.16.26.126:8386 // 重定向的主机，不配置就是当前主机，这个是我本地的地址和端口 - match: uri: prefix: /tov2 route: - destination: host: http-sample--default port: number: 8386 subset: v2 验证：curl http://10.0.75.173/tov1 查看本地日志发现被路由到了本地 重写类似于请求转发，浏览器 URL 不会变，由服务器转发新地址 123456789101112131415161718192021222324252627282930apiVersion: networking.istio.io/v1beta1kind: VirtualServicespec: gateways: - httpsample-gateway hosts: - &apos;*&apos; http: - match: - uri: prefix: /tov1 rewrite: uri: /print // 重写的路径 authority: 172.16.26.126:8386 // 重写的主机 route: - destination: host: http-sample--default port: number: 8386 subset: v1 - match: uri: prefix: /tov2 route: - destination: host: http-sample--default port: number: 8386 subset: v2 验证方式同重定向一样，有一点区别的是重写下面还可以配置路由，如果没有配置重写的主机名默认会路由到下面的子集，上面的例子如果没有配置重写的主机会路由到v1的 /print 的 path 上 重试123456789101112131415161718apiVersion: networking.istio.io/v1beta1kind: VirtualServicespec: gateways: - httpsample-gateway hosts: - &apos;*&apos; http: - route: - destination: host: http-sample--default port: number: 8386 retries: attempts: 3 // 重试次数 perTryTimeout: 2s // 重试超时等待时间 retryOn: 5xx,connect-failure // 重试条件 5xx 状态码或者连接失败 验证，Demo 中有一个返回500错误的方法，curl http://10.0.75.173/error500 打开两个 Pod 的实例观察请求的日志，加上重试一共请求4次 故障注入延迟故障12345678910111213141516171819apiVersion: networking.istio.io/v1beta1kind: VirtualServicespec: gateways: - httpsample-gateway hosts: - &apos;*&apos; http: - fault: delay: // 注入延迟故障 percentage: value: 10 // 注入百分比 fixedDelay: 5s // 延迟时间 - route: - destination: host: http-sample--default port: number: 8386 错误故障12345678910111213141516171819apiVersion: networking.istio.io/v1beta1kind: VirtualServicespec: gateways: - httpsample-gateway hosts: - &apos;*&apos; http: - fault: abort: // 错误故障 percentage: value: 10 // 注入百分比 httpStatus: 500 // 响应状态码 - route: - destination: host: http-sample--default port: number: 8386 curl http://10.0.75.173 即可验证 负载均衡Istio 除了 Service 本身带有的负载均衡，在 DestinationRule 中可以配置子集的负载均衡，支持更多算法 12345678910111213apiVersion: networking.istio.io/v1beta1kind: DestinationRulespec: host: http-sample--default subsets: - labels: version: v1 app: http-sample name: v1 trafficPolicy: lodaBalancer: // 负载均衡配置 simple: ROUND_ROBIN // 轮询负载均衡算法，还支持随机算法(RANDOM)，最少连接(LEAST_CONN)，直接转发(PASSTHROUTE) 异常检测 - 熔断限流12345678910111213141516171819202122232425apiVersion: networking.istio.io/v1beta1kind: DestinationRulespec: host: http-sample--default subsets: - labels: version: v1 app: http-sample name: v1 - labels: version: v2 app: http-sample name: v2 trafficPolicy: connectionPool: http: http1MaxPendingRequests: 1 // 最大请求等待数 maxRequestsPerConnection: 1 // 每个连接最大请求数 tcp: macConnections: 1 // 最大连接数 outlierDetection: baseEjectionTime: 100s // 基础熔断时间，实际时间是 = 基础熔断时间 x 熔断次数 consecutiveErrors: 1 // 触发熔断的连续错误次数 maxEjectionPercent: 100 // 熔断实例的比例，100%即为所有实例都可以同时熔断 验证，这里通过 fortio 验证了限流，再高于5个连接并发的情况下会有部分请求失败被限流，熔断还还不知道怎么验证，感觉应该没问题后面验证了再补充上 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051fortio load -c 5 -qps 0 -n 100 -loglevel Warning http://10.0.75.17317:45:28 I logger.go:127&gt; Log level is now 3 Warning (was 2 Info)Fortio 1.14.1 running at 0 queries per second, 8-&gt;8 procs, for 100 calls: http://10.0.75.173Starting at max qps with 5 thread(s) [gomax 8] for exactly 100 calls (20 per thread + 0)17:45:28 W http_client.go:781&gt; Parsed non ok code 503 (HTTP/1.1 503)17:45:28 W http_client.go:781&gt; Parsed non ok code 503 (HTTP/1.1 503)17:45:28 W http_client.go:781&gt; Parsed non ok code 503 (HTTP/1.1 503)17:45:28 W http_client.go:781&gt; Parsed non ok code 503 (HTTP/1.1 503)17:45:28 W http_client.go:781&gt; Parsed non ok code 503 (HTTP/1.1 503)17:45:28 W http_client.go:781&gt; Parsed non ok code 503 (HTTP/1.1 503)17:45:28 W http_client.go:781&gt; Parsed non ok code 503 (HTTP/1.1 503)17:45:28 W http_client.go:781&gt; Parsed non ok code 503 (HTTP/1.1 503)17:45:28 W http_client.go:781&gt; Parsed non ok code 503 (HTTP/1.1 503)17:45:28 W http_client.go:781&gt; Parsed non ok code 503 (HTTP/1.1 503)17:45:28 W http_client.go:781&gt; Parsed non ok code 503 (HTTP/1.1 503)17:45:29 W http_client.go:781&gt; Parsed non ok code 503 (HTTP/1.1 503)17:45:29 W http_client.go:781&gt; Parsed non ok code 503 (HTTP/1.1 503)17:45:29 W http_client.go:781&gt; Parsed non ok code 503 (HTTP/1.1 503)17:45:29 W http_client.go:781&gt; Parsed non ok code 503 (HTTP/1.1 503)17:45:29 W http_client.go:781&gt; Parsed non ok code 503 (HTTP/1.1 503)17:45:29 W http_client.go:781&gt; Parsed non ok code 503 (HTTP/1.1 503)17:45:29 W http_client.go:781&gt; Parsed non ok code 503 (HTTP/1.1 503)Ended after 181.75592ms : 100 calls. qps=550.19Aggregated Function Time : count 100 avg 0.0084987707 +/- 0.003829 min 0.003318402 max 0.01871654 sum 0.849877069# range, mid point, percentile, count&gt;= 0.0033184 &lt;= 0.004 , 0.0036592 , 8.00, 8&gt; 0.004 &lt;= 0.005 , 0.0045 , 15.00, 7&gt; 0.005 &lt;= 0.006 , 0.0055 , 26.00, 11&gt; 0.006 &lt;= 0.007 , 0.0065 , 44.00, 18&gt; 0.007 &lt;= 0.008 , 0.0075 , 58.00, 14&gt; 0.008 &lt;= 0.009 , 0.0085 , 64.00, 6&gt; 0.009 &lt;= 0.01 , 0.0095 , 73.00, 9&gt; 0.01 &lt;= 0.011 , 0.0105 , 75.00, 2&gt; 0.011 &lt;= 0.012 , 0.0115 , 80.00, 5&gt; 0.012 &lt;= 0.014 , 0.013 , 88.00, 8&gt; 0.014 &lt;= 0.016 , 0.015 , 94.00, 6&gt; 0.016 &lt;= 0.018 , 0.017 , 98.00, 4&gt; 0.018 &lt;= 0.0187165 , 0.0183583 , 100.00, 2# target 50% 0.00742857# target 75% 0.011# target 90% 0.0146667# target 99% 0.0183583# target 99.9% 0.0186807Sockets used: 23 (for perfect keepalive, would be 5)Jitter: falseCode 200 : 82 (82.0 %)Code 503 : 18 (18.0 %)Response Header Sizes : count 100 avg 141.04 +/- 66.08 min 0 max 172 sum 14104Response Body/Total Sizes : count 100 avg 252.32 +/- 2.533 min 247 max 254 sum 25232All done 100 calls (plus 0 warmup) 8.499 ms avg, 550.2 qps]]></content>
      <tags>
        <tag>Istio</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hexo 迁移到 hugo 方案]]></title>
    <url>%2F2021%2F03%2F04%2Fhexo%E8%BF%81%E7%A7%BB%E5%88%B0hugo%E6%96%B9%E6%A1%88%2F</url>
    <content type="text"><![CDATA[云原生第一步首先要拥抱 go 语言，go 语言第一步首先从迁移博客开始，hugo 是用 golang 实现的静态博客生成工具，给我最大的吸引力是生成静态资源的速度很快，并且是热更新，就是说我修改了文章后不需要重启 hugo 就可以更新博客的状态，这简直太爽了 安装12345678910111213141516# 安装brew install hugo#Error: hugo: no bottle available!You can try to install from source with: brew install --build-from-source hugoPlease note building from source is unsupported. You will encounter buildfailures with some formulae. If you experience any issues please create pullrequests instead of asking for help on Homebrew&apos;s GitHub, Twitter or any otherofficial channels.# 按照提示重新安装brew install --build-from-source hugo# 验证hugo version # 成功Hugo Static Site Generator v0.80.0/extended darwin/amd64 BuildDate: unknown 创建一个网站1hugo new site blog-hugo 会在hugo目录下创建一个 blog-hugo 的文件夹，目录结构为 123456789.├── archetypes│ └── default.md├── config.toml├── content├── data├── layouts├── static└── themes 添加主题我选用LoveIt的主题 123456789cd blog-hugo/themes/git clone https://github.com/dillonzq/LoveIt.git# 复制 exampleSite 中的文件到 blog-hugo 目录下cp -rf LoveIt/exampleSite/ ../../# 修改主题位置vim config.toml# 修改 themesDir = &quot;themes/&quot;# 启动 必须要在创建的 Site 目录下，否有要 -s=xxx 指定目录hugo server 踩坑! 如果提示保持 too many request from balabala … 需要在config.toml中添加配置 ignoreErrors = [“error-remote-getjson”] 迁移博客 头信息修改，hexo中的头信息我是这样写的 123456title: 2020 又是起起落落落落的一年 author: YyWang tags: 生活杂谈 categories: 生活杂谈date: 2021-02-08 17:57:12--- hugo 中头信息为这样 1234567891011---title: 2020 又是起起落落落落的一年author: YyWangauthorLink: http://www.yywang.top #新增date: 2021-02-08T17:57:12+08:00 #修改格式lastmod: 2021-02-08T17:57:12+08:00 #新增draft: false #新增tags: [&quot;生活杂谈&quot;] #修改格式categories: [&quot;生活杂谈&quot;] #修改格式featuredImagePreview: #新增--- 当然是写代码修改啦，因为hexo中的文章都没以 — 开头，所以我就统一这个格式处理了，(刚学golang写的很糙😬)，处理代码如下 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128package mainimport ( &quot;bufio&quot; &quot;fmt&quot; &quot;io&quot; &quot;os&quot; &quot;path/filepath&quot; &quot;strings&quot; &quot;time&quot;)func main()&#123; // 获取文件夹中所有文件 pathPrefix := &quot;$&#123;pathPrefix&#125;&quot; files := getAllFiles(pathPrefix) for _,f := range files &#123; // 先读文件，在写文件 err := writeFile(f, readFile(f)) if err != nil &#123; fmt.Printf(&quot;write error %v&quot;, err) &#125; &#125;&#125;func readFile(filepath string) []byte&#123; file, _ := os.OpenFile(filepath, os.O_RDONLY, 0644) defer file.Close() reader := bufio.NewReader(file) buffer := make([]byte, 0) var title, author, tags, categories, date string appendFlag := false for &#123; line, _, err := reader.ReadLine() if err != nil &#123; if err == io.EOF &#123; appendPre := make([]byte, 0) appendPre = append(appendPre, &quot;---\n&quot;...) appendPre = append(appendPre, &quot;title: &quot; + title +&quot;\n&quot;...) appendPre = append(appendPre, &quot;author: &quot; + author +&quot;\n&quot;...) appendPre = append(appendPre, &quot;authorLink: http://www.yywang.top\n&quot;...) appendPre = append(appendPre, &quot;date: &quot; + date +&quot;\n&quot;...) appendPre = append(appendPre, &quot;lastmod: &quot; + date +&quot;\n&quot;...) appendPre = append(appendPre, &quot;draft: false\n&quot;...) appendPre = append(appendPre, &quot;tags: [\&quot;&quot;+tags+&quot;\&quot;]\n&quot;...) appendPre = append(appendPre, &quot;categories: [\&quot;&quot;+categories+&quot;\&quot;]\n&quot;...) appendPre = append(appendPre, &quot;featuredImagePreview: \n&quot;...) appendPre = append(appendPre, &quot;---\n&quot;...) return append(appendPre, buffer...) &#125; &#125; lineStr := string(line[:]) if strings.EqualFold(lineStr, &quot;---&quot;) &#123; appendFlag = true continue &#125; if appendFlag &#123; // copy buffer = append(buffer, line...) buffer = append(buffer, &quot;\n&quot;...) &#125; else &#123; i := strings.Index(lineStr, &quot;:&quot;) if i &gt; 0 &#123; k := lineStr[0:i] v := strings.TrimSpace(lineStr[i+1:]) switch k &#123; case &quot;title&quot;: title = v case &quot;author&quot;: author = v case &quot;tags&quot;: tags = v case &quot;categories&quot;: categories = v case &quot;date&quot;: date = transDataFormat(v, &quot;2006-01-02 15:04:05&quot;, &quot;2006-01-02T15:04:05+08:00&quot;) default: fmt.Println(&quot;error switch &quot; + k) &#125; &#125; else &#123; fmt.Println(&quot;split error &quot; + lineStr) &#125; &#125; &#125;&#125;func getAllFiles(path string) []string &#123; files := make([]string, 0) err := filepath.Walk(path, func(path string, f os.FileInfo, err error) error&#123; if f.IsDir() &#123; return nil &#125; files = append(files, path) return nil &#125;) if err != nil &#123; fmt.Printf(&quot;walk file path err info is %v&quot;, err) &#125; return files&#125;func transDataFormat(timeStr string, oldFormat string, newFormat string) string &#123; date, _ := time.Parse(oldFormat, timeStr) return date.Format(newFormat)&#125;func writeFile(filePath string, content []byte) error &#123; f, err := os.OpenFile(filePath, os.O_WRONLY|os.O_TRUNC, 0600) defer f.Close() if err != nil &#123; return err &#125; writer := bufio.NewWriter(f) _, err = writer.Write(content) if err != nil &#123; return err &#125; err = writer.Flush() if err != nil &#123; fmt.Printf(&quot;flush error %v&quot;, err) &#125; return nil&#125; 然后将新修改的文件移动到 blog-hugo/content/posts/ 目录下 将文章中引用的图片移动到 blog-hugo/assets/images/ 目录下 如果在文章中还引用过其他文章，url会失效，手动修改下或者参考这里，查看文件链接处理 到这里博客基本上迁移完毕了，附一个初步的效果图，后面还需进一步美化和优化，等上线了再切负载替换hexo TODO 打包docker镜像，以docker的方式部署，nginx切换负载 备份hugo博客的方案 参考这里做增强 换一套头像，大图小图啥的，参考主题中exampleSite里的post介绍，这个网站生成套图 更换评论系统插件waline]]></content>
      <categories>
        <category>hugo</category>
      </categories>
      <tags>
        <tag>hugo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[2020 又是起起落落落落的一年]]></title>
    <url>%2F2021%2F02%2F08%2F2020%20%E5%8F%88%E6%98%AF%E8%B5%B7%E8%B5%B7%E8%90%BD%E8%90%BD%E8%90%BD%E8%90%BD%E7%9A%84%E4%B8%80%E5%B9%B4%2F</url>
    <content type="text"><![CDATA[2021年已经过去了39天，上一年的总结赶紧补上，先盘点下之前立过的Flag，然后写一下自己的心路历程吧 Flag还记得19年写总结的时候立下了的Flag，一一盘点一下子 每月平均两篇博客的更新 截止到最后一篇文章11月17日一共有20篇，离24篇还差点意思，完成率83%吧，怎么硕呢~ 看数据的话可就是没完成，但是，其中有4个月的时间因为一些事情没有写文章更新，可以算是及格吧 博客填坑 当时计划要学习：spring/spring boot、WAL、设计模式、netty这些，并写文章出来，学习是学了文章没写，没啥好说的妥妥没完成 部门业务深入 Flag是部门业务吃透，这里话太满了我撤回，吃透算不上应该说得上是深入了解，本来计划是每天看一点点不紧不慢的节奏，后来有人离职我代替他值班，驱动我不得不加快学习速度，感觉已经完全适应工作状态了，另外下一代微服务也学习了，本来计划了解一些能吹牛逼就行，后来发现这个还挺有意思的也就多看了看，意外收获，哈哈，这个是超额完成 一次5天以上的旅行 因为疫情上半年的假期基本都是在北京度过，国庆的时候去上海玩了4天，心疼机票钱选择国庆后出门🤣，这项也算完成了吧 综合来看，Flag完成情况可以说是及格吧，毕竟计划往往是赶不上变化的，心里记着目标努力去完成就好，Flag也设定的稍微大一些，反正最后肯定完不成，结果肯定会比低预期的Flag要好很多~ 小算盘 从参加工作以来，工作内容一直都是后台系统的优化和维护，申请不到前端资源甚至连前端页面也写，更像一个全栈。这个工作内容和读研时期一模一样，而且工作氛围有些封闭感觉我更像外包一样，道理我都懂，这些活总要有人来做，我是新人当然是我来做，等再有新人来我不就解放了嘛，就这样我打起了自己的小算盘😬，可后面要做些什么我不知道，我就看身边的大佬搞什么就想办法往那边去靠，厚着脸皮跟着大佬去做一个operator的项目，也就从这开始我接触到了k8s和云原生发现这真是一个神奇的东西 打杂的？ 就在快有新人来之前，我的计划也按部就班的来，找老板提出我的想法去做云原生的项目或者SDK，不料被驳回了，理由是这两个项目都不缺人，然后安排我做另外一个项目，希望破灭，在新的项目里倒是不用写前端了，可还是一个 API Boy 在我看来工作内容都是一样的，没有好的机会就做吧还能咋的。后来，晋升答辩T2-&gt;T3，以往都不需要答辩今年不知怎么了，我汇报了一年的工作，台下一个评委说感觉你像打杂的，结果没过，心想我一个T2不打杂干什么，让我做T10的活吗？ 打杂的！ 我为自己感到不公，便开始找新的机会，期间边看机会边准备也就空出3个月没有更新文章，原因在这🤣，起初还是按照基础架构这个方向去找，毕竟做了有1年的时间想在这个方向多深入一些，刚开始还是一直碰壁，简历不过的，理解深度不够的，自己暴露的问题有很多，因为我说想做一些更有挑战性的工作，被灵魂拷问你想做什么的时候，我脑子一片空白，只是有想法但做什么却不知道，这算什么，投递简历很多都是不过的，简历过了面试的问题也答不好，我这一年到底干了什么？结论：我这一年光打杂了，就是一个打杂的！ 自省 自我反省一下，自己确实是个打杂的，工作内容没有亮点，首先我要明确自己想做什么，业务还是基础架构？业务接触的技术广，机会多，好的业务往往绩效也好，相应的压力会大一些；基础架构方向有技术的深度，绩效往往一般；相比之下我更喜欢基础架构多一些，更喜欢偏研究类型的工作，经过面试看下来基础架构往往需求工作经验丰富的人，我打杂一年希望渺茫；我选择先找业务方向工作一段时间再入坑基础架构，这样希望大些，随后我投递了业务方向的岗位，最终拿到了美团的offer，当时已经进入第4季度加上我年限少涨幅也没有到预期，决定年底再看，这个阶段我明确了我想要什么，有了短期的规划 前行 有了规划开始按部就班的走，工作之余每天抽出时间刷题、学习给自己充电，计划是过完年再开始找机会，到了12月几乎每天都有5个猎头或者hr要简历，感觉需求量很大，随之调整计划，填鸭式的学习，打算在年前把这事搞定，这一个月我也没更新文章😬，从元旦后开始投递简历，有了充分的准备，这次结果还不错，收到了3家offer，其他的5家也都通过3面，还有一家是我主动放弃的，这结果我还是很欣慰的，其中拒了百度（感觉没有诚意），拒了阿里（纠结了很久），最终选择一个规模不大的独角兽，做云原生基础架构（不忘初心吧） 云原生 GO GO GO 自己也没想到会有选offer的一天，本来幻想着去快手挣快钱，二面一个半小时3道算法题也都做了，莫名其妙的就挂了，墨菲定律，越是想去的地方越没有机会，越是不在意的地方往往会有惊喜，比如阿里和蚂蚁，业务都还不错本来想试试可没想到都过了还🤣，玄学，最后打算选做云原生，转Go语言，选择初心，希望这次不要选错，我可是拒了阿里 结语 这一年最大的收获就是知道自己想要什么了，未来的路也逐渐清晰，面试过程中听到最多的话就是你还年轻，路还很长，毕竟工作不久，也算是一点点优势吧。最后，该开始新一年的Flag了 博客不能断，一年不能少于20篇吧 Go语言、k8s、Istio、Mosn都整明白了，最起码能独立解决问题吧 买了相机不能吃灰吧，整两篇文章看下成功 旅行不能少哦，读万卷书行万里路 参与开源项目或者社区（终极目标😬）]]></content>
      <categories>
        <category>生活杂谈</category>
      </categories>
      <tags>
        <tag>生活杂谈</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[一次MySQL死锁的踩坑记录]]></title>
    <url>%2F2020%2F11%2F17%2F%E4%B8%80%E6%AC%A1MySQL%E6%AD%BB%E9%94%81%E7%9A%84%E8%B8%A9%E5%9D%91%E8%AE%B0%E5%BD%95%2F</url>
    <content type="text"><![CDATA[我又写bug了，O(∩_∩)O哈哈~，这次是MySQL数据库的死锁，真实太菜了🤷‍♀️(日常一菜) 背景 我在实现一个接口，使用动态配置中心的API，创建配置并发布，因为要保证接口的幂等性，我为了方便每次将配置删除并重新创建再发布，相较于先查询所有的配置，判断当前配置不存在后再创建的方法，我觉着会多了判断的逻辑消耗，所以采用了第一种方式： 调用删除配置的api接口清空历史数据 -&gt; 创建新的配置 -&gt; 发布新的配置 接下来介绍一下动态配置中心的背景，创建的配置保存在config_item表中，发布的配置将config_item表中的数据插入到config_item_release表中，两个表的结构是一样的，主要信息粘一下，发布配置是以profile维度(就理解为配置的路径)，所以会有profile_id+key的唯一索引； 123456789config_item和config_item_release( id bigint not null comment &apos;主键id&apos; primary key, profile_id bigint not null comment &apos;profile id&apos;, `key` varchar(200) not null comment &apos;配置项key&apos;, value varchar(6144) not null comment &apos;配置项value&apos;, constraint uniq_profile_key unique (profile_id, `key`)) 这样经过测试是没有问题的，后面我的操作就写了bug，我在测试的过程中发现接口比较慢，想优化一下速度，发现接口的操作都是串行的，我创建并发布的配置比较多，所以马上就会想到改为多线程，再联想到插入config_item_release表是以profileId维度，不同profile是相互隔离的，脑补了一下没问题就开干了 多线程版本后，运行几次后只有很小的概率会成功，这就踩到坑了 定位首先要看日志，具体日志找不到了，主要是有下面这么一行，deadlock关键字可以定位到问题了，简单思考一下，数据库的并发操作都是不同的数据行，没有并发对统一数据的写操作，下面就开始科学排查了（Google） ### Cause: com.mysql.jdbc.exceptions.jdbc4.MySQLTransactionRollbackException: Deadlock found when trying to get lock; try restarting transaction 首先要找到MySQL死锁的日志，都说用这个SQL SHOW ENGINE INNODB STATUS 可以看；我怎么搞都不行，最后是用 select @@log_error 找到MySQL错误日志的位置，再通过命令行去看的，如下 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051------------------------LATEST DETECTED DEADLOCK-------------------------- 这行可以定位到头发越来越少的原因了😹2020-11-12 03:04:06 0x70000fccb000-- 第一个事务*** (1) TRANSACTION:-- 事务id=69581 正在执行插入语句TRANSACTION 69581, ACTIVE 0 sec inserting-- 使用到了两张表，加锁了两张表mysql tables in use 2, locked 2-- 事务处于LOCK WAIT状态，有6种锁结构 其中4个行锁LOCK WAIT 6 lock struct(s), heap size 1136, 4 row lock(s), undo log entries 1-- 线程信息MySQL thread id 627, OS thread handle 123145568219136, query id 21548 localhost 127.0.0.1 root Sending data-- 事务发生阻塞的SQL语句INSERT INTO config_item_release SELECT * FROM config_item c WHERE c.profile_id=8720-- 等待获取的锁*** (1) WAITING FOR THIS LOCK TO BE GRANTED:-- 等待获取唯一索引insert intention锁 细节1RECORD LOCKS space id 1112 page no 1955 n bits 376 index uniq_profile_key of table `my_table`.`config_item_release` trx id 69581 lock_mode X insert intention waiting-- 该记录的信息Record lock, heap no 1 PHYSICAL RECORD: n_fields 1; compact format; info bits 0-- supremum 细节2 0: len 8; hex 73757072656d756d; asc supremum;;-- 第二个事务*** (2) TRANSACTION:TRANSACTION 69580, ACTIVE 0 sec insertingmysql tables in use 2, locked 26 lock struct(s), heap size 1136, 4 row lock(s), undo log entries 1MySQL thread id 626, OS thread handle 123145567383552, query id 21549 localhost 127.0.0.1 root Sending dataINSERT INTO config_item_release SELECT * FROM config_item c WHERE c.profile_id=8721-- 当前获取到锁的信息*** (2) HOLDS THE LOCK(S):-- 当前获取到的时唯一索引的X锁 细节3RECORD LOCKS space id 1112 page no 1955 n bits 376 index uniq_profile_key of table `my_table`.`config_item_release` trx id 69580 lock_mode XRecord lock, heap no 1 PHYSICAL RECORD: n_fields 1; compact format; info bits 0 0: len 8; hex 73757072656d756d; asc supremum;;-- 事务等待获取的锁*** (2) WAITING FOR THIS LOCK TO BE GRANTED:-- 等待获取唯一索引insert intention锁 细节4RECORD LOCKS space id 1112 page no 1955 n bits 376 index uniq_profile_key of table `laf_config`.`config_item_release` trx id 69580 lock_mode X insert intention waitingRecord lock, heap no 1 PHYSICAL RECORD: n_fields 1; compact format; info bits 0 0: len 8; hex 73757072656d756d; asc supremum;;-- 回滚了事务2*** WE ROLL BACK TRANSACTION (2) 在这段日志中，忽略了几个细节导致在排查问题的时候走了很多的弯路 事务在等待的锁是Insert Intention锁，这个锁是间隙锁的一种，容易被忽略掉，刚开始的我还以为是insert操作在等待X锁导致排查的方向就做了 supremum 代表无穷大，这里也能够猜想到等待锁的时一个区间是(8720,+∞)的间隙锁，这个细节也被我忽略掉了，注意力完全被 lock model X 吸引走了 事务2当前获取到的锁是唯一索引的X锁，与事务1等待的锁是不一样的，还是对Insert Intention锁不了解导致这个细节忽略掉了 事务2等待的锁和事务1等待的锁是相同的，应该是互相等待对方释放形成了闭环所以才会发生死锁，死锁的基本概念都忘了，感觉自己像做梦一样🤷‍♀️ 分析 从死锁的定义来看，多个事物要获取的资源形成了闭环，结合日志来看两个事务都在insert操作时阻塞，等待相同位置资源锁，并且被对方限制 在从日志来看事务1并没有获取到任何的锁，事务2获得的是唯一索引的记录锁，看不出来有什么资源被互相限制；大胆猜想一下，这里一定存在事务已经获取到的锁但是没有在日志中体现出来 从日志中被阻塞到的insert操作和Insert Intention关键字入手查找资料发现了惊人的东西，我的知识体系中存在这巨大漏洞，下面就是被忽略的细节 在insert操作之前会有Insert Intention锁(插入意向锁)是间隙锁的一种，从日志来看加锁的间隙为(max,+∞) Insert Intention锁之间只要插入的数据不是同一个数据是不会冲突的 间隙锁和Insert Intention锁之间也会有互斥的关系，已经存在了G锁(间隙锁)是不能在加I锁(插入意向锁)，相反已经存在I锁是可以再加G锁的 两个G锁直接是相互兼容的 在补充了这些知识盲区后，真相浮出水面，两个事务都先加了范围是的G锁，下一步都要执行insert操作，insert之前都要加I锁，I锁都被对方事务事先加号的G锁阻塞，形成了闭环，发生死锁 结合业务逻辑来看 第一步删除历史数据清空了config_item_release表的数据 第二步更新配置，在config_item表中update操作 第三步发布配置，这个api的逻辑是先删除config_item_release中的记录，在将config_item表中的数据插入进来 问题就出现在第一步清空了config_item_release表的数据后该表中是没有数据的，第三步先delete操作这时候两个事务会加区间为(max,+∞)的G锁，然后insert操作前会在这个区间加I锁，都被对方的G锁排斥形成死锁， 那么如果是这个问题，在config_item_release表中存在数据时，不同事务delete加G锁的区间不同在加I锁就不会被阻塞就可以避免死锁了(delete操作的加锁过程见参考文章) 验证这里通过两个实验来验证上面的分析结果 实验一：config_item_release不存在数据，两个事务先delete后insert会发生死锁 事务1 事务2 结果 分析 begain begain DELETE FROM config_item_release WHERE profile_id=9118 Affected rows: 0, Time: 0.002000s 事务1对(max,+∞)区间加G锁 DELETE FROM config_item_release WHERE profile_id=9112 Affected rows: 0, Time: 0.002000s 事务2对(max,+∞)区间加G锁 INSERT INTO config_item_release SELECT * FROM config_item c WHERE c.profile_id=9108 事务1对(max,+∞)加插入意向锁，被事务2阻塞 INSERT INTO config_item_release SELECT * FROM config_item c WHERE c.profile_id=9112 1213 - Deadlock found when trying to get lock; try restarting transaction, Time: 0.008000s 事务2对(max,+∞)加插入意向锁，被事务1阻塞，出现死锁 实验二：config_item_release存在数据，两个事务先delete后insert不会发生死锁首先执行下面两条语句初始化表中的数据 12INSERT INTO config_item_release SELECT * FROM config_item c WHERE c.profile_id=9111;INSERT INTO config_item_release SELECT * FROM config_item c WHERE c.profile_id=9112; 事务1 事务2 结果 分析 begain begain DELETE FROM config_item_release WHERE profile_id=9111 Affected rows: 1, Time: 0.000000s 事务1对profile_id=9111记录前的间隙加G锁 DELETE FROM config_item_release WHERE profile_id=9112 Affected rows: 3, Time: 0.000000s 事务2对profile_id=9112记录前的间隙加G锁 INSERT INTO config_item_release SELECT * FROM config_item c WHERE c.profile_id=9111 事务1阻塞，因为事务2对profile_id=9112之前的间隙加了G锁，9111这条记录刚好在这个区间，事务1要加I锁时被事务2的G锁阻塞 INSERT INTO config_item_release SELECT * FROM config_item c WHERE c.profile_id=9112 Affected rows: 3, Time: 0.000000s 事务2先对9112之前的间隙加I锁这个间隙是当前事务的G锁不冲突没有阻塞 commit OK, Time: 0.001000s 事务2成功提交，事务1结束阻塞状态 commit OK, Time: 0.001000s 事务1成功提交 综上所述，正式由于我先清除了历史数据，在删除表里不存在的记录时多个事务将相同的区间加了G锁，再加I锁时产生死锁，解决：删除业务逻辑中的清除历史数据的操作，保证表中数据存在。 总结 补充一下自己的知识盲区，重新梳理数据库的锁，详细见上一篇文章 避免删除不存在的记录的操作，这个操作会加G锁，可能多个事务的G锁重叠了导致死锁 删除操作最好是先找到记录的id再根据id删除；因为只有在唯一索引的删除操作才会加R锁其他情况都会有G锁 参考资料MySQL DELETE 删除语句加锁分析 从一个死锁看mysql innodb的锁机制 一个死锁问题 MySQL加锁分析]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[捋一捋MySQL的锁]]></title>
    <url>%2F2020%2F11%2F16%2F%E6%8D%8B%E4%B8%80%E6%8D%8BMySQL%E7%9A%84%E9%94%81%2F</url>
    <content type="text"><![CDATA[引言本文主要梳理MySQL的锁机制，主要是针对于Innodb引擎，目前网络上查的文章基本上都差不多，实际上是忽略了一些细节的，这些细节可能会成为今后搬砖过程中的恶魔，比如说插入意向锁，行锁之间的兼容关系这些，本文通过查阅资料加锁MySQL官网的说明再结合自己的理解梳理了一下MySQL的锁机制~ 锁的划分这里要有一个前提，就是MySQL对锁的划分是两种不同的维度，按照加锁的粒度和锁的类型，并不是固定的什么锁什么锁，就比如表锁和行锁里都有共享锁或者排他锁，同样，共享锁或排他锁中也都有行锁和表锁，是你中有我我中有你的关系，按照不同维度划分的结果，下面就来一一列举这些锁 锁粒度以加锁的粒度为准可以分为，全局锁，表锁和行锁； 全局锁；对整个数据库加锁，让整个数据库在只读状态，在数据库备份时使用（主库上备份，所有写操作将不能进行影响业务；从库上备份，备份期间不能有写操作，不能执行binlog，主从延迟增大） 表锁，加锁的粒度为数据表 自增锁 AUTO-INC Locks 是一种特殊的表锁，可以保证一个事务插入数据的id连续 行锁，加锁的粒度为数据行 记录锁 Record Locks；锁定当前数据行 间隙锁 Gap Locks；锁定数据行的前后间隙 插入意向锁 Insert Intention Locks；在插入操作之前会把插入的区域加入插入意向锁，不同区域的的锁互相兼容 临键锁 Next-Key Locks；锁定数据行+前后的间隙 锁类型 共享锁（S）和 排他锁（X）；相当于，读锁和写锁，读可以共享锁，写只能独占资源；粒度可以有行锁和表锁，比如行级或者表级的S锁（或X锁） 意向锁(意向共享锁IS，意向排他锁IX)，一个事务在给数据行加锁时会在数据所在的表加相同类型的意向锁(比如对数据行加X锁就会在该表加表级别的X意向锁)，表示该表有事务对数据行加了锁，意向锁直接是相互兼容的，但是与具体的表锁或者行锁有着互斥关系的，具体关系见下面分析 锁之间的兼容关系 S X IS IX S ✅ ❎ ✅ ❎ X ❎ ❎ ❎ ❎ IS ✅ ❎ ✅ ✅ IX ❎ ❎ ✅ ✅ 注: 意向锁是表级别的锁，上面表格中与意向锁兼容和互斥关系指的是与表级别的S锁或者X锁，意向锁和行级别的锁是不冲突的；主要是为了防止一个事务在插入或者修改数据的时候另一个事务修改了表结构之间会冲突；插入或者修改数据是一般会加行锁或者间隙锁，同时在表上加IX锁(意向排他锁)，另一个事务要修改表结构是要给表加X锁，这时会和IX锁冲突等待IX锁释放 这个只是我们熟知的锁之间的兼容关系，除此之外呢，MySQL中还有更加精确的锁之间的兼容关系，也就是在所有类型的行锁之间的兼容关系，(见参考文章3)；这个关系是在X锁与X锁或者S锁与X锁不兼容的情况下再进行比对 G I R N G ✅ ✅ ✅ ✅ I ❎ ✅ ✅ ❎ R ✅ ✅ ❎ ❎ N ✅ ✅ ❎ ❎ 注: G=Gap锁，I=Insert Intention锁，R=Record锁，N=Next-Key锁； 上表中的行代表当前已经存在的锁，理解一下这张表就假设两个X锁排斥的前提下： 第一列 已经存在G锁，不允许再加I锁（加了间隙锁就不允许在间隙中插入操作了） 已经存在G锁，还可以再加G锁、R锁和N锁（也就是说G锁之间是相互兼容的，R锁和G锁本身就不冲突当然兼容，N锁实质上就是G锁+R锁，G锁和R锁都兼容那么N锁一定兼容） 第二列，已经存在I锁，剩下的所有类型锁都可以再加 这里看到再加G锁也是兼容的即使加锁的间隙是一样的 根据官方文档两个I锁如果插入不是同一个位置是相互兼容的，这样可以提高并发 兼容R锁也很好理解，I锁是间隙，R锁是记录本身就不冲突 G锁和R锁都兼容了那么N锁一定兼容 第三列，已经存在R锁，是可以加间隙锁的(G锁和I锁)，但如果包含记录的锁就不兼容(R锁和N锁) 第四列，已经存在N锁，首先包含记录的锁(R锁和N锁)是不兼容的，I锁表明要插入数据也是不兼容的，G锁是兼容的 总结：G锁与其他锁之间是相互兼容的，无论间隙是否相同，也无论当前是什么类型的锁，再加G锁也是兼容的；I锁是G锁的一种，是在插入之前表明插入操作的意向，如果当前存在G锁或者N锁，也就是加锁的区域相同就不能再加I锁，需要等待，其他情况与G锁相同都是兼容的；R锁和N锁就看加锁的数据是否冲突来判断锁是否兼容 参考秒懂InnoDB的锁 InnoDB Locking 从一个死锁看mysql innodb的锁机制]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java NIO]]></title>
    <url>%2F2020%2F10%2F23%2FJavaNIO%2F</url>
    <content type="text"><![CDATA[开门见山，最近打算看一下netty，做这么长时间微服务netty还没看过是不是太飘了，这篇是netty的背景知识 NIONon-blocking I/O 非阻塞I/O；与传统阻塞I/O相比最大的时阻塞和非阻塞的区别；除此之外NIO操作的是缓冲区，以块的形式处理数据，传统I/O以数据流的形式处理数据；而且NIO支持了Selector；我的简单理解，传统I/O相当于拿一根水管（单向的）插入到水桶里，让水从水桶中流出，从水管中得到水（数据）；NIO则是用水管（双向的水管？栗子可能比较糙但就是这么个意思）将桶中的水流入一个小水池中（缓冲区），从小水池中得到水（数据）；所以基于流的读写只能按顺序来，不能改变读写的位置，且只能是单向的，而对于缓冲区的数据来说就可以随意修改读写的指针了 Channel 用来进行IO操作（文件IO或网络IO），与BIO的Stream类似，不同的时Channel是双向的Stream只能是单向的；Channel读写的对象是Buffer Buffer 用来存放Channel读写的数据，其实就是内存中的一块区域，保存不同类型的数据(ByteBuffer，CharBuffer等，可以理解为数组，字节数组，字符数组等)；首先通过Channel将数据写入到Buffer中，再对Buffer进行读写，flip()切换到读模式，clear()或compact()切换到写模式 对Buffer每次读写之后Buffer都会记录当前的状态，通过capacity（Buffer的最大值），position（下次读或写的位置，每次读写后更新），limit（Buffer中数据的大小）三个属性；0 &lt;= position &lt;= limit &lt;= capacity 向缓冲区写入数据时，limit = capacity， position = 下一次写入的位置（初始为0）；如果想读出缓冲区的数据，调用filp()方法切换为读，limit = 下一次写入的位置（即读的边界），position = 0（从头开始读）；读完数据想要继续写，调用clear()方法，并不是缓冲区里的数据清空，而是将position重新指向0，limit = capacity 与写的状态一样，新写入的数据会覆盖到缓冲区中；compact()方法，将读模式下position-limit的数据复制到buffer的开头，相当与将已经读过的数据覆盖掉，limit = capacity，position = limit - position Selector NIO非阻塞的特性，可以通过Selector使用一个线程监听多个Channel的IO事件，方法是将所有Channel注册到Selector中(这里Channel必须是非阻塞的)，并注册感兴趣的事件，Selector#select方法找到事件发生的Channel进行下一步工作，select这一步是阻塞的如果事件没有发生将一直阻塞，select的操作系统的实现为IO多路复用技术（select，poll，epoll），Linux下使用epoll 简单罗列一下IO模型，和相关实现 阻塞I/O线程发起I/O请求会一直阻塞等待I/O条件就绪 非阻塞I/O线程发起I/O请求后，如果I/O条件不是就绪状态立即返回一个状态不会一直等待，可以先做其他的任务，间隔一段时间查看I/O条件是否就绪，如果就绪进行下一步操作 多路复用I/O非阻塞I/O线程需要一直去询问I/O事件是否就绪，如果线程很多每个线程都不听的去轮询I/O事件必将造成资源的浪费；多路复用I/O将所有线程的I/O请求注册到一个新的线程中（select），由这一个线程进行轮询去查看I/O条件是否就绪，有就绪状态就通知对应的线程进行处理；相当于是把非阻塞I/O中多线程查看I/O条件的事情委托给了单独的一个线程，提高了系统的吞吐量； 在Linux中该模型的实现有select，poll和epoll的系统调用，服务端接受连接，select和poll都会将连接感兴趣的I/O事件保存到一个集合中（fd集合，在Linux中I/O是文件），每次Selector#select传递给内核，内核去寻找集合中满足条件的I/O，返回满足条件的数量，用户线程得到满足I/O条件的数量，需要再次遍历集合找到满足I/O条件的连接进行下一步操作，时间复杂度为O(2n)；epoll使用事件驱动模式，首先将连接感兴趣的I/O注册到内核，并且注册了一个回调函数，当满足I/O条件会发生回调将该I/O对应的fd移动到内核中的就绪队列，每次select只需从就绪队列中读取具备I/O条件的数量即可，再进行下一步的操作，当有m（m&lt;=n）个连接具备条件，时间复杂度为O(m) 信号驱动I/O这个感觉和多路复用I/O差不多，这里将多线程的I/O操作注册为一个信号，信号中有回调函数，当信号发生call回调函数通知用户线程，先简单这么理解 异步I/O线程发出I/O请求后不需要做任何操作，I/O操作完全由操作系统内核完成，之后会通知线程I/O已经完成 具体例子可以参考这里]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[分布式锁的套路-watchdog实现]]></title>
    <url>%2F2020%2F10%2F19%2F%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81%E7%9A%84%E5%A5%97%E8%B7%AF-watchdog%E5%AE%9E%E7%8E%B0%2F</url>
    <content type="text"><![CDATA[开门见山，分布式锁用来保证分布式环境下业务逻辑的原子性以及互斥，原理就是锁的原理，多个系统一同去竞争同一个资源（类比单机环境下多个线程竞争同一块内存），获得资源的系统可以认为是加锁成功，否则加锁失败；下面总结一个简单可用的分布式锁的实现 业务场景日常开发中，一定会有定时任务操作一些数据的需求，而且这个定时任务还必须要高可用，所以就必须要在分布式环境下运行，但是又不能多个系统一起运行，所以就需要用到分布式锁，能够保证一个系统去运行定时任务，在这个系统出现异常了，其他的系统能够顶上来完成剩下的任务，类似于watchdog的功能 总结了一个流程图如下 如图所示这个套路，简单无脑，定时任务的时候lock一下，成功了就继续执行，失败了就return，下一个周期再lock；把过期时间设置的比定时任务周期稍微长一些，也就是说当一个系统获取锁成功后，如果没有意外情况后面的周期还是这个系统运行（类比于jvm中的偏向锁，不同的时这个会一直偏不会锁升级），当系统发送异常情况，其他的系统就会lock成功，继续后面的任务，可以完成一个简单高可用的定时任务 实现上面讲过，分布式锁的原理就是能够保证互斥，在一个所有系统都能访问到的地方去做文章，基于这点就有很多种实现，比如数据库这样提供存储的工具(mysql、redis、zk、etcd等等)，理论上所有数据库都可以用来实现分布式锁甚至文件都可以，就看自己的需求了；通常的话使用数据库、redis和zk的比较多 mysqlmysql的话是通过数据库的唯一索引保证原子性，首先要创建一个表用于存锁的相关信息，需要一些必填字段 lockName - 唯一索引，锁的名称 modifyTime - 修改时间 owerIp - 获取锁的Ip lockTime - 锁的有效时间 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748public boolean lock(lockName, lockTime)&#123; // 获取当前的锁 Lock currentLock = lockDao.findLockByLockName(lockName); // 当前没有加锁 if (currentLock == null) &#123; return tryLock(lockName, maxLockTime);//加锁 &#125; // 锁过期了并且成功释放锁 -&gt; 重新加锁，释放锁异常返回false if (currentTimeMillis-currentLock.getModifyTime().TimeMills &gt; currentLock.getMaxLockTime()) &#123; return unlock(lockName) ? tryLock(lockName, maxLockTime) : false; &#125; // 锁没过期且自己占有锁且锁没过期 续租 if (currentLock.getOwnerIP().equals(NetUtils.getLocalHost())) &#123; renewLock(currentLock); return true; &#125; return false;&#125;public void renewLock(Lock currentLock) &#123; try&#123; currentLock.setModifyTime(new Date()); lockDao.update(currentLock); &#125;catch(Exception e)&#123; // 续租失败，但锁没过期，仍然有效 &#125;&#125;public boolean tryLock(String lockName, long maxLockTime) &#123; try&#123; lockDao.save(new Lock(lockName, NetUtils.getLocalHost(), maxLockTime)); return true; &#125;catch (Exception e)&#123; return false; &#125;&#125;public boolean unlock(String lockName) &#123; try &#123; lockDao.deleteLockByLockName(lockName); // 可能存在其他线程把当前线程的锁释放掉，这里可以根据线程的持有者进行释放锁的操作 // 在我的场景下可以保证定时任务一定会在锁的有效时间内执行完成，故不考虑这种情况 return true; &#125;catch (Exception e) &#123; return false; &#125;&#125; redisredis相较于mysql而言吞吐量有了显著的提高，并且也提供了一系列原子操作的api，而且还有过期时间的api不需要，可以很简单的实现分布式锁 1234567891011121314151617181920212223242526272829303132333435363738394041public boolean lock(lockName, lockTime)&#123; // 获取当前的锁 String value = redis.get(lockName); // 当前没有加锁 if (value == null) &#123; return tryLock(lockName, maxLockTime);//加锁 &#125; // redis自己会清理过期的key, 锁没过期且自己占有锁且锁没过期 续租 if (value.equals(NetUtils.getLocalHost())) &#123; renewLock(lockName, period); return true; &#125; return false;&#125;public void renewLock(Strng lockName, long period) &#123; try&#123; // period为定时任务的周期时间，因为lockTime要比period大，每次续期lockTime后锁的过期时间会越来越大 redis.expire(lockName, redis.ttl(lockName)+period); &#125;catch(Exception e)&#123; // 续租失败，但锁没过期，仍然有效 &#125;&#125;public boolean tryLock(String lockName, long maxLockTime) &#123; try&#123; return redis.setNx(lockName, NetUtils.getLocalHost(), maxLockTime)); &#125;catch (Exception e)&#123; return false; &#125;&#125;public boolean unlock(String lockName) &#123; try &#123; lockDao.deleteLockByLockName(lockName); return true; &#125;catch (Exception e) &#123; return false; &#125;&#125; 上面给了两种方式的简单实现，实际过程中还需要考虑异常情况的细节，除此以外还有很多种实现的方式只是列举了两种，套用流程图上的套路，实现一个简单的watchdog的功能]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring中bean的生命周期总结]]></title>
    <url>%2F2020%2F10%2F09%2FSpring%E7%94%9F%E5%91%BD%E5%91%A8%E6%9C%9F%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[最近非常的忙碌，博客也一直没有更新，可惜自己一直没有时间去看新的东西还想更新博客，心有余而力不足，那就把旧的知识温习一下，来“敷衍”一下；废话不多说，要看spring中bean完整的生命周期要从BeanFactory接口中看，如图，主要分为以下几个部分 xxxxAware接口的方法 BeanPostProcessor接口的postProcessBeforeInitialization方法 InitializingBean接口的afterPropertiesSet方法 自定义的init方法 BeanPostProcessor接口的postProcessAfterInitialization方法 销毁 DestructionAwareBeanPostProcessor的postProcessBeforeDestruction方法 DisposableBean接口的destroy方法 自定义的销毁方法 下面结合源码画一个生命周期图]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[我又来入门k8s了]]></title>
    <url>%2F2020%2F06%2F30%2F%E6%88%91%E5%8F%88%E6%9D%A5%E5%85%A5%E9%97%A8k8s%E4%BA%86%2F</url>
    <content type="text"><![CDATA[引言之前分析过Docker容器技术，在容器技术很快的被广大使用之后，对于业务复杂的公司来说往往需要非常多的容器，而每次都需要docker run或者restart的话也是非常麻烦的而且人操作的话还容易出错，这就需要一个容器管理的一个组件，比如docker swarm、mesos和k8s，最终k8s脱颖而出称为大多数人的选择，而且k8s还被称为PaaS平台的操作系统，那么k8s能做什么呢？ Pod，是k8s提出的概念，是k8s的最小调度单位，Pod中可以有一个容器或者多个容器 Pod调度；k8s采用声明式API的方式，用户只需编写yaml文件描述所期望的Pod状态(比如2个容器，4c8g)，k8s根据所期望的Pod状态进行部署和维护 健康检查自动恢复；监控集群中Pod的状态发现异常Pod进行迁移或重启 动态扩缩容；检查Pod负载高时动态扩容进行负载均衡；反之减少容器节省资源 负载均衡 类似于Pod的运维系统，有了这些功能完全可以将自己的系统托管给k8s，可以减轻运维人员的工作 架构master+slave的架构，master节点负责系统逻辑的处理，调度，slave节点来干活，与spark集群的模式是一样的 master节点组件 etcd：分布式kv数据库，用于保存数据(yaml文件)和集群的状态，其他组件都通过api server向etcd读写数据，理解为用来保存状态的数据层；etcd还是高可用的分布式数据库可以保证master的高可用 api server：提供api服务，负责各个模块之间的通信，不同组件之间交互都需要经过api server，理解为数据总线 controller manager：负责维护集群的状态，确保集群的状态与etcd中的状态保持一致，理解为MVC中的Controller层；例如健康检查，slave节点中的kubectl会向master节点(通过api server)定期报告节点中Pod的状态，相当于slave向master发心跳，心跳状态会保存在etcd中，master节点中的controller manager会定期从etcd中获取slave的状态，针对这些状态与etcd中保存的期望状态比对进行下一步操作，通过api server通知scheduler组件创建一个调度任务发送给slave节点 scheduler：负责调度，将pod调度到合适的node中；创建pod资源的时候，通过etcd中的状态调度到合适的slave节点中，更新或者删除也是这样 slave组件 kubelet：可以理解为通过实现了一些接口来对slave节点进行管控操作；负责与master通信，通过CRI(Container Runtime Interface)操作容器运行时(container runtime)，相当于是slave节点中的控制器，理解为通过CRI”发送指令”到容器运行时，对当前节点中pod做CRUD操作；还负责配置当前slave节点的网络和存储，通过调用网络插件和存储插件为容器配置网络（CNI Container Networking Interface）和持久化存储（CSI Container Storage Interface）； kube-proxy：用于service的服务发现和负载均衡，通过iptable机制；service是相同服务的的多个pod集合，相当于一个VIP职责，不需要关心具体服务的ip只需访问服务的域名，由kube-proxy来转发到具体的pod container runtime：真正对pod做CRUD操作的组件，相当于kubelet的slave 如上图在slave节点中kubelet扮演控制器的角色来操作通过进行时对Pod进行操作，而kube-proxy是将访问pod的流量转发到相应的pod中，一个pod在启动之前k8s会在pod中先启动一个初始容器为这个容器添加Namespace，network，Volume这些设置，再将后启动的容器添加到初始容器的Namespace中去，这个初始容器用来进行进程隔离，与Pod具有相同的生命周期，通常Pod中容器的访问，日志收集等操作都会由这个容器来完成，也就是sidecar容器；访问某个pod的时候首先会经过iptables的规则转发到Pod的sidecar容器里，再由sidecar容器转发到目标应用容器中，sidecar可以天然用来做微服务中的流量控制，服务治理，灰度发布等功能 工作原理 用户提交了yaml文件给apiserver apiserver会将数据保存到etcd中，再通知scheduler有容器需要被调度 scheduler根据配置选择合适的node，返回给apiserver apiserver将结果同步到etcd中，再通知对应node中的kubectl kubectl收到通知后调用container runtime来真正去启动这个配置的容器，调用storage plugin配置存储，调用network plugin配置网络 API Pod；Pod是k8s的最小调度单位，Pod中可以有一个容器或者多个容器；前面分析过docker是通过Namespace和Cgroup技术来进行进程的隔离，是基于单进程模型并不具备管理多进程的能力，（参考这里大概是是无法回收僵尸进程和孤儿进程的资源的意思因为回收进程资源需要向父进程发送一个信号）；k8s通过将多个容器加入到同一个Namespace中并给头号进程赋予了管理多进程的能力，所以说相较于docker容器来说k8s的Pod概念更像是虚拟机一样，提供了传统虚拟机到容器环境的完美迁移方案 Deployment；对Pod的一个抽象，可以定义Pod的副本数量，版本，可以用Deployment来描述一个应用集群的状态 ReplicaSet；用来控制Pod的版本，Deployment不会之间控制Pod，而是通过ReplicaSet来间接控制Pod，一个Pod的版本对应一个RS（可以实现金丝雀发布，蓝绿发布） StatefulSet；有状态的Pod进行编排；Pod之间有拓扑关系的拓扑状态或者存储状态； DaemonSet；集群中运行一个DaemonPod，每个Node中有且只有一个，如果有新节点加入集群会自动创建；比如node中的各种插件（网络，存储，监控，日志） Service；提供了一个或者多个Pod的访问地址，由于Pod的地址可能会变，通过域名可以做到不依赖于固定的ip地址访问Pod，相当于VIP，由kube-proxy+iptables来共同实现 Job；一次性任务，运行完成后退出 CronJob；定时任务，用于离线计算 等等等等，只是了解到了这些，还有很多去查看官方文档吧]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>k8s</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[一年菜鸡带你看微服务]]></title>
    <url>%2F2020%2F06%2F25%2F%E4%B8%80%E5%B9%B4%E8%8F%9C%E9%B8%A1%E5%B8%A6%E4%BD%A0%E7%9C%8B%E5%BE%AE%E6%9C%8D%E5%8A%A1%2F</url>
    <content type="text"><![CDATA[工作快一年了，我从一个刚入职时候的小白变成了现在有一年经验的小白,在我这一年的工作中修炼自己，现在可以说是把自己的一条腿抬过了微服务的门槛，在这个位置看到了一下东西，把我的理解记录分享一下。 前言随着历史进程的发展，我们的业务量也愈发膨胀，系统的也从原来的单体架构，逐渐演化成微服务架构，将重复的业务逻辑抽象成基础的服务，这样做不仅仅可以将业务解耦，还通过将一个大的系统拆分成服务粒度的子系统，各个子系统单独开发编译测试上线，大大提高了开发的效率，加快了系统迭代的速度。根据我的理解，微服务框架包括RPC框架和注册中心两个部分，下面就来分别介绍一下 注册中心微服务框架是用来进行远程调用，涉及到远程调用就会有服务的提供方（provider）和调用方（consumer），注册中心的工作就是让他们彼此认识，即服务注册和服务发现，除此之外注册中心还负责将对方状态的变化通知到另一方，配置下发等功能，主要有CP和AP两种选型的注册中心 CP 强一致性 Zookeeper、etcd … 用Zookeeper举例来说，发布服务就会创建一个目录，在该目录下维护服务提供方和调用方的信息，通过zk本身的watch机制来观察服务状态变化 缺点是当服务规模很大时，zk需要数据同步的时间变长，期间服务不可用，也就是选择CP会出现的问题；数据同步的请求量大很可能将leader打挂（比如说我了解到曾经有服务大规模扩容，为了保证顺序所有follower将写请求发送给leader，大量写请求导致leader宕机，重新选择leader期间服务不可用，新的leader瞬间又被打挂） AP 弱一致性 消息总线型 服务注册和订阅的数据全量保存在一个存储介质中，注册中心从存储介质中获取的数据缓存在内存中，通过消息总线做数据同步（推拉结合，用版本号保证消息的顺序性） 服务调用方从注册中心获取数据保存在调用方的内存中，同样采用推拉结合，保证最终一致性； 推 callback机制，服务调用方在生成代理的目标对象之前会向注册中心订阅配置，订阅的时候会将callback序列化发送给注册中心，注册中心收到带有callback参数的请求为callback创建代理对象，相当于是一个反向的RPC调用（服务提供方向服务调用方发送请求复用已有的tcp连接） 拉 心跳，服务调用方通常会向注册中心发送心跳来告知自己的状态，发心跳的同时拉取需要更新的数据到内存中 RPC框架RPC框架用于服务之间的通信，例如Dubbo、SpringCloud、gRPC，通过不同的协议完成服务之间的调用；除了最基本的通信以外还包括服务治理策和流量控制的策略，服务监控和追踪，等其他特性 服务治理&amp;流量控制 服务管理 服务节点的新增删除；分组，动态分组的设置与取消；不同维度的上下线 路由策略 调用者将请求路由至固定的一个或者多个服务提供方的节点；用于测试，或者灰度发布 负载均衡 将服务调用方的请求均匀的发送给选择到的服务提供方节点；随机、加权随机、轮询、加权轮询、最少活跃、一致性哈希，之前分析过不同的策略实现，移步这里查看 容错策略(集群策略) failover 失败自动切换不同的服务提供方进行重试 （业务错误重试和安全重试？） failfast 快速失败，失败 failsafe 失败安全，出现异常直接忽略，用于记录审计日志 broadcast 广播调用，失败的跳过 pinpoint 点对点调用 限流 用于保护服务提供方（按APP，接口，分组，IP，方法不同的维度）在服务提供方和调用方都可以实现限流的逻辑 在服务提供方的限流逻辑只是针对于单个容器或者物理机，服务提供方只需处理小于最大限流值的请求即可，不需要关心其他的服务节点，几乎没有性能的损耗，具体的限流算法之前写过一篇限流算法的介绍 在服务调用方做限流逻辑可针对整个集群的维度，一般是先请求集中式的服务来判断本次请求是否超过限流值，多了一次rpc请求，会影响性能，在京东微服务框架中，限流逻辑在服务调用方有monitor和counter两种实现方式；monitor服务，对es中的监控日志进行统计异步判断是否超过限流值，因为是异步请求不影响性能，但限流的实时性无法保证不完全精准，目前这种方式已经废弃；counter服务，通过访问缓存数据库实时统计请求，判断是否超过限流值，精度准确，会影响性能； 熔断，用于保护服务调用方 防止服务调用方依赖下游服务异常，挂起大量请求压垮容器，比如服务调用方依赖下游的服务，由于下游的服务异常导致短时间内无法收到响应而一直挂起，如果挂起的请求过大可能会使服务不可用，熔断策略可以快速返回失败从而保护服务不被打挂掉 熔断器（打开，半打开，关闭三种状态；服务调用的失败率高于某一阈值，新的请求直接返回失败不进行处理，进入半打开状态；半打开状态一段时间后，开始处理新的请求，如果失败率仍然高于阈值，则进入关闭状态否则进入打开状态） 分组 业务流量隔离，将核心业务与其他业务隔离开来 控制同机房调用，不同的机房设置不同的分组，通过分组来实现相同机房的服务以及互相调用 动态分组；可以用来流量切换；可以应对突发的流量激增，分组中预留的容器依然不能顶住流量，可以借用其他分组中容器来分担一部分流量 流量回放；服务调用方异步存储请求和响应，用来测试 服务监控和追踪用来查看请求量（TPS，实时和历史数据）、响应时间 服务监控 数据采集方式 a)通过服务主动上报，将日志数据发送到日志节点 b)通过代理收集，将日志数据保存到本地，代理解析本地日志（sidecar） 服务追踪 整条链路用TraceId标记，其中经过的每个服务节点都有不同的SpanId，最终通过对数据结构的解析绘制链路图 其他特性 健康检查，通过发送心跳报告节点的状态 比如在京东微服务框架中调用方隔30s向内存中的服务提供方列表发送心跳（探活），探活不同结果将列表分成不同的状态（健康、亚健康、死亡），调用方每次从健康节点的集合中选择一个发起调用；亚健康状态只发心跳不发请求，当心跳恢复移至健康节点，健康-&gt;亚健康（连续6次心跳失败，异常心跳可重试两次，三次都失败则当前心跳失败），连续60次心跳失败加入重连的集合中，10s重连一次 服务提供方和服务调用方都会想注册中心发送心跳报告状态，30s，服务提供方连续8小时没有向注册中心发送心跳会删除 优雅启停 停止；拒绝新的请求，返回一个正在关闭的异常，调用方安全重试-&gt;在超时时间范围内处理完已经接受的请求，时间范围以外的返回异常-&gt;开始关闭动作释放资源 启动；启动预热，随着启动时间的增加逐步增加流量，定时动态修改负载均衡策略的权重；提前加载缓存数据；注册之前模拟调用逻辑保证服务可用-&gt;延迟暴露，待所有的服务完全启动完再想注册中心注册服务 泛化调用；在没有接口和API的情况下发起调用，将服务提供方的接口名，分组，方法名，参数发送给服务提供方，随后根据信息通过反射调用本地方法（1.测试平台，无需修改配置重启再发起调用；2.统一网关，无需引入jar包） 安全问题；服务调用方通过引入jar包的方式来发起调用，可能会发生在服务提供方不知情的情况下发起调用，成为压垮服务的最后一根稻草 服务的提供方和调用方商量一个token，服务提供方收到请求在filter中校验隐式传参的的token判断是否通行 在京东微服务框架中还可以再服务治理平台中开启APP调用，只有申请了APP调用被服务提供方审核之后才能从注册中心中获取服务列表 实现原理将远程调用的过程通过动态代理封装起来，与业务逻辑解耦，使用者可以专心于业务逻辑而不必关心RPC调用的过程； 服务提供方启动 与注册中心建立连接，订阅全局配置（远程callback机制，发送请求将callback序列化发送出去，接收方对callback进行动态代理回调发送方） 开启并暴露服务的端口，向注册中心注册 服务调用方启动 与注册中心建立连接，订阅全局配置 创建动态代理对象，构造执行链 filter chain（内置的filter-&gt;自定义的filter-&gt;最后的filter根据配置生成路由，负载均衡策略的逻辑）注入到代理对象中 向注册中心订阅服务列表 调用方发起调用 调用前首先运行执行链，最后的filter过滤出服务提供方节点（本地调用-&gt;路由策略-&gt;黑白名单-&gt;负载均衡） 序列化请求的参数，封装协议报文，根据配置的集群容错策略通过netty框架向服务提供方发送请求， 服务方处理请求 接收到请求首先适配协议，根据协议和序列化、压缩的方式解析请求 运行执行链，最后的filter会根据接口名、方法和参数信息通过反射调用本地方法，最后将接口返回给调用方，调用方进行反序列化得到响应结果 Service Mesh 服务网格微服务发展到今天一些弊端也逐渐显露出来，最大的痛点就是业务入侵严重，使用者通过引入jar包使用微服务框架，如果要增加新的功能点或者修复一个紧急的bug就需要告诉所有使用方升级一下jar包，这会非常困难，可能你会说maven修改一下版本不就好了，但是在京东如果非常重要的业务比如交易服务，是不希望去做改变的，而且服务上下有着非常复杂的依赖关系牵一发而动全身；另外微服务框架不支持跨语言，对应微服务框架的不同语言直接想要互相调用得需要多个语言开发的框架版本才行，这对于开发和维护的成本都非常大。 Service Mesh完美的解决了这两个痛点，可以简单将其理解为将RPC框架的内容抽象成sidecar，微服务框架的jar包中只保留与sidecar通信的总要逻辑即可，这些逻辑基本上是不会变的，当发布你的应用容器的时候注入sidecar，原来是容器中的应用直接互相调用的方式现在变成了容器中的应用与容器中的sidecar通信，sidecar通过iptables规则做请求转发，并且服务治理，流量控制的这些逻辑抽象到了sidecar中这对于业务方来讲只需重新注入sidecar即可完成升级，对于应用来讲升级过程是透明的。]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[蓦然回首servlet]]></title>
    <url>%2F2020%2F06%2F11%2F%E8%93%A6%E7%84%B6%E5%9B%9E%E9%A6%96servlet%2F</url>
    <content type="text"><![CDATA[听到Servlet我既熟悉又陌生，我第一次接触还是在2013年，当时对于课程设计水平的我来说仅仅有个感性的认识，后来接触了ssh之后好像已经疏远了servlet，我只在写业务逻辑一直到现在，我对于servlet的印象还停留在声明，在web.xml中配置，写mapping这些，说明spring的解耦是真的强👍，让我对servlet的认识止步榆次，今天就回首看看这位“老朋友”，就大概梳理一下吧 Servlet是一个接口，服务器用来处理Http的请求的，接口中主要service方法用来处理http请求，init和destroy方法表示servlet初始化和销毁是调用，总结一句话来说，servlet是一种规范，是服务器处理Http请求的规范。 Tomcat就是实现servlet规范(接口)的一个🌰，Tomcat中实现了servlet容器用来管理servlet，当收到Http请求后将请求封装成request对象，并根据请求的信息找到对应servlet(web.xml)，将请求交给对应的servlet处理，并将处理结果的response对象转化成Http的协议返回给浏览器 叫容器的就可以理解为字面意思，用来存放一类东西；web容器里存储web应用，Servlet容器里存储Servlet，Spring容器存放bean等等等等 Tomcat就是一个web容器，其中包含多个web应用，每个应用在Tomcat启动时都会初始化一个servlet容器，用来保存应用下的servlet；Tomcat启动后会监听在8080端口，等待接收请求的到来，在收到请求后根据请求信息首先到想要访问的目标web应用中的web.xml文件里找到目标Servlet，并将Http请求封装成request对象交给Servlet处理（容器中如果没有相应的servlet就会先初始化–懒加载） servlet处理请求是调用的service方法，在SSM中我们通常会在web.xml中配置springMVC的DispatcherServlet用来处理所有请求(servletMapping为*)，这个servlet根据请求对象，将这个request封装成Spring框架中的request对象，从SpringMVC中找到对应Controller处理 a. 当初始化这个servlet会触发初始化SpringMVC容器，SpringMVC容器会初始化Spring容器，并将Spring容器设置为自己的父容器，这时候就是熟悉的Spring容器的加载 b. 这里SpringMVC容器里管理的时ControllerBean，Spring容器中管理端的是ServiceBean和DAOBean这些，（这些bean是创建顺序我还没研究，挖坑→_→）由于是父子关系SpringMVC可以访问Spring容器中的bean，反过来就不可以 这步就是熟悉的Controller层调用Spring容器中的Service逻辑，在调用DAO层逻辑持久化，将结果response返回给SpringMVC SpringMVC将response对象转为servlet规范里的response对象返回给servlet Servlet将response转化为Http的响应交给Web容器Tomcat，最终由Tomcat返回给浏览器]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[震惊!系统崩了竟然因为这个]]></title>
    <url>%2F2020%2F05%2F28%2F%E9%9C%87%E6%83%8A!%E7%B3%BB%E7%BB%9F%E5%B4%A9%E4%BA%86%E7%AB%9F%E7%84%B6%E5%9B%A0%E4%B8%BA%E8%BF%99%E4%B8%AA%2F</url>
    <content type="text"><![CDATA[菜鸟遇到线上问题，从第一次发现问题到问题解决用时2个月，也算是个记录吧，哈哈，本文记录下我解决问题的心路历程，也不是什么高级的问题，大神请绕路 第一次问题背景4月27日10:40-11:40一个尾数164的容器CPU突然飙升疯狂收到报警的邮件和消息 应对措施 查看后台日志有一个url在刷屏，条件反射的找到这个刷屏的人给他限流（因为之前有过类似的情况，用户通过程序发送url请求来获取数据，30秒之内精准限流，我也是老手了） 继续观察监控，调用量下来了，CPU迟迟不降，没有办法重启了容器 分析 CPU不降一定是还在做计算工作 排查被刷的url，是一个监控报表的url（由于系统只提供最大1小时的数据，临近618很多用户需要几天甚至几周的数据做分析，不得已通过程序来跑出自己所需的数据） 代码走查，是通过调用es的服务，获取数据，再封装成前端需要的数据返回，逻辑上是没问题的 获取数据：查的是es响应很快，2s之内就有数据 前端页面一共3个图，不论查询多少时间间隔的数据都只有90个点，3个图共270个点，也就是后台封装270个对象 整个过程也就封装对象是计算的过程需要CPU，难不成这个人用多个线程来跑这个url，这也太变态了吧 验证：7个任务，每个任务循环访问500次，查看监控CPU还不到5%，平常2%左右 处理 可以排除是获取监控数据这个URL的问题，当天回看日志没有发现其他异常，问了前辈之前也没出现过类似问题，而且手上还有需求就先搁置了；过了一周再排查的时候发现找不到历史日志了，因为刚刚迁移了环境历史日志没有打开，死无对证了。。。 也算排查了一个系统的风险点吧，最终，开启系统的历史日志，重新配置报警的阈值，等下次再出问题时摘除负载均衡，保留现场再做排查 第二次出现问题背景5月26日19:15前后，同样还是收到尾数164的容器CPU飙升的告警邮件，本以为上次的问题是个灵异事件，没想到又出现了，有了上次的经验，这次就很从容，将负载均衡摘除安心排查问题，可是一会又收到了同机房尾数是182的容器的报警邮件，群里的用户也开始反馈系统无法访问了，我愣住了，脑子里都是在想最近有做什么上线吗，是哪里出了问题；在我发愣的时候，前辈已经开始扩容，紧急扩容了4个容器这才稳住局势，这我才回过神来，我还是年轻😂 分析 经过上面的处理，下面就开始分析问题了，首先还是看日志没有发现异常，于是和运维同学要了dump文件，运维同学说dump不用看了，容器的jvm内存只有1G？？？想到当时迁移系统时没改配置，使用的是默认的配置，修改了内存配置后解决问题，完事儿！那我写这篇文章也太水了吧，哈哈 我要了dump文件，还是要看一下问题的，而且每次都是尾数164的容器出错，太诡异了 使用JProFiler分析dump，可以看到百万数量级的引用4类，结合最大的对象来看，是一个超大的list，占用了80%的内存 代码走查，list中的对象是事件的对象，用来同步数据用，类似消息队列，再结合日志来看，马上定位到了一个用户再操作实例的上线（更改实例中所有接口的状态，产生的事件是为了同步数据），并产生了300w+的事件，系统封装事件后终于把内存撑爆，进行FullGC，Stop The Word 查看日志和用户操作的记录，我寻思对一个实例操作怎么会有这么多事件，不会是有死循环了吧；先排查了不是多线程的问题 12345678910for (Server server : servers) &#123; // 外层循环生产事件 eventList.add(buildEvent(server)); for (IfaceAlias ifaceAlias : ifaceAliasList) &#123;// 内层循环与外层循环的数据一样 if (condition) &#123; eventList.add(buildEvent(ifaceAlias)); &#125; &#125;&#125;// 伪代码，只是为了展示代码结构 上线的逻辑是这样 a.数据库中修改实例的状态（两个sql用时3s内） b.封装要操作的事件 c.发送事件 （调用远程服务，远程服务没有接受到事件的日志，定位在b中出现问题） 步骤b中，嵌套了两层循环来生产事件，逻辑如下（以前代码的逻辑，为什么这么做就不知道了，前辈的东西先不动），我查了线上的数据，这个实例中有282个接口，两层循环也就8w不到的事件啊 验证：将线上数据拷贝下来，本地测试，产生6000+的事件也不到8w啊？debug后才知道，两层嵌套循环符合条件的只有77个（业务问题不需要关心），77*77+外层循环生产的事件刚好6000+数量级，这和线上的百万数量级差好多哦，这多出来的是从哪来的呢 想了两天没有结果，忍不住了，我找到用户的联系方式直接问，原来操作了20多个实例，发现用户操作的日志超长了，后面的内容截断了，让我以为就操作了一个实例 验证：按照25个实例来算，每个实例两层循环需要重新计算外层循环x内存循环（25x77）x（25x77）结果证实300w+的数量级，破案 总结主要问题还是迁移系统之后jvm设置的内存有问题，连带找出其他bug（以外收获） 封装事件代码有问题，两层嵌套循环产生很多重复事件（不是说之前写代码的人太水，而是业务复杂，刚好用户的数据结构特殊导致产生大量重复事件） 用户操作的日志记录不完整，误导了排查错误的方向，这是个风险 jvm内存设置的有问题，即使上面两个问题不修改，源码8g内存都用上的话运行5年的话也不会出问题 直接查看jvm的配置或者找用户了解情况就不会走这么多弯路，这条里就是经验了，本文的精华都在这一句了]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[AQS分析]]></title>
    <url>%2F2020%2F05%2F20%2FAQS%E5%88%86%E6%9E%90%2F</url>
    <content type="text"><![CDATA[AQS AbstraceQueuedSynchronizer 维护了一个共享变量state（int类型被volatile修饰保证线程的可见性） 通过不同线程修改state的状态来决定线程获取锁的状态，并将这些线程维护在一个队列里，每个线程都封装成一个Node对象 Node中定义了线程的状态 复制表示Node处于有效的等待状态，正值表示Node被取消 CANCELLED（1） 当前Node已经取消调度，超时或中断会变更为次状态，进入该状态后的Node不再变化 SIGNAL（-1）表示后继Node等待当前Node唤醒，后继Node入队，会修改前驱Node状态为SIGNAL CONDITION（-2）表示Node等待在Condition上，其他线程调用signal()方法后，CONDITION的Node会从等待队列中转移到同步队列，等待获取同步锁 PROPAGATE（-3）共享模式下，前驱节点不仅会唤醒后继Node，还可能唤醒后继的后继Node 0 新节点入队时的默认状态 定义了独占（Exclusive）和共享（share）两种对state的使用方式 独占 exclusive 只能一个线程操作state；使用 acquire-relase 方法获取和释放资源 acquire tryAcquire 根据需要具体实现 尝试获取资源，成功返回true，失败返回false 获取资源失败，将当前线程入队，找到安全点进入等待状态 当被唤醒后判断自己是否是队列中的老二，不是老二找到安全点进入等待状态；是老二尝试获取资源，获取失败继续进入等待状态，等待别唤醒 relase tryRelase 根据需要具体实现 尝试释放资源，成功返回true，失败返回false 当资源全部被释放后（state=0，可能被重入state的值大于0）会唤醒队列中的老二来获取资源 共享 share 多个线程可以同时操作state；使用 acquireShared-relaseShared 方法获取和释放资源 acquireShared tryAcquireShared 根据需要具体实现 尝试获取资源，负数表示失败；正数表示成功，数值表示剩余的资源数量 获取资源失败，将当前线程入队，入队后如果是老二节点尝试获取资源，老二节点获取资源成功，根据剩余资源量唤醒后面的线程 不是老二节点或者老二节点获取资源失败，找到安全点进入等待状态，等待被唤醒 relaseShared tryRelaseShared 根据需要具体实现 尝试释放资源，成功返回true，失败返回false 释放资源成功就去唤醒队列中的老二，老二被唤醒尝试获取资源进入到acquireShared中的第二步 总结 AQS其实是一个抽象的基于队列同步器（正如其名称所示，但是并没有使用抽象方法，而是将可扩展的方法默认抛出异常，留给子类去重写覆盖，可能是考虑到单独扩展共享模式或者独占模式，只需实现两个方法即可，不需要全都重写，根据需要选择重写，这样更灵活一些），其中封装了独占模式和共享模式下获取和释放资源的方法，其中没有给出tryAcquire-tryRelase和tryAcquireShared-tryRelaseShared的具体实现，可以根据需要重写这些方法即可，不需要去关心队列中线程的状态变化；比如ReentrantLock就是重写了独占模式中的方法实现；CountDownLatch是重写了共享模式中的方法实现 ReentrantLockReentrantLock中重写了tryAcquire和tryRelase，所有是独占模式，所以ReentrantLock是独占锁并且是可重入的，其中分别有公平和非公平两种实现，默认是非公平的 公平 lock() -&gt; acquire(1) 获取锁（修改资源的状态为1）其中使用的时AQS的实现 重写了tryAcquire方法，如果资源状态是空闲（state=0）并且队列中没有等待资源的线程，才会去获取资源；如果是当前线程获取资源，直接修改状态并获得锁成功（state += n；可重入；）；其他情况返回false获取资源失败 之后就是AQS中的逻辑 入队、等待被唤醒 balabala… 1234567891011121314151617181920212223242526272829// 公平锁的实现 Sync继承了AQSstatic final class FairSync extends Sync &#123; final void lock() &#123; acquire(1);// 获取资源，调用AQS中的 acquire(1) 方法 &#125; // AQS中的 acquire 方法调用了 tryAcquire 方法，在这里重写执行 protected final boolean tryAcquire(int acquires) &#123; final Thread current = Thread.currentThread(); int c = getState(); if (c == 0) &#123; // 当前资源空闲并且队列中没有等待资源的线程才会去CAS获取资源 if (!hasQueuedPredecessors() &amp;&amp; compareAndSetState(0, acquires)) &#123; setExclusiveOwnerThread(current); return true; &#125; &#125;// 如果是当前线程直接修改资源，返回成功；可重入 else if (current == getExclusiveOwnerThread()) &#123; int nextc = c + acquires; if (nextc &lt; 0) throw new Error(&quot;Maximum lock count exceeded&quot;); setState(nextc); return true; &#125; eturn false; &#125;&#125; 非公平 lock -&gt; 抢占锁（CAS修改资源状态） -&gt; 抢锁失败调用acquire(1)获取锁，同样适用AQS的实现 重写了tryAcquire方法，如果资源状态是空闲（state=0）就CAS修改状态的值获取资源；如果是当前线程获取资源，修改状态获取资源成功（与公平锁相同，CAS修改state，可重入）；其他情况返回false获取资源失败 （相同逻辑）入队、等待被唤醒 balabala… 12345678910111213141516171819202122232425262728293031323334// Sync继承了AQSstatic final class NonfairSync extends Sync &#123; final void lock() &#123; // lock的时候抢占一次资源 if (compareAndSetState(0, 1)) setExclusiveOwnerThread(Thread.currentThread()); else acquire(1);// 没抢占到调用 acquire 方法（AQS中） &#125; // AQS中的 acquire 方法调用了 tryAcquire 方法，在这里重写执行 protected final boolean tryAcquire(int acquires) &#123; return nonfairTryAcquire(acquires);// 父类中实现 &#125;&#125;final boolean nonfairTryAcquire(int acquires) &#123; final Thread current = Thread.currentThread(); int c = getState(); if (c == 0) &#123;// 与公平锁的实现不同，这资源空闲会再抢占一次资源 if (compareAndSetState(0, acquires)) &#123; setExclusiveOwnerThread(current); return true; &#125; &#125;// 与公平锁一样 可重入 else if (current == getExclusiveOwnerThread()) &#123; int nextc = c + acquires; if (nextc &lt; 0) // overflow throw new Error(&quot;Maximum lock count exceeded&quot;); setState(nextc); return true; &#125; return false;&#125; 总结 公平锁和非公平锁释放资源都使用的父类中的 tryRelase 方法，简单的逻辑，确认当前线程在占用资源后cas修改资源的状态，返回资源是否空闲（state==0?）其他逻辑和AQS中的 relase 相同 可以看到斜体的地方就是公平锁和非公平锁的区别，在资源状态空闲的时候，非公平锁会去抢占资源而公平锁判断队列中没有等待资源的线程才会去获取资源；还有在Acquire之前非公平锁会去抢占一次资源；非公平锁会在lock的时候抢占资源，没有抢到会执行tryAcquire方法，如果此时刚好资源被释放还会去抢占一次资源，都失败了就会入队进入等待状态 共享模式的实现本来想找一个共享模式的实现来分析一下，在AQS中查到实现有这么几个，Semaphore、CountDownLatch和ReentrantReadWriteLock，前两个比较简单来分析一下，后一个比较复杂段时间还搞不定（柿子要挑软的捏是不是？这里再挖个坑吧） SemaphoreSemaphore用来控制线程的并发量，指定并发量就是Semaphore中的许可，拿到许可可以运行，没有拿到许可进入等待状态，有释放的许可唤醒等待的线程，保证线程运行的数量，类似于令牌桶的亚子；其中重写了 tryAcquireShared 和 tryRelaseShared 方法，所以Semaphore是共享模式的实现，同样有公平和非公平两种方式，默认非公平的； acquire 获取许可 -&gt; 调用 acquireSharedInterruptibly 方法，与acquireShared不同的是先判断线程的中断状态，如果中断抛异常， 调用 tryAcquireShared 方法获取资源（公平模式下线判断队列中是否有等待资源的线程，有则返回-1表示失败；没有返回剩余资源数量，获取资源成功；非公平模式下不用判断队列是否有线程直接去获取资源，返回剩余的资源），后面同AQS中的逻辑 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556// 构造方法初始化AQS的state为permit的数量public Semaphore(int permits) &#123; sync = new NonfairSync(permits);&#125;// 转调AQS中 acquireSharedInterruptibly 方法public void acquire() throws InterruptedException &#123; sync.acquireSharedInterruptibly(1);// AQS中的实现&#125;public final void acquireSharedInterruptibly(int arg) throws InterruptedException &#123; if (Thread.interrupted()) throw new InterruptedException(); if (tryAcquireShared(arg) &lt; 0)// 这里调用 tryAcquireShared 方法 doAcquireSharedInterruptibly(arg);&#125; // 非公平模式下转调 nonfairTryAcquireShared 方法protected int tryAcquireShared(int acquires) &#123; return nonfairTryAcquireShared(acquires);&#125;final int nonfairTryAcquireShared(int acquires) &#123; for (;;) &#123; int available = getState(); int remaining = available - acquires;// 获取资源后的余量 if (remaining &lt; 0 || compareAndSetState(available, remaining))// 余量大于0 CAS修改状态获取资源成功 否则执行AQS中剩下的逻辑 入队、等待... return remaining; &#125;&#125;// 公平模式下直接重写 tryAcquireShared 方法protected int tryAcquireShared(int acquires) &#123; for (;;) &#123; if (hasQueuedPredecessors())// 比非公平模式多了判断队列中是否有等待的线程 return -1; int available = getState(); int remaining = available - acquires; if (remaining &lt; 0 || compareAndSetState(available, remaining)) return remaining; &#125;&#125;// relase 方法转调AQS中的 relaseShared 方法public void release(int permits) &#123; if (permits &lt; 0) throw new IllegalArgumentException(); sync.releaseShared(permits);// 其中调用 tryRelaseShared 方法&#125;// 重写 tryRelaseShared 方法(公平非公平相同) 循环CAS改变状态，判断边界范围protected final boolean tryReleaseShared(int releases) &#123; for (;;) &#123; int current = getState(); int next = current + releases; if (next &lt; current) // overflow throw new Error(&quot;Maximum permit count exceeded&quot;); if (compareAndSetState(current, next)) return true; &#125;&#125; CountDownLatchCountDownLatch通常用来判断多个线程是否都执行完毕，初始化的时候将AQS中的state设置为等待的线程数量（n），表示资源被n个线程获取； await方法转调acquireSharedInterruptibly其中又转调 tryAcquireShared ，返回state是否为0，因为初始化为n所以不为0返回-1，表示获取资源失败将线程入队等待 线程执行完毕后调用countDown方法，转调relaseShared方法将资源的数量减一，当所有线程都调用了countDown此时资源被完全释放（state=0）线程被唤醒，再次 tryAcquireShared 获取state为0返回0，表示获取资源成功，执行后面的逻辑 123456789101112131415161718192021222324252627282930313233343536373839// 构造方法初始化AQS的state为count；Sync继承AQSpublic CountDownLatch(int count) &#123; if (count &lt; 0) throw new IllegalArgumentException(&quot;count &lt; 0&quot;); this.sync = new Sync(count);&#125;// 转调AQS中 acquireSharedInterruptibly 方法public void await() throws InterruptedException &#123; sync.acquireSharedInterruptibly(1);// AQS中的实现&#125;public final void acquireSharedInterruptibly(int arg) throws InterruptedException &#123; if (Thread.interrupted()) throw new InterruptedException(); if (tryAcquireShared(arg) &lt; 0)// 这里调用 tryAcquireShared 方法 doAcquireSharedInterruptibly(arg);&#125;// 重写了 tryAcquireShared 方法protected int tryAcquireShared(int acquires) &#123; // state为0返回1表示获取资源成功，不为0返回-1表示获取资源失败 // 由于刚刚初始化了state=count，假设当前还没有释放资源，state不为0返回-1表示失败，后面就是AQS中的逻辑，入队、等待... return (getState() == 0) ? 1 : -1;&#125;// countDown 方法转调 relaseShared 方法public void countDown() &#123; sync.releaseShared(1);// AQS中的实现 其中调用了 tryRelaseShared 方法&#125;// 重写了 tryRelaseShared 方法，如果state-1之后还不为0返回false表示释放失败，其实是成功的，返回失败是因为还要等待其他线程// 先不去唤醒等待的线程，当释放资源后state为0返回成功，这时候再去唤醒等待的线程protected boolean tryReleaseShared(int releases) &#123; // 循环CAS操作将state-1 for (;;) &#123; int c = getState(); if (c == 0) return false; int nextc = c-1; if (compareAndSetState(c, nextc)) return nextc == 0; &#125;&#125; 参考文献Java并发之AQS详解]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ThreadLocal分析]]></title>
    <url>%2F2020%2F05%2F19%2FThreadLocal%E5%88%86%E6%9E%90%2F</url>
    <content type="text"><![CDATA[废话不说，直接开整，上源码 Java中每个Thread类中都有属于自己的私有map（ThreadLocalMap key是ThreadLocal的弱引用），不同线程之间的map是私有的相互隔离 12345public class Thread implements Runnable &#123; ... ThreadLocal.ThreadLocalMap threadLocals = null; ...&#125; set方法 计算hash值，找到table中对应的位置，key是null直接放入，key相同替换，key冲突后向后查找直到找到可以插入的地方 从这个插入的方式可以看出，table中的桶对应一个entry，与HashMap中的链表或者红黑树不同，而且到达3/4的容量就会扩容，所以不会存在，桶中有链表或者红黑树的数据结构 插entry后 cleanSomeSlot 从当前插入entry的位置，往后扫描找key为null的entry，找logn次（who tell me 这是 why？）找到key为null的entry（可能1个可能多个） expungeStaleEntry(i) 方法清理 expungeStaleEntry(i) 清理从i开始往后到下一个entry是null之间的位置 如果找到key为null的entry，并且经过清理之后tab的数量还大于扩容的阈值，调用 rehash 方法扩容 expungeStaleEntries() 清理整个table中key是null的entry，清理之后tab的size大于扩容的阈值 进行 resize （扩容的逻辑） 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152public void set(T value) &#123; Thread t = Thread.currentThread(); ThreadLocalMap map = getMap(t); if (map != null) map.set(this, value); // 进入这里 else createMap(t, value);&#125;private void set(ThreadLocal&lt;?&gt; key, Object value) &#123; Entry[] tab = table; int len = tab.length; int i = key.threadLocalHashCode &amp; (len-1); for (Entry e = tab[i]; e != null; e = tab[i = nextIndex(i, len)]) &#123; ThreadLocal&lt;?&gt; k = e.get(); // key相同替换 返回 if (k == key) &#123; e.value = value; return; &#125; // key为null替换 返回 if (k == null) &#123; replaceStaleEntry(key, value, i); return; &#125; &#125; // 找到entry为null的位置插入 tab[i] = new Entry(key, value); int sz = ++size; // cleanSomeSlots清理一部分entry后size还大于阈值进行扩容 if (!cleanSomeSlots(i, sz) &amp;&amp; sz &gt;= threshold) rehash();&#125; // 如函数名所说，清理一部分Solts（key为null的entry），具体的说清理从i到下一个entry是null之间的部分private boolean cleanSomeSlots(int i, int n) &#123; boolean removed = false; Entry[] tab = table; int len = tab.length; do &#123; i = nextIndex(i, len);// 从i开始往下遍历，遍历logn次 Entry e = tab[i]; if (e != null &amp;&amp; e.get() == null) &#123;// 找到key是null的entry n = len; removed = true; i = expungeStaleEntry(i);// 清理从i开始到entry为null的位置 并且对key不为null的entry做rehash 代码就不贴了 &#125; &#125; while ( (n &gt;&gt;&gt;= 1) != 0);// 每次n/2 遍历logn次 return removed;&#125; get方法 调用threadLocalMap中的getEntry方法，通过hash值找到tab中的位置，当前位置没找到调用 getEntryAfterMiss 方法 getEntryAfterMiss 从当前位置往后找到key的entry返回 12345678910111213141516171819202122232425262728293031323334353637383940public T get() &#123;Thread t = Thread.currentThread();ThreadLocalMap map = getMap(t);if (map != null) &#123; ThreadLocalMap.Entry e = map.getEntry(this);// 进入这里看看 if (e != null) &#123; @SuppressWarnings(&quot;unchecked&quot;) T result = (T)e.value; return result; &#125;&#125;return setInitialValue();// map为空set初始值&#125; private Entry getEntry(ThreadLocal&lt;?&gt; key) &#123; int i = key.threadLocalHashCode &amp; (table.length - 1); Entry e = table[i]; if (e != null &amp;&amp; e.get() == key) return e; else return getEntryAfterMiss(key, i, e); // hash后的位置没找到key&#125; // 从当前位置向后找 过程中遇到key为null的 entry 调用expungeStaleEntry(i)进行清理private Entry getEntryAfterMiss(ThreadLocal&lt;?&gt; key, int i, Entry e) &#123; Entry[] tab = table; int len = tab.length; while (e != null) &#123; ThreadLocal&lt;?&gt; k = e.get(); if (k == key) return e; if (k == null) // 遇到key是null的entry进行清理 expungeStaleEntry(i);// 与set过程中调用同一方法，清理从i到下一个key为null节点之间的位置 else i = nextIndex(i, len); e = tab[i]; &#125; return null;&#125; 内存溢出问题 ThreadLocal的结构如图所示，因为new ThreadLocal对象，所有栈中有ThreadLocal的强引用，而ThreadLocalMap中key是ThreadLocal的弱引用，如果将ThreadLocal对象置为null，则ThreadLocal只有弱引用指向它，当下次gc的时候key会被回收掉 如果当前线程没有退出，value依然有强引用指向它，所以value并不会被回收，虽然经过分析源码使用get和set方法会清理map中的key为null的一部分节点清理掉，但是在调用get和set之前仍然存在oom的风险 最稳妥的就是使用remove方法，将不需要的ThreadLocal清理掉 不要和线程池一起使用，线程池中的线程是复用的，永远不会被销毁，所以线程中的ThreadLocalMap也不会被清理，如果这个线程一直不被使用或者不在调用get和set方法，这块内存永远不会被回收 挖坑 根据nextIndex方法里的实现来看，这个结构是一个环形结构 private static int nextIndex(int i, int len) { return ((i + 1 &lt; len) ? i + 1 : 0); } 参考文献中所说，hash算法使用黄金分割数，大大降低了hash冲突的几率，具体怎么降低的先挖个坑后面再填 参考文献一篇文章彻底了解ThreadLocal的原理]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[get限流姿势]]></title>
    <url>%2F2020%2F05%2F14%2Fget%E9%99%90%E6%B5%81%E5%A7%BF%E5%8A%BF%2F</url>
    <content type="text"><![CDATA[限流通常用作服务的降级策略，以牺牲一部分请求的方式换来系统的部分可用；在高并发的场景下保护系统不会挂掉，比如大促、秒杀这类的场景保护像交易这样的核心服务可用，通过学习限流的代码之后，掌握了通常的限流姿势，分享一下 计数器类似于滑动窗口，给定一个时间段的最大请求数（窗口，比如1秒最多100个请求），再将窗口设置多个小段（一个时间的偏移量，比如100ms，一个窗口就被分成了10小段）每一小段记录当前正在处理的请求数量，每次移动一小段，滑出的一段中的请求数量被释放，新进入窗口的一段最多可以处理被释放的请求数量 总结 简单粗暴好实现，偏移量取值越小限流越精细，每次滑动需要获取当前一段中的请求数，计算窗口中的总的请求数是否超过限定值 如果在中间一小段涌入大量请求到达限定值，那就需要等待这段滑出窗口后才能处理新的请求，从宏观的角度来说，可以保证窗口期内的平均处理请求的量，但是从微观来看处理请求的方式不均衡，存在风险 漏桶算法一个破桶一边以一个速度漏水（处理请求）一边以一个速度往里加水（新的请求到来）；假设向桶里加水的速度很快（大量新的请求到来）一会就把桶占满了，此后再向桶里加水就会漏出去（新的请求会被丢弃） 实现12345678910111213// 生产者和消费者// 用阻塞队列来实现桶BlockingQueue bucket = new BlockingQueue(MAX_SIZE);// 请求来 -&gt; 入队if (!bucket.offer();&#123; // 大于桶的最大值入队失败，做进一步操作（拒绝、保存到mq或者db中）&#125;while (true) &#123; bucker.take(); // 出队成功 异步处理请求 等待下一个周期后再次从队列中获取请求，队列为空阻塞在原地 sleep(10);&#125; 总结 通过计算每次请求的最小时间间隔，当大量的请求到来时让系统以一个恒定的速度去处理请求，保护系统不会被超过本身处理能力的请求打挂 不足之处是不够优雅；当某个时间点有大量的请求到来很快将桶塞满，多于的请求直接丢弃，而突然有大量请求的场景有很多（例如秒杀，大促等）这些都是正常的请求，不应该被丢弃； 令牌桶以一个速度向桶里生产令牌，当桶内令牌满了时将暂停生产，处理请求需要从桶里拿到令牌才可以，如果桶里没有令牌拒绝该请求（通常的做法是返回一个限流信息，类似于非阻塞的方式） 实现12345678910111213141516171819202122232425262728// 一个请求周期的类class Cycle&#123; lastTime;// 上一次请求的时间戳 curTokenCount;// 当前桶内有效token数量&#125;public boolean getLicense() &#123; // 是否可以执行请求 boolean license = false; do &#123; // 请求到来，计算从限流开始到现在的时间间隔，通过当前时间戳-开始时间戳 curTime = currentTime - startTime; // 计算从上一次请求开始到现在的时间间隔，lastTime是从限流开始到上一次请求的时间间隔 curDuration = curTime - lastTime; // 计算这段时间产生的令牌数量 incrementTokenCount = curDuration * createTokenSpeed; // 计算当前时间内有效的token数量 curTokenCount是当前桶里的token数量 curTokenCount = Min(maxTokenCount, currentTokenCount + incrementTokenCount); // 如果有效的token数量大于0，数量减一处理请求， if (curToken &gt; 0) &#123; incrementTokenCount--; license = true; &#125; lastTime = curTime; &#125; while (!CAS(curCycle, new Cycle(lastTime, curTokenCount)));// CAS操作设置当前请求周期为下一个周期，操作成功进入下一周期，返回是否可以执行请求 // 要进入下一周期需要CAS操作lastTime和curTokenCount两个变量，分别CAS不能保证一致性，所以封装成一个对象做CAS操作 return license;&#125; 总结 相较与漏桶算法，令牌桶可以应对一些突发流量的变大，最大同时处理令牌桶中最大令牌数量的请求，所有设置令牌桶中最大令牌数量要非常小心，否则会把服务器压垮 Guava中实现了漏桶算法的限流器，还具有一定的超额消费的能力，更灵活了一下，具体实现原理也差不多，可以直接用 以上是单机模式下的限流实现，只需要拦截每次请求，执行上面的逻辑根据是否满足条件决定处不处理请求，分布式环境下的限流可以使用lua+redis来实现]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[初识Guava Cache]]></title>
    <url>%2F2020%2F05%2F11%2F%E5%88%9D%E8%AF%86Guava%20Cache%2F</url>
    <content type="text"><![CDATA[背景随着系统的膨胀，数量越来越大，统计报表的相关SQL会非常慢，代表的SQL是这样，需要统计两张表中不重复的ip，大概是2000w两级，只能两张表分别distinct，最后union的时候再distinct一下，没想到更好的办法，只能加缓存了 考虑过使用Redis，这是常规的做法，可是要缓存的数据很少，结构简单，访问量不大通常是管理员来查看统计一下产品的使用情况，使用Redis逻辑复杂，还要考虑缓存击穿，缓存雪崩的情况，还依赖于Redis的可用性，所以决定舍弃该方案，使用Guava Cache来做缓存，并在时间间隔内进行缓存数据的更新 Guava Cache虽然提供缓存的过期时间，但是只有在过期之后的一次get才会进行缓存的更新，而且如果获取缓存的时间很长会造成阻塞，这样缓存的意义就没了； 如果设置成异步刷新缓存，可以解决阻塞的问题，但是得到的时上一个时间周期的数据，缓存的实时性不能保证； 最终采用开启定时的线程，在每个时间周期内异步刷新缓存数据，最坏的情况是得到上一个时间周期的数据，但是可以解决上一条中多次点击才会刷新的点，这里还有一个风险点，如果多个服务器在同一时间启动，就会在相同的时间间隔去请求数据库计算数据并更新，可能造成数据库CPU忙碌状态，我的环境是4台服务器，并发的去请求数据库是没问题的，而且通常都是滚动更新，所以不会出现这个问题，综合评估后采用该方案 实现 在Spring容器启动完毕的时候（这里有个坑，因为spring容器没有启动完成是不能与数据库建立连接的，所以在spring容器启动过程中就加载缓存是不行的），开启线程统计数据（要查从库避免锁表） 再通过定时任务异步去刷新数据 Guava Cache 编码过程中那个通常缓存的实现是定义一个全局变量，多个线程都可以访问到，并可以对该变量进行修改；当然需要用到线程安全的数据结构，比如ConcurrentHashMap，但是缓存的更新删除，这些逻辑的自己实现，而我理解的Guava Cache就是封装了这些逻辑并提供出API的一个工具 缓存过期的设置方式 设置缓存的大小，超过阈值的删除（这里指的是缓存的数量，key的数量） 设置缓存的时间，超过时间的删除 不是定时去判断的，而是get的时候会判断是否超时，超时就重新加载，这样如果刷新key的用时很长的话会阻塞；Guava Cache也提供了异步刷新key的方式，这样如果对缓存更新实时性要求高的话，在缓存刷新后重新get才能获得最新的缓存值；或者用一个定时任务异步刷新key 设置弱引用，让垃圾收集器来回收 显式的删除key 可以添加key被删除的监听器 使用了类似jdk1.7中ConcurrentHashMap的Segment的结构，降低锁的粒度提高并发的吞吐量；再通过两次hash找到value的位置 相关知识 强引用 通过 new 关键字产生，不会被JVM回收；如果是局部变量，引用保存在线程栈中，方法结束引用被依赖的数量为0，将会被JVM回收掉；如果是全局变量，引用将一直会存在，可以将引用设置为null被JVM回收 软引用 内存充足时不会被回收，当内存空间不足会被回收 弱引用 JVM进行垃圾回收的时候就会被回收掉，如果长时间不进行垃圾回收就会一直存在 虚引用 必须与引用队列一起使用，在JVM进行垃圾回收之前，虚引用会被加入到引用队列中 引用队列 可以和软引用，弱引用，虚引用联合使用，在JVM进行垃圾回收之前，要被回收的引用会被加入到队列中，用来查看JVM垃圾回收情况 ConcurrentHashMap HashMap jdk1.7 数组+链表的结构 当有hash冲突的时候链表会很长，查询一个节点效率很低，时间复杂度为O(N) jdk1.8 数组+红黑树的结构 链表中节点大于8时会转成红黑树，查询时间复杂度为O(logN) put 判断是否需要扩容（resize）或者初始化（懒加载） 通过hash找到桶，没有冲突直接放入； 有hash冲突，a.判断是否和第一个Node的key相同，相同则覆盖value；b.判断是否是红黑树，插入value相同key覆盖 c.判断是否需要转红黑树，需要则红黑树插入，否则插入链表末尾，相同key覆盖value， 插入value后判断是否需要扩容 get 根据hash值找到桶，从桶中找key对应的value，没有返回null resize 1.8不会进行重新hash，而是看hash值新增的那个bit位是1还是0，0位置不变，1的话位置是原位置+扩容前容量 索引中的位置，由于hash值新增的那个bit为可以认为是随机的，所以可以将原来桶中的链表或者红黑树均匀的拆分成两个链表或者红黑树 线程不安全问题 1.7 可能丢失key，还会出现循环链表，当get一个不存在的key出现死循环 1.8 由于table中size变量没有加volatile关键字，多线程++size时可能覆盖以前的记录 线程不安全主要是由于resize方法导致，1.7先rehash转移数据在改数组的引用，而且转移数据后链表会反转多线程并发修改引用会造成循环链表的现象；1.8先改数组的引用再转移数据，并且转移数据不会修改链表的结构，理论上不会造成循环引用，但当多线程并发操作会出现数据丢失的现象 concurrentHashMap 1.7 引入segment的概念，将整个table划分成若干个segment，对segment加锁减小锁的粒度提高吞吐量，get的时候先通过hash找到segment，再找到对应的table中的位置 1.8 对Node加锁进一步减小了锁的粒度提高吞吐量，加入多线程扩容的逻辑加速扩容的过程，put操作时发现正在扩容可以帮助扩容，而不是阻塞起来傻等 扩容的逻辑很复杂，整理一下大概的逻辑吧，首先将CAS操作将table扩容，根据原来table的大小将扩容工作拆成多个任务，每个任务最少迁移16个桶，当线程完成扩容任务会继续领取下一个任务进行扩容 多线程领取任务开始扩容，安装索引从大到小的顺序开始，扩容过程中get操作，会get到ForwardNode，转发到新的table中查找value；扩容过程中put操作，如果当前扩容的线程数量小于最大限制的数量就加入扩容的队列中，否则阻塞 put 使用synchronized关键字对Node加锁；当Node中的链表大于8，如果当前容量没有超过64先进行扩容，否则才转红黑树；扩容过程中红黑树节点小于6个转链表]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[将Hexo博客迁移到docker中（究极解决方案）]]></title>
    <url>%2F2020%2F04%2F19%2F%E5%B0%86Hexo%E5%8D%9A%E5%AE%A2%E8%BF%81%E7%A7%BB%E5%88%B0docker%EF%BC%88%E7%A9%B6%E6%9E%81%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88%EF%BC%89%2F</url>
    <content type="text"><![CDATA[前两个阶段是两个月前的试验版本，只是在本机上用docker模拟并没有真正做迁移，然而在真正迁移的过程中，虽然可以完整迁移，但是体验不友好，我改进了迁移方案，首先总结一下缺点吧 启动容器后需要进入容器中，启动nginx做转发 如果不使用也需要进入容器中启动hexo，且不能退出否则hexo也会跟着退出 后台启动需要依赖pm2这个工具 后台启动hexo和nginx会不会有资源争抢的问题，这个应该没有纯属给自己加戏 修改文章后即使做了文件挂载也需要进入容器中重新生成静态文件 图解一下，原来的方案和现在的方案 可以看到原来是塞到一个docker容器中的，中间的图是现在的架构，将nginx和hexo拆分，分别放入docker中，nginx的docker转发请求到hexo的docker，hexo的docker需要运行hexo s；未来如果我有新的网站可以重新部署一个容器通过nginx做转发，比如，不同域名转发到不同的容器，或者我再搞一个WordPress版本的docker，还可以做金丝雀发布，ab测试。哈哈 下面开始动手 先从nginx开始12345# 直接拉取nginx镜像docker pull nginx# 修改配置文件运行 把配置文件做目录挂载 绑定80端口docker run -di nginx --name nginx -v /usr/local/temp/nginx.conf:/etc/conf/nginx/nginx.conf -p 80:80 nginx# 之后配置有变化修改 nginx.conf 后 docker restart 即可 hexo与之前的版本不同的是，我要在容器启动的时候就把hexo运行起来，每次修改文件后docker restart就能重新生成静态文件并启动hexo 坑点 刚开始我再dockerfile中添加命令 CMD[‘hexo’,’s’] 编译好的镜像run了之后并没有启动，查看状态run了之后就退出了 我的第一反应是不是要后台启动才可以，随即有尝试使用 pm2 后台启动，修改命令CMD[‘pm2’,’start’,’run.js’] 还是不行呢，冷静下来发现不管是hexo还是pm2都是nodejs中的命令，而dockerfile中运行的应该是sh脚本 于是转换思路 dockerfile中启动shell脚本，脚本中运行hexo 修改命令 CMD [“/usr/local/myblog/buildbak/run.sh”] 还有一个小坑，运行起来会报没有权限的错误 再添加命令赋权 重新build就完成了 chmod 777 /usr/local/myblog/buildbak/run.sh run.sh 很简单，每次clean后重新生成静态文件再启动hexo，这样每次新增或者修改博客的时候restart就好了 12345#!/bin/shcd /usr/local/myblog;hexo clean;hexo g;hexo s 完整dockerfile 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586FROM centos:7MAINTAINER yywang sbsbjs@qq.com# 安装依赖RUN yum update -y &amp;&amp; yum install -y wget git-core vim* gcc-c++ pcre pcre-devel zlib zlib-devel openssl openssl-devel \# 安装nodejs# 新建目录 WORKDIR /usr/local# 下载tarRUN wget https://nodejs.org/dist/v12.15.0/node-v12.15.0-linux-x64.tar.xz \# 解压&amp;&amp; tar -xvf node-v12.15.0-linux-x64.tar.xz \&amp;&amp; mv node-v12.15.0-linux-x64 node_12.15.0 \&amp;&amp; mkdir /usr/local/nodejs \&amp;&amp; mv node_12.15.0 /usr/local/nodejs/ \&amp;&amp; rm -rf node-v12.15.0-linux-x64.tar.xz \# 部署bin文件&amp;&amp; ln -s /usr/local/nodejs/node_12.15.0/bin/node /usr/local/bin/node \&amp;&amp; ln -s /usr/local/nodejs/node_12.15.0/bin/npm /usr/local/bin/npm \# 修改npm源&amp;&amp; npm config set registry https://registry.npm.taobao.org \# 安装hexo&amp;&amp; npm install -g hexo-cli \# 配置环境变量&amp;&amp; ln -s /usr/local/nodejs/node_12.15.0/bin/hexo /usr/local/bin/hexo \# 创建网站文件夹&amp;&amp; mkdir /usr/local/myblog \&amp;&amp; cd /usr/local/myblog \# 初始化hexo&amp;&amp; hexo init \&amp;&amp; hexo generat \# 安装依赖RUN yum update -y &amp;&amp; yum install -y zlib-devel bzip2-devel openssl-devel ncurses-devel sqlite-devel readline-devel tk-devel gcc make \# 备份原始的python&amp;&amp; mv /usr/bin/python /usr/bin/python.bak \# 下载解压&amp;&amp; cd /usr/local \&amp;&amp; wget https://www.python.org/ftp/python/3.6.2/Python-3.6.2.tar.xz \&amp;&amp; tar -xvJf Python-3.6.2.tar.xz \# 编译安装&amp;&amp; cd Python-3.6.2 \&amp;&amp; ./configure prefix=/usr/local/python3 \&amp;&amp; make &amp;&amp; make install \&amp;&amp; rm -rf /usr/local/Python-3.6.2.tar.xz \# 添加软链&amp;&amp; ln -s /usr/local/python3/bin/python3 /usr/bin/python3 \&amp;&amp; ln -s /usr/local/python3/bin/pip3 /usr/bin/pip3 \# 安装依赖&amp;&amp; pip3 install Pillow \# 迁移博客 由于clone速度极其慢，而且还需要添加git秘钥，改用本地先clone好复制过去&amp;&amp; rm -rf /usr/local/myblogCOPY myblog /usr/local/myblog/# 安装package.json中的依赖# 修改下载源，安装更快RUN npm install hexo --save \&amp;&amp; npm install hexo-admin --save \&amp;&amp; npm install hexo-deployer-git --save \&amp;&amp; npm install hexo-generator-archive --save \&amp;&amp; npm install hexo-generator-baidu-sitemap --save \&amp;&amp; npm install hexo-generator-category --save \&amp;&amp; npm install hexo-generator-feed --save \&amp;&amp; npm install hexo-generator-index --save \&amp;&amp; npm install hexo-generator-search --save \&amp;&amp; npm install hexo-generator-searchdb --save \&amp;&amp; npm install hexo-generator-sitemap --save \&amp;&amp; npm install hexo-generator-tag --save \&amp;&amp; npm install hexo-helper-live2d --save \&amp;&amp; npm install hexo-renderer-ejs --save \&amp;&amp; npm install hexo-renderer-marked --save \&amp;&amp; npm install hexo-renderer-stylus --save \&amp;&amp; npm install hexo-server --save \&amp;&amp; npm install hexo-tag-cloud --save \&amp;&amp; npm install hexo-wordcount --save \# 重新生成静态文件&amp;&amp; cd /usr/local/myblog \&amp;&amp; hexo clean \&amp;&amp; hexo g \&amp;&amp; chmod 777 /usr/local/myblog/buildbak/run.sh# 环境搭建完成，启动脚本CMD [&quot;/usr/local/myblog/buildbak/run.sh&quot;] build好镜像后，运行容器 1docker run -di -v /usr/local/temp/myblog/source/_posts/:/usr/local/myblog/source/_posts/ -v /usr/local/temp/myblog/source/images/:/usr/local/myblog/source/images/ --name myblog -p 22000:4000 myblog:final 启动起来后查询dockerip 1docker inspect --format=&apos;&#123;&#123;.NetworkSettings.IPAddress&#125;&#125;&apos; myblog 修改nginx.conf 将请求转发到docker的4000端口，重启nginx容器，完美结束，最后把阿里云上的域名的规则修改为新的服务器的ip，成了 每次修改或者新增文件，重启hexo容器就可以了，最后别忘了提交文件到github中做备份 后续 将Dockerfile nginx.conf run.sh 复制到myblog中，提交到github中做备份 将最终的镜像上传至阿里云 如果容器没有变化迁移环境的话直接，从阿里云拉取镜像运行即可 如果内容变化就要先提交最新状态到github中，在新的环境中clone仓库，重新build镜像运行即可]]></content>
      <categories>
        <category>容器</category>
      </categories>
      <tags>
        <tag>容器</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[揭秘京东微服务框架的负载均衡算法]]></title>
    <url>%2F2020%2F03%2F27%2F%E6%8F%AD%E7%A7%98%E4%BA%AC%E4%B8%9C%E5%BE%AE%E6%9C%8D%E5%8A%A1%E6%A1%86%E6%9E%B6%E7%9A%84%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E7%AE%97%E6%B3%95%2F</url>
    <content type="text"><![CDATA[在京东广泛使用的微服务框架是JSF(Jingdong Service Framework)，中文名叫杰夫，今天给大家分享一下JSF的负载均衡算法。先串一下服务调用的过程，consumer在向provider发起远程调用之前会从注册中心拿到自己订阅的provider列表，然后和列表中的provider建立连接缓存起来，当发起调用的时候会从缓存的provider中选择一个进行调用，从多个provider选择一个进行调用，那么具体选择哪一个就用到了负载均衡算法，下面分别介绍一下JSF中的负载均衡算法： 随机 无权重或权重相等则从provider列表中随机选择一个发起调用； 有权重，假定总的权重值为x，随机生成[0-x)的偏移量，然后遍历减去provider列表的权重，当偏移量为负是选择当前的provider发起调用 附伪代码 12345678910111213// ...初始化总权重值totalWeight和权重是否相同sameWeight,length为providerList长度if (totalWeight &gt; 0 &amp;&amp; !sameWeight) &#123; offset = random.nextInt(totalWeight);// 偏移量 for (item : providerList) &#123; offset -= item.getWeight(i); if (offset &lt; 0) &#123; return item &#125; &#125;&#125; else &#123;// 没有权重或权重相同随机选择 return providerList.get(random.nextInt(length));&#125; 算法复杂度分析： 有权重值或无权重值都需要先初始化总权重值及权重值是否相等的变量复杂度为O(n)；没有权重值随机选择一个发起调用复杂度为O(1)；有权重值且权重值不同通过偏移量随机选择的复杂度为O(n)；无权重时的复杂度为O(n)，有权重时总的复杂度为2O(n) 轮询 无权重，方法级别的轮询，方法的调用次数和provider列表数量取余的结果为选择的provider 有权重，在无权重的基础上，将调用次数和providerList中最大权重值取余，在List中筛选权重值大于余数的provider，最后调用次数和筛选结果长度取余的结果就是最终选择的provider 取余的操作是让结果在[0-被取余数)之间循环，第一次和最大权重取余，是让权重从小到大循环起来；第二次在筛选的结果中取余，就是在权重值大于第一次余数的结果中循环选择 eg：第一次取余的结果大，筛选出来的List就相对较小，且List都是权重较大的provider，第二次取余是在权重较大的provider中进行轮询选择；反之，第一次取余的结果小，筛选出来的List相对较大，第二次取余是在相对较大的List中进行轮询选择；这样在轮询的基础上保证权重值大的provider的节点有更多次机会被轮询到 验证一下这个算法：假设有3个Provider A、B、C，他们的权重分别为3、3、4，进行10次调用试一下，每一行的结果分别为 调用次数、%最大权重、筛选出List长度、调用次数%List长度、最后选择 0 0 3 0 A 1 1 3 1 B 2 2 3 2 C 3 3 1 - C 4 0 3 1 B 5 1 3 2 C 6 2 3 0 A 7 3 1 - C 8 0 3 2 B 9 1 3 0 A 可以看到结果10次调用，基本是轮询的状态，而且权重为4的C节点被调用4次 附伪代码 1234567891011// key = className+alias+method// 初始化最小和最大权重 minWeight maxWeightif (maxWeight &gt; 0 &amp;&amp; minWeight &lt; maxWeight) &#123; currentWeight = count % maxWeight; subList = getSubList(providerList);// 选择权重大于当前权重的子集 return subList.get(count%subList.size());&#125; else &#123; // 无权重或权重相等 count = getAndIncrement(key);// 通过key获取调用次数并自增1 return providerList.get(count%length);&#125; 算法复杂度分析：初始化最小和最大权重复杂度为O(n)，无权重或权重相同直接取余选择即可复杂度O(1)；有权重时需要筛选大于当前权重的自己复杂度为O(n)，对子集轮询算账复杂度为O(1)；无权重轮询的复杂度为O(n)，有权重轮询的复杂度为2O(n) 最少活跃优先每次选择最少活跃的provider发起调用，当最少活跃的节点多时，在最少活跃的节点中使用随机算法，有权重随机或者无权重随机选择； 最少活跃可以理解为最少并发数，并发数少的节点表示节点处理请求的速度快，性能强 最少活跃数以最近100次连接中的失败数量为准，如果为0表示最近没有失败连接，直接返回真实的并发数；如果大于0，限制最大值为90，在[0,100)中产生随机数，当随机数比失败连接数大时返回真实的并发数，否自返回最大值；也就是说节点中最近100次连接有失败的记录，该节点则有一定几率不会被选中调用，且失败的连接数越多，不被选中的几率越大 当节点快速抛异常会被认为是处理请求速度快的节点，所以最大失败值限制90，provider抛异常最低有10%选中的概率，等provider恢复并不再抛异常了恢复正常 附伪代码 1234567// 初始化 最小活跃数leastActive、最小活跃数的数量leastCount等if (leastCount == 1) &#123; // 最少活跃数的provider列表只有1个直接返回&#125; else &#123; // 采用随机算法&#125; 算法复杂度分析：初始化工作复杂度O(n)，最少活跃数量为1直接返回O(1)，否则使用随机算法；最少活跃优先算法，无权重情况下2O(n)，有权重情况下3O(n) 一致性hash 以方法维度定义了选择器，保存映射关系，以interfaceName+methodName为key，自定义的选择器为value； 当首次对一个方法发起调用或者providerList发生变化时，初始化选择器 每个节点创建128个虚拟节点，以 ip+port+index 为key得到128个hash值，保存虚拟节点的映射关系（要有序） 如果当前方法存在选择器且providerList没变，用方法的第一个参数得到hash值，从虚拟节点的映射中get，命中直接返回，不命中选择第一个大于该hash值的节点，没有则选择虚拟节点中的第一个 hash算法：通过对一个key使用MD5算法得到一个摘要，这个摘要是byte[16]类型，将数组按照索引 0-3 4-7 8-11 12-15 分成4段，每一个段有4个byte，组成一个32位的hash值，一个摘要可以生成4个hash值 附伪代码 1234567891011121314151617181920212223242526272829303132selector = selectorMap.get(key);if (selector == null || selector.hash() != hashCode)&#123; // 首次调用或者providerList发生变化 selectorMap.put(key, new Selector());&#125; return selecotr.select();class Selector&#123; Selector()&#123; // 初始化选择器 for(item : providerList) &#123; for (0 : 31) &#123; digest = md5.digist(key);// byte[16]类型，4个hash值 for (0 : 3) &#123; virtualNodes.put(hash(digest,index));// hash()就是将摘要分段返回index个段作为hash值 &#125; &#125; &#125; &#125; public Provider select()&#123; digest = md5.digest(arg[0]);// 方法的第一个参数作为key生成摘要 hashCode = hash(digest,0);// 将摘要的第一个端最为hash值 provider = virtualNodes.get(hashCode) if (provider == null) &#123; // 选择大于hashCode的第一个key对应的节点，没有就选择第一个key的节点 &#125; return provider; &#125;&#125; 算法复杂度分析：在最坏的情况下，每次选择都要初始化选择器的复杂度为128O(n)，当provider列表不变时只需进行1次初始化，后续的选择操作复杂度为O(1) 本地优先随机算法判断provider列表中是否存在本地ip，有则发起调用，没有就使用随机算法 算法复杂度分析：最坏的情况下每次都找不到本地ip则比随机算法多O(n)的复杂度，如果能找到本地ip的复杂度为O(n) 总结： 随机算法和轮询算法，适用于节点差异不大的情景，节点有差异需要设置权重值 优点，简单高效 缺点，需要找到最合适的权重值 最少活跃优先算法，适用节点之间有差异的情景 优点，无权重值下，可以均衡节点之间的差异，不用去设置权重值 缺点，算法复杂度较高 一致性hash 适用于节点中有缓存数据的情景，相同的请求总是选择同样的节点 缺点，算法复杂度较高 本地IP调用优先 适用于本地同时提供服务的情景 综上，理论上，本地有自己要调用的服务配置本地IP调用优先，其他情况使用随机或者轮询都可以，默认随机算法不用管就好了]]></content>
      <categories>
        <category>微服务</category>
      </categories>
      <tags>
        <tag>微服务</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[一张图看懂CPU]]></title>
    <url>%2F2020%2F03%2F20%2F%E4%B8%80%E5%BC%A0%E5%9B%BE%E7%9C%8B%E6%87%82CPU%2F</url>
    <content type="text"><![CDATA[废话不说，直接上图 CPU可以拆解为三个部分 控制单元 理解为软件设计中的controller，控制数据的流向以及执行计算机指令 数据单元 用做内存的缓存，存放CPU运算的中间结果 运算单元 负责运算，例如加、减、移位这样 简单来说CPU的工作过程是这样的：获取进程中的的指令（程序代码编译运行后的二进制），然后执行这些指令，在此过程中控制单元执行的一些指令，从内存中加载数数据到数据单元，指挥运算单元进行运算，将结果返回数据单元，最后将结果从数据单元写会内存 往细了说 控制单元中有一个指令指针寄存器和一个指令寄存器，控制单元通过下一条指令在内存中的地址，找到该指令并存入指令寄存器；控制单元中还有一个指令起始寄存器和一个数据起始寄存器，这就是进程切换中上下文的概念了，进程1切换到进程2，将进程1的状态分别保存在指令起始地址寄存器（进程1执行到了哪一行代码）和数据起始地址寄存器（进程1数据读到了哪一行）； 再往细了说 先看数据单元，数据寄存器用来保存数据段（内存中分配给进程存放变量的区域，代码段指内存中存放运行代码的区域）的偏移量，数据段的起始地址在控制单元的寄存器中，起始地址+偏移量 就可以得出读出的数据； 就以x86架构的经典处理器8086来说，数据寄存器有8个16位通用寄存器 AX、BX、CX、DX、SP、BP、SI、DI ，其中前4个寄存器分别可以单独拆分为2个8位的寄存器来使用，这就可以获取短的数据或者长的数据，很灵活； 再看控制单元，CS和DS分别保存代码段的起始地址（指令的起始地址）和数据段的起始地址，C为code，D为data；SS是栈寄存器，存放函数的调用关系；IP寄存器存放下一条指令的地址 8086的寄存器都是16位的，可地址总线是20位的，所以说在内存中寻址的时候起始地址需要左移4位再加偏移量得到最终的地址 再再往细了说 32位处理器的数据单元将原来16位的寄存器扩展到32位，并且为了兼容保持了原始16位寄存器的结构；控制单元中的段寄存器（CS,DS,SS,ES）变化较大，其中CS,DS,SS,ES还是16位，只是不在存起始地址，真正的地址在后面16位中的段描述符缓存器里，而端寄存器中存的东西叫做选择子，来选择段描述符缓存器中的地址信息 再再再往细了说呢 没有了，哈哈，我就学习到这里了]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[将Hexo博客迁移到docker（二）]]></title>
    <url>%2F2020%2F02%2F14%2F%E5%B0%86Hexo%E5%8D%9A%E5%AE%A2%E8%BF%81%E7%A7%BB%E5%88%B0docker%EF%BC%88%E4%BA%8C%EF%BC%89%2F</url>
    <content type="text"><![CDATA[本篇将进行迁移的第二阶段，主要步骤为 在git上备份博客中的文件 进入docker容器中还原 验证 修改Dockerfile 验证 在git上备份博客中的文件hexo d 是将静态文件发布到git上，内容是 public 文件夹中的文件，hexo g 命令会重新生成静态文件；那么其他文件就是我要转移的文件了，将其他文件备份到git仓库中的新分支中 （.gitignore 里给出存放不需要备份的文件，至于为什么后面慢慢了解，本篇重点不在这） 参考这里 12345678910111213141516171819202122232425# 在github上新建分支 hexo-backupgit clone $&#123;git path&#125;# 备份文件cp rf $&#123;username&#125;.github.io/* myblog# 除了 .git 以外的文件都删除cd $&#123;username&#125;.github.iomv .git ../rm -rf * mv ../.git .# 复制刚刚备份的文件过来cp rf ../myblog/* ./# 准备gitignore 文件内容下面附vim .gitignore# 删除主题文件中的.gitrm -rf /themes/next/.git # 更新分支git add .git commit -m &apos;初次提交&apos;git push origin hexo# 删除所有文件 后提交分支rm -rf *git add .git commit -m &apos;删除文件&apos;git push origin hexo 12345678# .gitignore 文件内容.DS_StoreThumbs.dbdb.json*.lognode_modules/public/.deploy*/ 到这里已经将自己博客下面的文件都提交到git的hexo分支中了 进入docker容器中还原1234567891011121314151617181920212223242526272829303132333435cd /usr/localgit clone $&#123;git path&#125;cd /usr/local/$&#123;username&#125;.github.iogit checkout hexo# 由于我已经有myblog的文件夹了这离要删除一下rm -rf /usr/local/myblogmv /usr/local/$&#123;username&#125;.github.io /usr/local/myblog# 安装package.json中的依赖# 修改下载源，安装更快npm config set registry https://registry.npm.taobao.orgnpm install hexo --savenpm install hexo-admin --savenpm install hexo-deployer-git --savenpm install hexo-generator-archive --savenpm install hexo-generator-baidu-sitemap --savenpm install hexo-generator-category --savenpm install hexo-generator-feed --savenpm install hexo-generator-index --savenpm install hexo-generator-search --savenpm install hexo-generator-searchdb --savenpm install hexo-generator-sitemap --savenpm install hexo-generator-tag --savenpm install hexo-helper-live2d --savenpm install hexo-renderer-ejs --savenpm install hexo-renderer-marked --savenpm install hexo-renderer-stylus --savenpm install hexo-server --savenpm install hexo-tag-cloud --savenpm install hexo-wordcoun --save# 重新生成静态文件cd /usr/local/mybloghexo cleanhexo ghexo d 验证在浏览器中访问 http://${ip}:8088 效果相同即为成功 修改Dockerfile因为要相册相关要用到python3，镜像中自带的时python2，所以要安装一下python3，在第二阶段的Dockerfile基础上增加下面操作 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950# 安装依赖RUN yum update -y &amp;&amp; yum install -y zlib-devel bzip2-devel openssl-devel ncurses-devel sqlite-devel readline-devel tk-devel gcc make \# 备份原始的python&amp;&amp; mv /usr/bin/python /usr/bin/python.bak \ # 下载解压&amp;&amp; cd /usr/local \&amp;&amp; wget https://www.python.org/ftp/python/3.6.2/Python-3.6.2.tar.xz \&amp;&amp; tar -xvJf Python-3.6.2.tar.xz \# 编译安装&amp;&amp; cd Python-3.6.2 \&amp;&amp; ./configure prefix=/usr/local/python3 \&amp;&amp; make &amp;&amp; make install \&amp;&amp; rm -rf /usr/local/Python-3.6.2.tar.xz \# 添加软链&amp;&amp; ln -s /usr/local/python3/bin/python3 /usr/bin/python3 \&amp;&amp; ln -s /usr/local/python3/bin/pip3 /usr/bin/pip3 \# 安装依赖&amp;&amp; pip3 install Pillow \# 迁移博客 由于clone速度极其慢，改用本地先clone好复制过去&amp;&amp; rm -rf /usr/local/myblogCOPY myblog /usr/local/myblog/# 安装package.json中的依赖# 修改下载源，安装更快RUN npm config set registry https://registry.npm.taobao.org \&amp;&amp; npm install hexo --save \&amp;&amp; npm install hexo-admin --save \&amp;&amp; npm install hexo-deployer-git --save \&amp;&amp; npm install hexo-generator-archive --save \&amp;&amp; npm install hexo-generator-baidu-sitemap --save \&amp;&amp; npm install hexo-generator-category --save \&amp;&amp; npm install hexo-generator-feed --save \&amp;&amp; npm install hexo-generator-index --save \&amp;&amp; npm install hexo-generator-search --save \&amp;&amp; npm install hexo-generator-searchdb --save \&amp;&amp; npm install hexo-generator-sitemap --save \&amp;&amp; npm install hexo-generator-tag --save \&amp;&amp; npm install hexo-helper-live2d --save \&amp;&amp; npm install hexo-renderer-ejs --save \&amp;&amp; npm install hexo-renderer-marked --save \&amp;&amp; npm install hexo-renderer-stylus --save \&amp;&amp; npm install hexo-server --save \&amp;&amp; npm install hexo-tag-cloud --save \&amp;&amp; npm install hexo-wordcount --save \# 重新生成静态文件&amp;&amp; cd /usr/local/myblog \&amp;&amp; hexo clean \&amp;&amp; hexo g 验证启动docker容器 绑定端口映射 8088:80 浏览器访问 http://${ip}:8088 查看效果无误，完成 最后总结一下需要迁移的步骤 git push origin hexo推送博客所有文件 编辑Dockerfile 在Dokerfile目录下git clone 博客文件 再切换hexo分支 重命名为myblog 在Dockerfile目录下编辑nginx.conf文件 使用Dockerfile生成镜像 启动容器 绑定端口 进入容器启动nginx 使用Dockerfile生成镜像 启动容器 绑定端口 是不是迁移起来非常简单，可以将生成的镜像备份成tar包，在任意的服务器上安装docker后，还原镜像启动容器即可 相册相关 我的相册是参考这里弄得；我将它移至博客文件的hexo分支，一起备份起来，要上传新的文件运行目录中的tool.py脚本，将照片裁剪后上传至github仓库，这时照片就有了URL，在博客中就可以看到了 发布博客相关 docker容器中的 /usr/local/source/_posts/ 目录下的文件名为乱码，下面方法可以解决，但是我这里没有成功，通过tab补全是正常的ls和ll看就有问题 123yum -y install convmvconvmv -f GBK -t UTF-8 --notest -r /usr/local/source/_posts/ 所有我觉得在宿主机建立文件映射，然后进入docker中hexo g -d更新 hexo d 会失败，这里要重新生成sshkey 12345ssh-keygen -t rsa -C &quot;$&#123;email&#125;&quot;# 拷贝sshkey到github中# 配置git config --global user.name &quot;$&#123;username&#125;&quot;git config --global user.email &quot;$&#123;email&#125;&quot;]]></content>
      <categories>
        <category>容器</category>
      </categories>
      <tags>
        <tag>容器</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[将Hexo博客迁移到docker（一）]]></title>
    <url>%2F2020%2F02%2F13%2F%E5%B0%86Hexo%E5%8D%9A%E5%AE%A2%E8%BF%81%E7%A7%BB%E5%88%B0docker%EF%BC%88%E4%B8%80%EF%BC%89%2F</url>
    <content type="text"><![CDATA[本篇是迁移工作的第一阶段 docker入门移步到这里 在docker容器中重新搭建Hexo博客系统并记录步骤拉取centos镜像 -&gt; 启动容器 -&gt; 进入容器bash -&gt; 搭建博客 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253# 拉取镜像docker pull centos:7# 启动容器docker run -di --name=centos7 centos:7# 进入命令行docker exec -it centos7 /bin/bash# 搭建hexo博客# 安装node.js# 安装wgetyum install -y wget# 新建目录 mkdir /usr/local/nodejs# 下载tarwget https://nodejs.org/dist/v12.15.0/node-v12.15.0-linux-x64.tar.xz# 解压xz -d node-v12.15.0-linux-x64.tar.xz# 部署bin文件ln -s /usr/local/nodejs/node_12.15.0/bin/node /usr/local/bin/nodeln -s /usr/local/nodejs/node_12.15.0/bin/npm /usr/local/bin/npm# 安装hexonpm install -g hexo-cli# 安装gityum install git-core# 配置环境变量ln -s /usr/local/nodejs/node_12.15.0/bin/hexo /usr/local/bin/hexo# 创建网站文件夹mkdir myblogcd myblog# 初始化hexohexo inithexo generate# 安装NGINX# 安装依赖yum install -y gcc-c++ pcre pcre-devel zlib zlib-devel openssl openssl-devel# 下载NGINXwget https://nginx.org/download/nginx-1.16.1.tar.gz# 解压tar -zxf nginx-1.16.1.tar.gzcd nginx-1.16.1# 编译安装./configure make &amp;&amp; make install# 配置NGINXvim /usr/local/nginx/conf/nginx.conf# 启动NGINXcd /usr/local/nginx/sbin./nginx 其中nginx.conf为 123456789101112131415161718192021# http中server模块做修改即可server &#123; listen 80 default_server; listen [::]:80 default_server; server_name _; root /usr/local/myblog/public/; # Load configuration files for the default server block. include /etc/nginx/default.d/*.conf; location / &#123; &#125; error_page 404 /404.html; location = /40x.html &#123; &#125; error_page 500 502 503 504 /50x.html; location = /50x.html &#123; &#125; &#125; 完成上述步骤后开始验证 1234567# 将容器保存为镜像docker commit centos7 mycentos:7.1# 启动新的容器docker run -di --name=centos7.1 -p 8088:80 mycentos:7.1 # 进入容器启动NGINX（从镜像启动容器并没有把NGINX启动）docker extc -it centos7.1 /bin/bash# 浏览器中访问 http://$&#123;ip&#125;:8088 验证 编写dockerfile根据上述的步骤一步步编写Dockerfile；然后进行 build -&gt; 报错 -&gt; 进入容器查看错误（我太菜了不能看日志直接修改Dockerfile） -&gt; 修改Dockerfile -&gt; build -&gt; … 直到成功 最终Dockerfile如下 12345678910111213141516171819202122232425262728293031323334353637383940414243444546FROM centos:7MAINTAINER yywang sbsbjs@qq.com# 安装依赖RUN yum update -y &amp;&amp; yum install -y wget git-core vim* gcc-c++ pcre pcre-devel zlib zlib-devel openssl openssl-devel \# 安装nodejs# 新建目录 WORKDIR /usr/local# 下载tarRUN wget https://nodejs.org/dist/v12.15.0/node-v12.15.0-linux-x64.tar.xz \# 解压&amp;&amp; tar -xvf node-v12.15.0-linux-x64.tar.xz \&amp;&amp; mv node-v12.15.0-linux-x64 node_12.15.0 \&amp;&amp; mkdir /usr/local/nodejs \&amp;&amp; mv node_12.15.0 /usr/local/nodejs/ \&amp;&amp; rm -rf node-v12.15.0-linux-x64.tar.xz \# 部署bin文件&amp;&amp; ln -s /usr/local/nodejs/node_12.15.0/bin/node /usr/local/bin/node \&amp;&amp; ln -s /usr/local/nodejs/node_12.15.0/bin/npm /usr/local/bin/npm \# 安装hexo&amp;&amp; npm install -g hexo-cli \# 配置环境变量&amp;&amp; ln -s /usr/local/nodejs/node_12.15.0/bin/hexo /usr/local/bin/hexo \# 创建网站文件夹&amp;&amp; mkdir /usr/local/myblog \&amp;&amp; cd /usr/local/myblog \# 初始化hexo&amp;&amp; hexo init \&amp;&amp; hexo generat \# 安装NGINX依赖&amp;&amp; cd /usr/local \# 下载NGINX&amp;&amp; wget https://nginx.org/download/nginx-1.16.1.tar.gz \# 解压&amp;&amp; tar -zxf nginx-1.16.1.tar.gz \&amp;&amp; cd /usr/local/nginx-1.16.1 \# 编译安装&amp;&amp; ./configure \&amp;&amp; make &amp;&amp; make install \&amp;&amp; rm -rf /usr/local/nginx-1.16.1 \&amp;&amp; rm -rf /usr/local/nginx-1.16.1.tar.gz 最后~ 验证 1234567# 构建镜像docker build -t mycentos:7.2# 启动容器docker run -di --name=centos7.2 -p 8088:80 mycentos:7.2# 进入容器修改nginx.conf并启动NGINXßdocker extc -it centos7.1 /bin/bash# 浏览器中访问 http://$&#123;ip&#125;:8088 验证]]></content>
      <categories>
        <category>容器</category>
      </categories>
      <tags>
        <tag>容器</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[将Hexo博客迁移到docker中（总）]]></title>
    <url>%2F2020%2F02%2F13%2F%E5%B0%86Hexo%E5%8D%9A%E5%AE%A2%E8%BF%81%E7%A7%BB%E5%88%B0docker%EF%BC%88%E6%80%BB%EF%BC%89%2F</url>
    <content type="text"><![CDATA[博客已经运行了大半年了，马上就要到期了，我得着手把搭建的博客备份一下了，续费很贵的话我得找一个便宜的用（我就是一个抠门怪哈哈），最简单的就是做系统的镜像，这也太low了吧。当下流行的是容器技术，决定把先把博客迁移到docker中，如果要换服务器的话直接备份docker就好了呀。 难点：搭建博客的时间过去很久，没有记录，完全忘了如何搭建，不知道都需要迁移哪些文件而且我还搞了很多花里胡哨的东西，这些东西也需要保留 这个就麻烦了，相当于重新搭建Hexo的博客了，没办法谁让我之前没有记录总要还的嘛 迁移步骤分为两个阶段： 第一阶段 重新搭建Hexo博客系统 入门docker 在docker容器中重新搭建Hexo博客系统并记录步骤（启动容器进行端口映射 8088:80，在公网验证） 根据记录的步骤编写Dockerfile，生成镜像（启动容器进行端口映射 8088:80 在公网验证） 见系列文章 将Hexo博客迁移到docker（一） 第二阶段 迁移博客 总结需要的文件 拷贝文件到容器中 修改Dockerfile 在公网验证 验证成功后，将宿主NGINX端口映射到docker容器中 最终将容器打包成tar做备份，或者将镜像提交到仓库中直接拉取即可，非常完美 见系列文章 将Hexo博客迁移到docker（二） 究极解决方案见系列文章 将Hexo博客迁移到docker（究极解决方案） 展望与未来未来可以搞到k8s上面，通过Deployment让hexo和nginx高可用，后续怎么设计一下，持续更新中]]></content>
      <categories>
        <category>容器</category>
      </categories>
      <tags>
        <tag>容器</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker入门]]></title>
    <url>%2F2020%2F02%2F12%2FDocker%E5%85%A5%E9%97%A8%2F</url>
    <content type="text"><![CDATA[开门见山，docker是一种新的虚拟化技术，体积小，启动快，减小了开发和运维成本；下面就简单扫个盲入个门 虚拟技术 传统的虚拟机技术 它的层次结构为： 个人pc（硬件） -&gt; 操作系统（Host OS） -&gt; 虚拟机管理系统（Hypervisor）-&gt; 虚拟机（VM） 虚拟机中的层次为：操作系统（windos/macos…） -&gt; 依赖库（C++…） -&gt; 应用（tomcat/nginx…） docker虚拟技术 它的层次结构为： 个人pc -&gt; 操作系统 -&gt; docker -&gt; 依赖库 -&gt; 容器 容器中的层次接口给为：依赖库（可以复用宿主机的依赖库） -&gt; 应用 总结 docker虚拟技术的层级更少，而且还可以复用宿主机的一些文件（依赖库等），所以docker容器的大小比虚拟机要小很多，并且启动也非常快；大致原理是利用Linux中namespace和cgroup将进程进行隔离，从外部来看就像是运行在容器中一样，docker可以说是进程间的隔离，而虚拟机技术是基于硬件的隔离，在虚拟的硬件基础上又有着不同的操作系统，相比之下docker容器又小又快 比如部署一个nginx；在传统的虚拟机技术下，要先安装一个Linux操作系统的虚拟机，然后在虚拟机上部署nginx；而在docker技术下，无需再安装Linux操作系统，直接复用宿主机的文件和内核即可（若宿主机是Centos，容器是Ubuntu，那就使用Ubuntu的文件，复用宿主机的内核），在此基础上启动nginx进程，并与宿主机的进程隔离，这样nginx容器就部署起来了 除此以外，将自己的应用和环境打包成docker镜像，只要有docker的地方都可以运行相同的容器，不再会有因为环境不同应用运行效果不一样的问题，减小了运维成本，一句话说docker技术解决了应用打包发布的问题 docker一些概念 镜像 用于创建容器的模板 容器 独立运行的一个或一组应用 镜像相当于类，容器相当于类的实例 仓库 用于保存镜像，有公有私有两种，类似于git仓库 常用命令查看版本1docker -v 修改镜像源1vim /etc/docker/daemon.json 启动/停止/重启/查看状态1systemctl start/stop/restart/status docker 查看镜像1docker images 搜索镜像1docker search $&#123;image name&#125; 拉取镜像 不指定版本号拉去最新的1docker search pull $&#123;image name&#125;:$&#123;version&#125; 删除镜像 -f 强制删除1docker rmi -f $&#123;image name/id&#125; 查看正在运行的容器 -a(查看所有)1docker ps -a 容器运行相关参数 -i：表示运行容器 -t：表示容器启动进入命令行 交互式容器 exit退出命令行，容器也退出（守护式容器不会退出） –name：为创建的容器命名 -v：表示目录映射关系（前者是宿主机目录，后者是映射到宿主机上的目录） -d: 守护模式容器 -p: 表示端口映射 前者宿主机端口 后者容器内映射端口 -e: 指定环境变量 启动交互式容器1docker run -it --name=$&#123;name&#125; $&#123;image name&#125;:$&#123;version&#125; /bin/bash 启动守护式容器1docker run -di --name=$&#123;name&#125; $&#123;image name&#125;:$&#123;version&#125; eg: 1docker run -di --name=mysql_test -p 3316:3306 -e MYSQL_ROOT_PASSWORD=root centosz:7 进入容器1docker exec -it $&#123;container name&#125; /bin/bash eg: 1docker exec -it mysql_test /bin/bash 启动/停止容器1docker start/stop $&#123;container name/id&#125; 宿主机和容器文件互拷宿主-&gt;容器 1docker cp $&#123;file&#125; $&#123;container name&#125;:$&#123;path&#125; 容器-&gt;宿主 要在宿主机中使用命令行 1docker cp $&#123;name&#125;:$&#123;file&#125; $&#123;path&#125; 目录挂载1docker run -di -v $&#123;source path&#125;:$&#123;target path&#125; --name=$&#123;container name&#125; $&#123;image name&#125;:$&#123;version&#125; 查看容器ip1docker inspect $&#123;container name/id&#125; 删除容器1docker rm $&#123;container name/id&#125; 将容器保存为镜像1docker commit $&#123;container name&#125; $&#123;inage name&#125; 将镜像保存为tar包1docker save -o $&#123;tar name&#125;.tar $&#123;path&#125; 恢复镜像1docker load -i $&#123;tar name&#125;.tar 停止全部容器1docker stop $(docker ps -q) 删除全部容器1docker rm $(docker ps -aq) 停止并删除全部容器1docker stop $(docker ps -q) &amp; docker rm $(docker ps -aq) dockerfile 创建镜像简单来说记录一系列命令和参数，然后docker根据dockerfile中的命令来构建镜像 From从哪个基础镜像进行构建 MAINTAINER镜像创建者 ENV key value设置环境变量 RUN command运行shell指令（多个RUN会有多层嵌套，不期望使用多个RUN，多个指令以 \ 结尾 &amp;&amp; 开头） ADD source_file dest_file将宿主文件复制到容器内，压缩文件自动解压 COPY source_file dest_file将宿主文件复制到容器内，压缩文件不自动解压 WORKDIR path设置工作目录，相当于 cd 构建镜像命令1docker build -t $&#123;image name&#125;:$&#123;tag&#125; .]]></content>
      <categories>
        <category>容器</category>
      </categories>
      <tags>
        <tag>容器</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[2019年终总结（新的开始）]]></title>
    <url>%2F2019%2F12%2F31%2F2019%E5%B9%B4%E7%BB%88%E6%80%BB%E7%BB%93%EF%BC%88%E6%96%B0%E7%9A%84%E5%BC%80%E5%A7%8B%EF%BC%89%2F</url>
    <content type="text"><![CDATA[光阴似箭岁月如梭，时光如水生命如歌，转眼间2019年到了最后的时刻，这一年对我来说是不平凡的，来盘点一下自己这一年都做了什么，主要有两件大事，一个是研究生毕业，一个是入职，上半年忙着毕业，下半年忙着上班。接下来进入回忆 博客 上半年基本一心扑在毕业的事情上，在等发毕业证的时间比较无聊，游戏已经打吐了，随后和马哥（实验室同门）一起租了服务器搭了博客，我选了Next，他选了另一个主题，我们俩就各自开始装修，再后来我弄好了相册功能，奈何他的主题相册的资料很少，所以这个不要脸的就复制了我的主题，博客搭好了之后也更新什么，打算工作后再说 EOS 这个EOS入坑也是马哥带的，记得是18年第二季度忘了是哪个月，比特币大涨在马哥的蛊惑下研究了一番当时EOS很火，是第三代区块链技术吹得特别的牛，没忍住入坑，￥58左右入坑，后面涨到了￥158，心态开始膨胀，当时的舆论也是一片看好，能够复现比特币的辉煌，随后我记得是马老师的一句话，对就是提前退休的那个马老师，大概意思是区块链是个好东西，比特币不是，接着开始大跌到底已经￥20左右，就被套了，就当交学费了。今年也是第二季度忘了哪个月EOS回涨了，到￥53想都没想马上脱坑，及时止损 不经历一下真的很难感受到人的欲望是无限的，当时在最高点的心态现在想想都后怕，还好及时止损了没亏多少，但也买了教训，期间看到各种人梭哈，想着翻盘不顾一切的那种，最后被套就很恐怖，和赌博很像，经历过就深有体会，关爱生命远离币圈，哈哈 西北大环线 拿着EOS脱坑的钱我换了一身行头，和同学去了西北大环线，青海湖，大柴旦，翡翠湖，最美公路，魔鬼城，莫高窟，丹霞，祁连大草原这些地方（都忘的差不多了，看微博想起来的），感受了祖国的大好河山 我的梦想就是能够和另一半读万卷书，行万里路，看遍天下的奇闻异事，这次是4个同学一起还都是男的，也算完成了一点点梦想吧 毕业 研究生阶段让我收获最大的是鱼人沟通和思考问题的方式，从开始的愣头青变成了会思考的愣头青；简单总结一下研究生的生活吧，心态从抱怨-&gt;无望-&gt;庆幸，抱怨开始工作学习太多被压着喘不过气，无望是看不到自己毕业的希望以出路-&gt;庆幸自己能够到这个实验室遇见最好的各位，也正是和优秀的各位一起学习和努力，顺利毕业，找到满意的工作，也有了新的规划 毕业前我还玩了一个月的尤克里里，会了几个和弦，能弹两个简单的曲子不过现在忘了，还有个小插曲马哥分手了，给我打电话嚎啕大哭，7年的感情说没就没，周哥说就像满级的号被盗了一样，我瞬间感受到了马哥的痛苦，哈哈；按照实验室的传统，毕业三顿饭，吃一顿少一顿，今年由于不可抗力因素变成两顿，最后一顿也是玩的非常开心，也说了我一直想说的话，即使没有结果，起码没留遗憾，之后我便回家呆了几天就去入职了 入职 入职前，我一直关注脉脉，都是职场环境不好的言论，各种甩锅，扯皮，明争暗斗，看的我十分害怕，给自己定的基调就是多听多看少说话，保证不出错，进了这个部门非常和谐，所有人都很nice，我的问题所有都会被解答，非常庆幸能够加入这个团队 到现在入职已有半年了，有过几次培训认识了很多人，发现身边大多都是97年以后的，很多活动自己已经提不起兴趣了，而他们还激情满满，暗暗感叹自己心态老了,中秋节是个转折点我有了新的收获 技术上自己成长了很多，这段时间刷新了对很多知识的理解，遇到的所有知识点都写下来，到现在为止已经写了26篇博客，目前来看都是偏应用和概念性的，大多都是扫盲，之前没有接触过这些东西，只能先了解一个大概，到后期再细细钻研 总结我的2019—-&gt;有自己的小确幸 2020年继续加油，目标（暂时这么些吧，刚毕业还是积累为主） 每月平均两篇博客的更新 把19年欠下的博客补上：spring/spring boot、WAL、设计模式 netty 把部门核心业务吃透，核心产品源码看完，最好能开始学习下一代微服务学习 一次5天以上旅行 奥利给~~]]></content>
      <categories>
        <category>生活杂谈</category>
      </categories>
      <tags>
        <tag>生活杂谈</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[2019的最后一天踩坑正则表达式]]></title>
    <url>%2F2019%2F12%2F31%2F2019%E7%9A%84%E6%9C%80%E5%90%8E%E4%B8%80%E5%A4%A9%E8%B8%A9%E5%9D%91%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[背景2019年的最后一天，和往常一样高高兴兴写着bug，遇到一个了需求 需要判断字符串前后是否有空白，返回true和false即可 思路正则表达式呗（条件反射的方案） 做法 第一步，打开浏览器用Google百度一下判断字符前后空白的正则 /(^\s)|(\s$)/g （看了一眼没毛病） 第二步，command+c出来 第三步，编写代码，把正则command+v过去 1Pattern.matches(&quot;/(^\\s*)|(\\s*$)/g&quot;, ” test “) 第四步，验证，run之后，返回false，嗯，bug来了 挣扎是我拷贝的姿势不对吗？换姿势试试 (^\s)|(\s$) ^\s|\s$ ^\s* \s*$ 结果还是false，团灭 字符串改成 ” “，返回true了，emmm…想不到了 看看源码是怎么说的，Pattern的matches方法底层调用的时Matcher的matches方法，先看注释 Attempts to match the entire region against the pattern. entire-&gt;整个的，意思是说matches方法是会匹配整个字符串 解决知道原因了，正则不对，网上的正则是匹配字符串前后的空白字符，并不是整个一起匹配，所以得重写正则 复制的正则 /(^\s)|(\s$)/g 修改后正则 (^\s.)|(.\s$) 试一下，所有都能匹配 是 * 的问题 修改一下 (^\s+.)|(.\s+$) 完美 中间补了一下正则表达式 五分钟搞定正则表达式，如果没搞定，再加两分钟]]></content>
  </entry>
  <entry>
    <title><![CDATA[TCP]]></title>
    <url>%2F2019%2F12%2F26%2FTCP%2F</url>
    <content type="text"><![CDATA[TCP报文 源端口 16bit 目的端口 16bit 序号 32bit seq 发送SYN时（SYN控制位是1）会初始化序列码（Initial Sequence Number, ISN），会用一个算法生产随机数 确认序号 32bit ack 伴随ACK（ACK控制位是1）报文一起，表示下一个要接收包的序列开始 4位首部长度 4bit 保留 6bit 标志 6bit URG 紧急标志 ACK 应答标志 PSH 推 RST 重置连接标志 用于重置连接 SYN 同步标志 用于建立连接 FIN 完成数据发送标志 用于释放连接 窗口大小 16bit 校验和 16bit 紧急指针 16bit 三次握手 客户端向服务器发送请求，等待服务器响应，客户端进入SYN_SENT状态；SYN=1, seq=x 服务器收到客户端建立连接的请求（SYN=1表示建立连接），向客户端发送响应，随后服务器进入SYN_RCVD状态；SYN=1，ACK=1，ack=x+1，seq=y 客户端收到响应确认后（确认ack=x+1，表示服务器接收到x+1前的所有的数据，没有丢包），进入到ESTAPLISHED状态（表示客户端向服务器发送的数据x可以被接收到，单方向连通），再向服务器发送响应，服务器接收到响应确认后（确认ack=y+1，表示接收到y+1前的所有的数据，没有丢包）进入ESTABLISHED状态（表示服务器想客户端发送的数据y可以被接收到，单方向连通）；ACK=1 ack=y+1 SYN=1 表示建立连接的请求 ACK=1 表示确认收到请求 seq 表示初始序列，相当于发送数据的开始索引 ack 表示收到数据后的序列，相当于下一次发送数据的开始索引（比如 ack=x+1 表示x+1前的数据接收到了，下次发送从x+1开始） 三次握手其实就是为了建立连接，客户端&lt;——&gt;服务器两个方向，一次连接建立的过程必须是发送seq序列并收到ack=seq+1的确认 为什么不是2次握手或者是4次握手 2次握手；当客户端发送了SYN=1 seq=x的连接请求，服务器返回ack=x+1的响应，如果是两次握手此时已经建立连接；这时候只能保证客户端向服务器发送的数据能被成功接收，而不能确定服务器给客户端发送的数据是否能被接收，相当于只是建立了 客户端——&gt;服务器单方向的连接 4次握手，参照2次握手发现建立单方向的连接往往需要2次握手，两个方向建立必然会4次握手，其实是第二次握手做了两件事，一是收到服务器的响应并确认，二是发送想服务器建立连接的请求；这两件事一起做相当于是3次握手 TCP不会重传ACK=1的报文，只能通过重发SYN=1的请求来尝试重新建立连接，比如（A是客户端，B是服务端） 第一个包，即A发给B的SYN没有到达B，A会超时重传，直到收到B的确认 第二个包，即B发送给A的SYN+ACK没有到达A，B会超时重传，直到收到A的确认 这里的报文虽然是ACK但是也包含SYN，所以可以重传 第三个包，即A发送给B的ACK没有到达B a.如双方果没有数据发送，B会超时重传，知道收到A的确认 b.如果A有数据发送，因为第二个包已经成功接收，A为ESTABLISHED状态，A-&gt;B的连接已经建立，A会发送Data+ACK的确认，当B接收到的时候会改变状态为ESTABLISHED c.如果B有数据发送，由于B没有收到确认还不是ESTABLISHED状态，还不能发送数据，会一直周期性超时重传SYN + ACK，直到收到A的确认才可以发送数据 TCP会不会重复建立连接呢？ 场景：客户端A和服务器B建立连接，第一个连接请求a没有收到，重新发送第二个请求b，请求b被接收后建立连接，过一会B又收到请求a 答案：不会，服务器B接收到请求a，认为a是无效请求，返回rst报文拒绝连接 假设如果已经建立了连接，服务器B发现请求a是失效的（因为是重发的请求源IP、端口和目标IP、端口是一样的，此时端口已经打开，连接建立）并向客户端A返回rst包，拒绝连接； 假设还连接还没建立，服务器B向客户端A返回ACK+SYN，A收到后验证发现该请求是无效的，回复rst关闭连接，B收不到回复会重发ACK+SYN到一定次数（可设置）不再重发并关闭这个未建立起来的连接 四次挥手 客户端发送向服务器发送关闭请求（FIN=1，seq=x），请求关闭客户端——&gt;服务器的连接，客户端进入FIN_WAIT_1的状态；客户端停止向服务器发送数据 服务器接收到关闭请求后，回复（ACK=1 ack=x+1 seq=y）给客户端，表示接收到关闭请求，服务器进入到CLOSE_WAIT状态，客户端收到回复后进入FIN_WAIT_2的状态 服务器发送向客户端发送关闭请求（FIN=1，ACK=1，seq=z，ack=x+1），服务器进入LAST_ACK状态；服务端停止向客户端发送数据，等待客户端响应 客户收到服务端的关闭请求，回复（ACK=1，seq=x+1，ack=z+1），客户端进入TIME_WAIT状态，等待2MSL（报文的最大生存时间）时间后，客户端进入CLOSED状态，服务器收到客户端的响应后进入CLOSED状态 等待2MSL的作用 1.为了保证客户端发送的ACK能够到达服务器，服务器的连接能够正常关闭； 假设ACK丢失，等待1个MSL的时间服务器重新发送FIN关闭连接，客户端在1个MSL的时间内收到重发的FIN请求就知道刚刚的ACK没有送到，重新发送ACK确认并重新计算MSL的时间；假设第四次挥手后直接关闭，服务端没有收到ACK重发FIN，此时客户端发送rst报文关闭连接，这时是异常的关闭，太暴力了不优雅 2.可以防止已经失效的数据包在下次的连接中传输 失效的数据包由于网络延迟，还未发送到目的地，这时数据包虽然已经生效但是生命周期还没有结束（在MSL的时间内），假如第四次挥手后马上关闭连接，此时又有新的连接建立，刚好是相同的IP和端口，旧的数据包传输可以在MSL时间内传输，等待2MSL后所有失效的数据包都已不存在 滑动窗口用来加速数据传输，假设A发送序列seq=x的包，必须等待收到ack=x+1的回复才继续发送后面的包，滑动窗口相当于规定了一个范围，只要发送seq的范围没有超过滑动窗口就能继续发送；这样发送端不需要长时间等待前一个ack就能继续发送后面的数据包，接收端可以收到多个数据包后只发送一个ack来表示确认，加速了传输速度 SYN攻击发生在三次握手的第三次过程中，服务器还没接收到客户端ack，状态是SYN_RCVD的时间段中，客户端伪造大量不存在的IP的SYN包，请求建立连接，服务器回复并等待，源ip是伪造的并不存在，服务器一直超时重发，造成网络堵塞，检测SYN攻击的方式很简单，服务器上有大量SYN_RCVD状态的链接，并且IP地址是随机的，可以用命令（#netstat -nap | grep SYN_RECV）判断 RST攻击客户端A与服务器B已经建立连接，C伪装成A发送RST包，B接收到后强制断开连接；亦或者C伪装A发送SYN包，B接收后发现该请求无效返回RST包要A断开连接；所以客户端的端口设置是随机的，不然很容易被猜到从而受到攻击 长连接短连接 短连接，客户端和服务器完成一次请求和响应，相当于完成一次读写，一般由客户端发起关闭连接操作，（服务器收到消息后关闭连接不优雅）；优点是便于管理，存活的连接都是有用的连接 长连接，客户端和服务器的连接不会主动关闭，后续的请求响应继续使用这个连接，通过保活机制维护连(2小时内没有请求和响应，服务器会想客户端发送一个探测报文) 客户端响应正常，时间刷新，2小时没有操作后继续探活 客户端不能响应探测报文（客户端异常无法发送响应或发送的响应无法到达服务器），75s后会超时，服务器共发送10个这样的探测，间隔75秒，10次结束后仍然没有收到回应，关闭连接 半连接队列和全连接队列 指的是服务器的状态，SYN_RCVD状态的连接会加入到半连接队列，服务器收到客户端的确认报文状态改为ESTABLISHED状态会从半连接队列中删除，加入到全连接队列 半连接队列满 不开启net.ipv4.tcp_syncookies，直接丢弃新来的SYN请求 开启net.ipv4.tcp_cookies，假设全连接队列满，并且qlen_young的值（半连接队列中还没有进行SYN+ACK的连接数量）大于1，丢弃这个SYN请求；假设全连接队列没满，生产syncookie并返回SYN+ACK包 syncookies用来防止syn floods攻击（攻击方不停发送SYN请求，不去回应ACK，使得半连接队列满，其他连接无法建立），通过将接收到的源ip源端口序列号进行hash，称为hash值，将hash值作为seq发送SYN+ACK，收到ACK响应验证cookie是否正确（ack-1），正确才能建立连接；但是对于没有受到攻击的服务器来说syncookies会造成负担 假设全连接队列满，会根据tcp_abort_on_overflow的值，执行相应的策略（值为0，服务器丢弃该连接，连接信息仍然保留在半连接队列中，服务器会重发SYN+ACK，直到队列不满，建立连接；值为1，服务器发送rst报文关闭连接） 拥塞控制控制网络流量，寻找一个合适的数据传输速度，防止造成网络堵塞或者传输速度过慢效率低的问题；拥塞窗口（cwnd）也就是发送数据的最大值，防止拥塞窗口过大，需要设置一个阈值（ssthresh）来控制窗口的大小，在阈值上下使用不同的算法 慢开始（cwnd &lt; ssthresh）；开始不会就发送大量的数据，由小到大慢慢增加拥塞窗口的大小，探测网络的拥塞程度，每收到一个ACK拥塞窗口（cwnd）增加一倍，从1开始（2的指数增加） 拥塞避免（cwnd &gt; ssthresh）；让窗口慢慢增大，经过一个往返时间RTT（收到一个ACK），窗口大小加1 在慢启动和拥塞避免的阶段中当出现网络拥塞（有报文超时），窗口会重置为1，ssthresh的阈值会重置为发生拥塞时窗口的一半，再重新开始传输数据 快重传；发送方按顺序传递报文，当出现丢失数据，接收方会发送重复的确认告知发送方报文丢失，发送方收到三个重复的确认立即重发报文，不必等待报文超时再重传 快恢复；发送方收到3个重发确认，将ssthresh减半，不执行慢开始（因为收到重复确认所以此时网络并没有拥塞，执行拥塞避免窗口加1，缓慢增大即可） 参考资料TCP为什么是三次握手，而不是两次或四次 TCP建立连接时三次握手的一个疑问点 TCP中的RST标志(Reset)详解 TCP协议详解 TCP流量控制、拥塞控制]]></content>
  </entry>
  <entry>
    <title><![CDATA[阻塞非阻塞，同步异步，网络I/O模型概念]]></title>
    <url>%2F2019%2F12%2F20%2FI-O%E6%A8%A1%E5%9E%8B%2F</url>
    <content type="text"><![CDATA[I/O 进程或线程会产生I/O，后面都以线程为例，真正操作I/O的是操作系统，也就是说线程线程向操作系统发送I/O请求，由操作系统来完成I/O执行，整个过程为应用程序的I/O调用； I/O调用的过程就是将进程中（用户空间）的数据输出到进程外部的的空间（系统空间），或者是将进程外部空间（系统空间）的数据输入到进程中（用户空间）；例如一个输入类型的I/O调用，线程首先向操作系统请求外部数据，操作系统将外部数据拷贝到内核缓冲区，进程中的线程再将内核缓冲区的数据拷贝到进程缓冲区，线程针对这部分数据继续后面的操作； 一个线程发出I/O请求后，需要等待I/O数据就绪（操作系统将I/O数据从外部拷贝到系统空间） 阻塞、非阻塞、同步、异步阻塞非阻塞 阻塞和非阻塞；等待I/O数据就绪是否可以做其他操作；一个线程请求I/O并且I/O数据未就绪，如果线程会一直等待不会做其他事情这种方式为阻塞，如果线程立即收到I/O数据未就绪的返回值，并不需要一直等待这个方式为非阻塞，通常是轮询去访问I/O数据是否就绪，虽然没有一直等也是需要不断去询问； 同步异步 同步和异步；可以类比线程的同步和异步，同步必须拿到I/O数据才能进行后面的操作，有很强顺序性，没有I/O数据就不能完成后面的操作，而异步不需要拿到I/O数据，去做别的操作没有顺序性；或者我觉得是不是可以这么理解 我来理解一下：简单来说同步异步的区别在于是否需要很强的顺序性；就是说同步异步区别在于用户线程是否需要拿到I/O数据再进行后面的操作，同步必须要用到这部分数据，I/O数据没有就绪就一直会等待，而异步不需要用到这部分数据，仅仅发送I/O请求等待操作系统通知即可，（这里同样提了等待，和阻塞的等待差不多都是等待I/O数据是否就绪，同步异步的关注点是是否需要等待I/O数据就绪完成下面的操作，类比于线程的同步和异步；而阻塞的关注点是等待I/O数据就绪的过程是否是一直在死等还是在做其他操作，非阻塞就是没有在死等，这段时间可以做其他的操作但是通常我们都会不断去询问I/O数据是否就绪） 组合概念 同步阻塞；线程发起I/O请求，I/O数据未就绪线程等待，这是阻塞，拿到I/O数据之后才进行进一步操作，这是同步；从程序的角度来看线程一直阻塞直到I/O数据就绪 同步非阻塞；线程发起I/O请求，I/O数据未就绪会立即收到一个返回值不用等待，这是非阻塞，拿到I/O数据之后才进行进一步操作，这是同步；这里虽然不需要等待I/O数据就绪，但是由于是同步的，用户线程必须拿到I/O数据，此时由于I/O数据未就绪，用户线程无法对数据进行拷贝用户线程只能通过轮询的方式去询问I/O数据是否就绪，再进行下一步操作；从程序的角度来看线程只是卡在了等待I/O数据就绪这里，不会阻塞，此时可以去做其他的操作，只是通常是去做询问I/O数据是否就绪的操作 异步阻塞；其实这种情况是不存在的，异步和阻塞是矛盾的； 异步非阻塞；用户线程发起I/O请求后，无须关心I/O数据是否就绪，待I/O数据就绪后由操作系统将数据拷贝到用户空间，再向用户线程发送通知进行下一步操作；从程序的角度看现场不会阻塞 网络I/O模型 阻塞I/O 线程发起I/O请求会一直阻塞等待I/O条件就绪 非阻塞I/O 线程发起I/O请求后，如果I/O条件不是就绪状态立即返回一个状态不会一直等待，可以先做其他的任务，间隔一段时间查看I/O条件是否就绪，如果就绪进行下一步操作 多路复用I/O 非阻塞I/O线程需要一直去询问I/O事件是否就绪，如果线程很多必将造成资源的浪费；多路复用I/O将所有线程的I/O请求注册到一个新的线程中（select），由这个线程进行轮询去查看I/O条件是否就绪，有就绪状态就通知对应的线程进行处理；相当于是把非阻塞I/O中多线程查看I/O条件的事情委托给了单独的一个线程，提高了系统的吞吐量 信号驱动I/O 这个感觉和多路复用I/O差不多，这里将多线程的I/O操作注册为一个信号，信号中有回调函数，当信号发生call回调函数通知用户线程，与本节无关先简单这么理解 异步I/O 线程发出I/O请求后不需要做任何操作，I/O操作完全由操作系统内核完成，之后会通知线程]]></content>
  </entry>
  <entry>
    <title><![CDATA[回调与监听器模式]]></title>
    <url>%2F2019%2F11%2F22%2F%E5%9B%9E%E8%B0%83%E4%B8%8E%E7%9B%91%E5%90%AC%E5%99%A8%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[监听器模式是基于Java回调机制的，首先了解一下回调 回调类似于多线程中new Thread(){run()} 这样，其实run方法就是回调方法，jdk并不关注你怎么去实现run方法，将其以接口的方式暴露出来，让你去填空；就好像你的同事和你配合写代码，挖了一个坑让你填，哈哈，这么比喻有些不妥，其实是为了解耦，不想让你的代码侵入进去，直接看类图 类图 回调就包含两个部分，分别是调用者和回调接口，实现也很简单，调用者中维护回调接口的对象并增加set方法，调用者中直接使用接口中的方法，具体实现在调用set方法时填写即可，我可能没有说清楚，直接上代码 实现回调接口 Callback 123public interface Callback &#123; void doSomething();&#125; 调用者 Caller 1234567891011121314public class Caller &#123; // 维护一个回调接口 private Callback callback; public void setCallback(Callback callback) &#123; this.callback = callback; &#125; public void call() &#123; System.out.println(&quot;do something before&quot;); callback.doSomething();// 使用回调接口中的方法，不需要在这里关系实现 System.out.println(&quot;do something behind&quot;); &#125;&#125; 测试 123456789101112public static void main(String[] args) &#123; Caller caller = new Caller(); // 具体实现在set方法中填写 caller.setCallback(new Callback() &#123; @Override public void doSomething() &#123; System.out.println(&quot;do something in callback&quot;); &#125; &#125;); caller.call();&#125; 监听器模式监听器模式是监听感兴趣的事件，事件发生做出相应的操作；是回调的一种拓展，是在包括监听器接口，事件源和事件对象三个部分，先看类图 类图 相较于回调，监听器接口相当于回调方法接口，事件源相当于调用者，监听器模式是在此基础上多了事件对象，并传给接口的方法中，我的理解是事件对象是对事件的一个封装，感兴趣的事件可能有多个，可以针对不同事件（不同的event对象）做不同的操作，这些操作也被封装在不同event对象中 实现监听器接口 123public interface EventListener &#123; void doSomething(Event event);&#125; 事件源 123456789101112131415public class EventSource &#123; // 维护监听器对象 private EventListener listener; public void setListener(EventListener listener) &#123; this.listener = listener; &#125; public void eventHappend(Event event) &#123; System.out.println(&quot;do something before&quot;); listener.doSomething(event);// 不关心方法具体实现，并传入event对象参数 System.out.println(&quot;do something behind&quot;); &#125;&#125; 事件对象 12345678910111213141516public class Event &#123; // 事件类型 private String eventInfo; public Event(String eventInfo)&#123; this.eventInfo = eventInfo; &#125; public String getEventInfo() &#123; return eventInfo; &#125; // 对于事件的操作 void doSomething() &#123; System.out.println(&quot;do something in event object&quot;); &#125;&#125; 测试 123456789101112131415public static void main(String[] args) &#123; EventSource eventSource = new EventSource(); eventSource.setListener(new EventListener() &#123; @Override public void doSomething(Event event) &#123; event.doSomething();// 不管事件是什么直接执行方法 // 有感兴趣的事件做对应的操作 if (&quot;event interested&quot;.equals(event.getEventInfo())) &#123; System.out.println(&quot;interesting event happened&quot;); &#125; &#125; &#125;); eventSource.eventHappend(new Event(&quot;event interested&quot;));&#125; 感觉事件对象还没有理解到位，针对不同的事件做不同的操作，可以设置不同的监听器，在不同的监听器中做对应的操作，相当于回调不用封装时间对象；也可以封装不同的监听事件作为参数传入，唯一的监听器中，针对不同的事件对象再做不同的操作。]]></content>
      <tags>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SQL Explain记录]]></title>
    <url>%2F2019%2F11%2F16%2FSQL-Explain%E8%AE%B0%E5%BD%95%2F</url>
    <content type="text"><![CDATA[要优化SQL必须得使用Explain，这里记录一下Explain的使用，直接查看即可，摘自MySQL Explain详解 explain 直接加载SQL语句之前，然后一起执行即可，只能分析查询语句，会出现以下结果 IDselect的查询顺序标识，SQL顺序由大到小执行，id相同从上往下顺序执行 select_typeselect的类型 SIMPLE(简单SELECT，不使用UNION或子查询等) PRIMARY(子查询中最外层查询，查询中若包含任何复杂的子部分，最外层的select被标记为PRIMARY) UNION(UNION中的第二个或后面的SELECT语句) DEPENDENT UNION(UNION中的第二个或后面的SELECT语句，取决于外面的查询) UNION RESULT(UNION的结果，union语句中第二个select开始后面所有select) SUBQUERY(子查询中的第一个SELECT，结果不依赖于外部查询) DEPENDENT SUBQUERY(子查询中的第一个SELECT，依赖于外部查询) DERIVED(派生表的SELECT, FROM子句的子查询) UNCACHEABLE SUBQUERY(一个子查询的结果不能被缓存，必须重新评估外链接的第一行) table显示这一步所访问数据库中表名称（显示这一行的数据是关于哪张表的），有时不是真实的表名字，可能是简称，例如上面的e，d，也可能是第几步执行的结果的简称 type对表访问方式，表示MySQL在表中找到所需行的方式，又称“访问类型”。 常用的类型有： ALL、index、range、 ref、eq_ref、const、system、NULL（从左到右，性能从差到好） ALL：Full Table Scan， MySQL将遍历全表以找到匹配的行 index: Full Index Scan，index与ALL区别为index类型只遍历索引树 range:只检索给定范围的行，使用一个索引来选择行 ref: 表示上述表的连接匹配条件，即哪些列或常量被用于查找索引列上的值 eq_ref: 类似ref，区别就在使用的索引是唯一索引，对于每个索引键值，表中只有一条记录匹配，简单来说，就是多表连接中使用primary key或者 unique key作为关联条件 const、system: 当MySQL对查询某部分进行优化，并转换为一个常量时，使用这些类型访问。如将主键置于where列表中，MySQL就能将该查询转换为一个常量，system是const类型的特例，当查询的表只有一行的情况下，使用system NULL: MySQL在优化过程中分解语句，执行时甚至不用访问表或索引，例如从一个索引列里选取最小值可以通过单独索引查找完成。 possible_keys指出MySQL能使用哪个索引在表中找到记录，查询涉及到的字段上若存在索引，则该索引将被列出，但不一定被查询使用（该查询可以利用的索引，如果没有任何索引显示 null） 该列完全独立于EXPLAIN输出所示的表的次序。这意味着在possible_keys中的某些键实际上不能按生成的表次序使用。如果该列是NULL，则没有相关的索引。在这种情况下，可以通过检查WHERE子句看是否它引用某些列或适合索引的列来提高你的查询性能。如果是这样，创造一个适当的索引并且再次用EXPLAIN检查查询 Keykey列显示MySQL实际决定使用的键（索引），必然包含在possible_keys中 如果没有选择索引，键是NULL。要想强制MySQL使用或忽视possible_keys列中的索引，在查询中使用FORCE INDEX、USE INDEX或者IGNORE INDEX。 key_len表示索引中使用的字节数，可通过该列计算查询中使用的索引的长度（key_len显示的值为索引字段的最大可能长度，并非实际使用长度，即key_len是根据表定义计算而得，不是通过表内检索出的） 不损失精确性的情况下，长度越短越好 ref列与索引的比较，表示上述表的连接匹配条件，即哪些列或常量被用于查找索引列上的值 rows估算出结果集行数，表示MySQL根据表统计信息及索引选用情况，估算的找到所需的记录所需要读取的行数 Extra该列包含MySQL解决查询的详细信息,有以下几种情况： Using where:不用读取表中所有信息，仅通过索引就可以获取所需数据，这发生在对表的全部的请求列都是同一个索引的部分的时候，表示mysql服务器将在存储引擎检索行后再进行过滤 Using temporary：表示MySQL需要使用临时表来存储结果集，常见于排序和分组查询，常见 group by ; order by Using filesort：当Query中包含 order by 操作，而且无法利用索引完成的排序操作称为“文件排序” Using join buffer：改值强调了在获取连接条件时没有使用索引，并且需要连接缓冲区来存储中间结果。如果出现了这个值，那应该注意，根据查询的具体情况可能需要添加索引来改进能。 Impossible where：这个值强调了where语句会导致没有符合条件的行（通过收集统计信息不可能存在结果）。 Select tables optimized away：这个值意味着仅通过使用索引，优化器可能仅从聚合函数结果中返回一行 No tables used：Query语句中使用from dual 或不含任何from子句 总结： EXPLAIN不会告诉你关于触发器、存储过程的信息或用户自定义函数对查询的影响情况 EXPLAIN不考虑各种Cache EXPLAIN不能显示MySQL在执行查询时所作的优化工作 部分统计信息是估算的，并非精确值 EXPALIN只能解释SELECT操作，其他操作要重写为SELECT后查看执行计划。 重点关注：type至少达到range级别 key列有值，并且key_len越少越好，做到有索引的查询 rows列越少越好]]></content>
      <tags>
        <tag>SQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SQL级联查询一些总结]]></title>
    <url>%2F2019%2F11%2F16%2FSQL%2F</url>
    <content type="text"><![CDATA[子查询导致索引失效 连接查询（连接条件为索引）的效率更高 背景：微服务相关管理端的系统，用户会在自己对应服务的地方查询所需的server，新增需求为要查看自己的服务所在的app 数据结构：server在单独的一张表，可以根据服务名称（interface_name）来查询；AppName在另外的一张表中；两张表没有联系需要通过一个中间表来连接；interface_name有索引，三个表之间的链接字段都有索引 分析：需要联合3张表来查询所需要的数据，每张表的数据量都比较大，而且这个SQL是系统使用最频繁的部分查询的频率还特别高，所以要尽可能快的出结果 我的心路历程：先通过interface_name条件筛选出一部分数据再链接另外两张表查询，都有索引一定是最优的，SQL如下 1234567891011SELECT app_name FROM saf_app WHERE app_id IN ( SELECT DISTINCT app_id FROM saf_ins_hb WHERE ins_key IN (SELECT ins_key FROM saf_server WHERE interface_name = &apos;xxx&apos;) ) ORDER BY app._name 查询时间竟然需要6s多，这绝对是不能忍的，接着我又试了一下级联查询，SQL如下 123456SELECT DISTINCT app.app_name FROM saf_server s LEFT JOIN saf_ins_hb hb ON s.ins_key = hb.ins_keyLEFT JOIN saf_app app ON hb.app_id = app.app_id WHERE s.interface_name = &apos;xxx&apos; ORDER BY app.app_name 这次的结果只需0.05s,相差100倍还多 explain看下呢 IN子查询如下 可以看到id为2和3的查询都用到了索引并且只需扫描的很少的行数，到了最外层的查询就变成了全表扫描了，索引就失效了 级联查询如下 级联查询全部使用到了索引，而且扫描的行数比子查询的要少很多，扫描的最终行数是乘积的关系，级联查询有两个子查询的rows为1所以要比IN子查询要小很多 所以说IN子查询会导致部分索引失效，我有了新的想法，既然连接查询会很快那么我先通过条件筛选出数据再做级联查询不是更快了，开整~ SQL如下 12345SELECT DISTINCT app.app_name FROM (SELECT ins_key FROM saf_server WHERE interface_name = &apos;xxx&apos;) s LEFT JOIN saf_ins_hb hb ON s.ins_key = hb.ins_keyLEFT JOIN saf_app app ON hb.app_id = app.app_id ORDER BY app.app_name 查询0.02s左右，我非常满意，explain一下呢 相较于级联查询还多了7000多次的遍历？？？子查询害人啊，查询结果0.02s左右应该是有缓存 看了一篇文章说在on后面加限制条件会比where中加限制条件用时要少，on后面加条件在两张表做连接的同时过滤掉一些数据后再和第三张表做连接，where是将连接了所有表之后的结果进行筛选，听着很有道理，那我试一下呢，SQL如下 12345SELECT DISTINCT app.app_name FROM saf_server s LEFT JOIN saf_ins_hb hb ON s.ins_key = hb.ins_key and s.interface_name = &apos;xxx&apos;LEFT JOIN saf_app app ON hb.app_id = app.app_id ORDER BY app.app_name explain看下 结果非常意外，不仅时间没有省下来，索引也没有使用，进行全表扫描，还好我验证了一下，原因的话还不知道，对mysql底层不是很熟悉，先暂时把遇到的问题记录下来吧 ^_^ 结论：子查询会导致索引失效，尽量不使用子查询，用级联查询代替，并将级联查询的条件设置建立索引 级联查询的原理mysql会首先找到一张表作为驱动表，就是首先要进行查询的表，以驱动表为基础匹配剩下的表，inner join的情况mysql会选择数据量小的表作为驱动表，left/right join分别以左/右表作为驱动表；接着会根据on的条件过滤结果，最终将连接的表都筛选完成后如果有where语句指定条件将进行最后的筛选得到结果 连接的算法也很简单，连接条件没有索引则进行全表扫描然后进行匹配，如果还有表连接则将匹配的结果继续与剩余的表进行扫描匹配，这种方法简单粗暴，叫做嵌套循环连接（Nested-Loop Join）；Mysql对这种方式有了优化，增加了join buffer，是将驱动表关联条件的相关列缓存起来，并将多次匹配合并，减少的匹配的次数，以此方式来加速查询结果，叫做BLJ算法（Block Nested-Loop Join）；有索引则会先匹配索引，匹配后的结果再插到对应的数据返回 综上，级联查询的查询条件最好是加索引，虽然mysql对没有索引的链接做了优化，那也是没有索引的方式快的，而且最好链接的条件是主键索引，这是由于非主键索引指向的时主键索引，要得到数据还要跑一次主键索引；还有我想到了阿里巴巴java开发规范中写道多余三张表不能使用join，用多次简单查询代替这个也要注意一下 参考： MySQL查询优化——连接以及连接原理]]></content>
      <tags>
        <tag>SQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[踩坑记录]]></title>
    <url>%2F2019%2F11%2F06%2F%E8%B8%A9%E5%9D%91%E8%AE%B0%E5%BD%95%2F</url>
    <content type="text"><![CDATA[在xml文件中if条件判断字符串相等时要用双引号而不是单引号 错误栗子： 1&lt;if test=&quot;params.appName != null and params.appName != &apos;&apos; and params.appName != &apos;*&apos;&quot;&gt; 正确栗子： 1&lt;if test=&apos;params.appName != null and params.appName != &quot;&quot; and params.appName != &quot;*&quot;&apos;&gt; MyBatis会将’*’转化为数字，并且会报NumberFormatException 原因百度了一下大概是这样，MyBatis使用OGNL表达式来解析，在OGNL表达式中单引号和其中的字符会被解析成一个字符，java对于没有引号的等式/不等式认为是数字类型并进行转化]]></content>
      <tags>
        <tag>MyBatis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[maven-assembly插件打zip包]]></title>
    <url>%2F2019%2F10%2F11%2Fmaven-assembly%E6%8F%92%E4%BB%B6%E6%89%93zip%E5%8C%85%2F</url>
    <content type="text"><![CDATA[web工程通过maven打包通常都是war包，Tomcat会自动将war包解压并发布出来，但如果本身做的不是web工程，是普通java项目如何发布到服务器上并运行main方法呢？公司里使用maven-assembly这个插件，将项目打包成zip压缩包，里面包含bin、conf和lib三个文件夹，bin目录中保存启动和停止的shell脚本，conf中保存配置文件，lib目录中保存编译好的jar和所依赖的jar；然后将zip包抽取并解压到服务器启动start.sh脚本来运行java项目。 在这个过程中就用到了maven-assembly这个插件来进行编译并打包，步骤如下 目录结构 1234567main |--assembly |----bin |---start.sh |---stop.sh |---jvm.properties |----assembly.xml pom中配置assembly插件 123456789101112131415161718192021&lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-assembly-plugin&lt;/artifactId&gt; &lt;version&gt;3.1.0&lt;/version&gt; &lt;configuration&gt; &lt;!--打包规则的配置--&gt; &lt;descriptors&gt; &lt;descriptor&gt;src/main/assembly/assembly.xml&lt;/descriptor&gt; &lt;/descriptors&gt; &lt;tarLongFileMode&gt;posix&lt;/tarLongFileMode&gt; &lt;/configuration&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;make-assembly&lt;/id&gt; &lt;phase&gt;package&lt;/phase&gt; &lt;goals&gt; &lt;goal&gt;single&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt;&lt;/plugin&gt; 注：使用assembly插件编译要讲该插件的配置放在plugins标签中的第一个，在我的工程中开始在前面的时spring-boot-maven-plugin插件导致编译失败了 2.创建并配置assembly.xml文件 123456789101112131415161718192021222324252627282930313233343536373839404142434445&lt;assembly&gt; &lt;id&gt;assembly&lt;/id&gt; &lt;formats&gt; &lt;format&gt;zip&lt;/format&gt; &lt;format&gt;dir&lt;/format&gt; &lt;/formats&gt; &lt;includeBaseDirectory&gt;false&lt;/includeBaseDirectory&gt; &lt;!--输出文件的配置 3个属性分别是 编译路径 输出路径 文件权限--&gt; &lt;fileSets&gt; &lt;fileSet&gt; &lt;directory&gt;src/main/resources&lt;/directory&gt; &lt;outputDirectory&gt;conf&lt;/outputDirectory&gt; &lt;fileMode&gt;0644&lt;/fileMode&gt; &lt;/fileSet&gt; &lt;fileSet&gt; &lt;directory&gt;src/main/assembly/bin&lt;/directory&gt; &lt;outputDirectory&gt;bin&lt;/outputDirectory&gt; &lt;includes&gt; &lt;include&gt;start.sh&lt;/include&gt; &lt;include&gt;stop.sh&lt;/include&gt; &lt;/includes&gt; &lt;fileMode&gt;0755&lt;/fileMode&gt; &lt;/fileSet&gt; &lt;fileSet&gt; &lt;directory&gt;src/main/assembly/bin&lt;/directory&gt; &lt;outputDirectory&gt;bin&lt;/outputDirectory&gt; &lt;includes&gt; &lt;include&gt;jvm.properties&lt;/include&gt; &lt;/includes&gt; &lt;filtered&gt;true&lt;/filtered&gt; &lt;fileMode&gt;0644&lt;/fileMode&gt; &lt;/fileSet&gt; &lt;/fileSets&gt; &lt;dependencySets&gt; &lt;dependencySet&gt; &lt;outputDirectory&gt;lib&lt;/outputDirectory&gt; &lt;/dependencySet&gt; &lt;/dependencySets&gt;&lt;/assembly&gt; 3.编写脚本 start.sh 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495969798#!/bin/shBASEDIR=`dirname $0`/..BASEDIR=`(cd &quot;$BASEDIR&quot;; pwd)`echo current path:$BASEDIRBASEBIN_DIR=$BASEDIR&quot;/bin&quot;cd $BASEBIN_DIRLAF_REG_INSTANCE=&quot;test-jsf-demo&quot;LOGPATH=&quot;&quot;LAF_REG_PIDPATH=&quot;$BASEBIN_DIR&quot;if [ &quot;$1&quot; != &quot;&quot; ] &amp;&amp; [ &quot;$2&quot; != &quot;&quot; ]; then LAF_REG_INSTANCE=&quot;$1&quot; LOGPATH=&quot;$2&quot;fiif [ &quot;$3&quot; != &quot;&quot; ]; then LAF_REG_PIDPATH=&quot;$3&quot;fi# ------ check if server is already runningPIDFILE=$LAF_REG_PIDPATH&quot;/&quot;$LAF_REG_INSTANCE&quot;_startup.pid&quot;if [ -f $PIDFILE ]; then if kill -0 `cat $PIDFILE` &gt; /dev/null 2&gt;&amp;1; then echo server already running as process `cat $PIDFILE`. exit 0 fifi# ------ set JAVACMD# If a specific java binary isn&apos;t specified search for the standard &apos;java&apos; binaryif [ -z &quot;$JAVACMD&quot; ] ; then if [ -n &quot;$JAVA_HOME&quot; ] ; then if [ -x &quot;$JAVA_HOME/jre/sh/java&quot; ] ; then # IBM&apos;s JDK on AIX uses strange locations for the executables JAVACMD=&quot;$JAVA_HOME/jre/sh/java&quot; else JAVACMD=&quot;$JAVA_HOME/bin/java&quot; fi else JAVACMD=`which java` fifiif [ ! -x &quot;$JAVACMD&quot; ] ; then echo &quot;Error: JAVA_HOME is not defined correctly.&quot; echo &quot; We cannot execute $JAVACMD&quot; exit 1fi# ------ set CLASSPATHCLASSPATH=&quot;$BASEDIR&quot;/conf/:&quot;$BASEDIR&quot;/root/:&quot;$BASEDIR&quot;/lib/*echo &quot;$CLASSPATH&quot;# ------ set jvm memorysed &quot;s/\r$//g&quot; jvm.properties &gt; 1.propertiesmv 1.properties jvm.propertiesif [ -z &quot;$OPTS_MEMORY&quot; ] ; then OPTS_MEMORY=&quot;`sed -n &apos;1p&apos; jvm.properties`&quot;fiif [ &quot;`sed -n &apos;2p&apos; jvm.properties`&quot; != &quot;&quot; ] ; then JAVA_CMD=&quot;`sed -n &apos;2p&apos; jvm.properties`&quot; if [ -f $JAVA_CMD ]; then JAVACMD=$JAVA_CMD fifi#DEBUG_OPTS=&quot;-Xdebug -Xnoagent -Djava.compiler=NONE -Xrunjdwp:transport=dt_socket,server=y,suspend=n,address=8000&quot;#JPDA_OPTS=&quot;-agentlib:jdwp=transport=dt_socket,address=8000,server=y,suspend=n&quot;# ------ run proxynohup &quot;$JAVACMD&quot; $JPDA_OPTS \ $OPTS_MEMORY $DEBUG_OPTS \ -classpath &quot;$CLASSPATH&quot; \ -Dbasedir=&quot;$BASEDIR&quot; \ -Dfile.encoding=&quot;UTF-8&quot; \ com.jd.testjsfdemo.TestjsfdemoApplication \ &gt; /Users/Logs/testjsfdemo_std.out &amp;# ------ wirte pid to fileif [ $? -eq 0 ]then if /bin/echo -n $! &gt; &quot;$PIDFILE&quot; then sleep 1 echo STARTED SUCCESS else echo FAILED TO WRITE PID exit 1 fi# tail -100f $LOGFILEelse echo SERVER DID NOT START exit 1fi stop.sh 1234567891011121314151617181920212223242526272829303132#!/bin/shBASEDIR=`dirname $0`BASEDIR=`(cd &quot;$BASEDIR&quot;; pwd)`echo current path $BASEDIRLAF_REG_INSTANCE=&quot;test-jsf-demo&quot;LAF_REG_PIDPATH=&quot;$BASEDIR&quot;if [ &quot;$1&quot; != &quot;&quot; ]; then LAF_REG_INSTANCE=&quot;$1&quot;fiif [ &quot;$2&quot; != &quot;&quot; ]; then LAF_REG_PIDPATH=&quot;$2&quot;fiPIDFILE=$LAF_REG_PIDPATH&quot;/&quot;$LAF_REG_INSTANCE&quot;_startup.pid&quot;echo $PIDFILEif [ ! -f &quot;$PIDFILE&quot; ]then echo &quot;no registry to stop (could not find file $PIDFILE)&quot;else kill $(cat &quot;$PIDFILE&quot;) sleep 10 kill -9 $(cat &quot;$PIDFILE&quot;) rm -f &quot;$PIDFILE&quot; echo STOPPEDfiexit 0echo stop finished. jvm.properties 12-Xms1024m -Xmx1024m -Xmn400m/Library/Java/JavaVirtualMachines/jdk1.8.0_181.jdk/Contents/Home/bin/java 4.编译后就成功啦，之后在jdos上配置一下就可以自动部署了]]></content>
  </entry>
  <entry>
    <title><![CDATA[观察者模式]]></title>
    <url>%2F2019%2F09%2F19%2F%E8%A7%82%E5%AF%9F%E8%80%85%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[观察者模式包含观察者和被观察者两个部分，原理也很简单，被观察者类中维护观察者对象的集合，当感兴趣的事件发生，遍历观察者的集合回调观察者对象中的相应方法（update）即可 被观察者除了维护观察者的集合外，还有对该集合的增（注册）、删（取消）及通知等操作 实现观察者123public interface Observer &#123; update(String msg);&#125; 1234567891011public class ObserverImpl implements Observer &#123; private String name = &quot;&quot;; Observer(String name)&#123; this.name = name; &#125; @override public void update(String msg)&#123; // 感兴趣的事件发生 System.out.println(msg); &#125;&#125; 被观察者123456public interface Observed&#123; registerObserver(Observer observer); removeObserver(Observer observer); notify(Observer observer); notifyAll();&#125; 1234567891011121314151617181920212223public class ObservedImpl implements Observed&#123; private static List&lt;Observer&gt; list = new ArrayList&lt;&gt;(); @Override public void registerObserver(Observer observer)&#123; list.add(observer); &#125; @Override public void removeObserver(Observer observer)&#123; list.remove(Observer); &#125; @Override public void notify(Observer observer)&#123; list.stream().filter(n -&gt; n.equals(observer)).update(&quot;notify&quot;); &#125; @Override public void notifyAll()&#123; list.stream().map(n -&gt; n.update(&quot;notifyAll&quot;)); &#125;&#125; 测试123456Observed o = new ObservedImpl();Observer o1 = new ObserverImpl(&quot;o1&quot;);Observer o2 = new ObserverImpl(&quot;o2&quot;);o.registerObserver(o1);o.registerObserver(o2);o.notifyAll(); Observer 和 Observablejdk中提供了观察者模式的API，java.util包下的Observer接口和Observable类，原理是一样的，这里只是进行的封装 上源码 Observer123public interface Observer &#123; void update(Observable o, Object arg);&#125; 和上面观察者的部分一样，实现一个回调方法，当感兴趣的事件发生回调该方法 使用时，实现Observer接口，重写update方法即可，当感兴趣的事件发生会回调update方法，这里会写增加的业务逻辑 Observable12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758public class Observable &#123; private boolean changed = false; private Vector&lt;Observer&gt; obs; public Observable() &#123; obs = new Vector&lt;&gt;(); &#125; public synchronized void addObserver(Observer o) &#123; if (o == null) throw new NullPointerException(); if (!obs.contains(o)) &#123; obs.addElement(o); &#125; &#125; public synchronized void deleteObserver(Observer o) &#123; obs.removeElement(o); &#125; public void notifyObservers() &#123; notifyObservers(null); &#125; public void notifyObservers(Object arg) &#123; Object[] arrLocal; synchronized (this) &#123; if (!changed) return; arrLocal = obs.toArray(); clearChanged(); &#125; for (int i = arrLocal.length-1; i&gt;=0; i--) ((Observer)arrLocal[i]).update(this, arg); &#125; public synchronized void deleteObservers() &#123; obs.removeAllElements(); &#125; protected synchronized void setChanged() &#123; changed = true; &#125; protected synchronized void clearChanged() &#123; changed = false; &#125; public synchronized boolean hasChanged() &#123; return changed; &#125; public synchronized int countObservers() &#123; return obs.size(); &#125;&#125; 同样，这里维护一个观察者的集合Vector，这里考虑了线程安全的问题，说明这种方式实现的观察者模式是线程安全的 除此之外还有一个bool类型的变量changed表示被观察者是否发生改变（也就是感兴趣的事件是否发生），通过该标志来通知观察者对象 同样，该类里有针对观察者集合的增、删、通知的操作，还多了对changed标志修改的操作；除此之外所有方法都有synchronized关键字，进一步说明了这种方式的观察者模式是线程安全的 使用时，在要被观察的类中继承Observable类，再添加实现了Observer接口的观察者对象，调用setChanged()方法改变changed标志后通过调用notify()方法进行通知]]></content>
      <categories>
        <category>设计模式</category>
      </categories>
      <tags>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Zookeeper扫盲]]></title>
    <url>%2F2019%2F08%2F29%2FZookeeper%E6%89%AB%E7%9B%B2%2F</url>
    <content type="text"><![CDATA[Zookeeper是一个分布式协调服务框架，这句话对于刚接触ZK（Zookeeper下文简称ZK）的我来说太抽象了，很难理解，只知道它能提供一些服务能够实现配置管理、命名服务、分布式锁等等，也就是在这些场景下会使用到ZK，这样说好像还是很难理解；之后，我找到了一个比较好理解的点，就是从CAP理论的角度，这需要对CAP有些了解，提前做了功课(CAP和BASE)，简单来说在分布式系统中出现网络故障时，最多满足其中的两项，而P是必须要满足的，那么就需要从CP和AP中做选择了；ZK就是可保证CP的框架，最后我的理解就是ZK通过特定的数据结构，封装一系列算法通过API的方式提供分布式环境数据一致性的服务，所有需要数据一致性的场景都可以使用ZK，也就是上面提到的配置管理、命名服务、分布式锁等等场景 入门数据结构ZK提供了一套类似于文件目录的数据结构，叫做多层级的节点命名空间，每个节点（ZK中称为znode）都可以存放数据且每个节点下都有若干个子节点，听起来和树的结构差不多，其实也一样，目录也是一种树结构的实现，znode可以理解为文件夹，文件夹中可以存放文件（znode可以存放数据），也可以存放文件夹（znode也可以存放znode） znode的类型 PERSISTENT–持久化目录节点 客户端和ZK断开连接后节点依然存在 PERSISTENT_SEQUENTIAL–持久化顺序编号目录节点 与持久化目录节点相同，只是多了ZK对节点的顺序编号 EPHEMERAL–临时目录节点 客户端和ZK断开连接后节点被删除 EPHEMERAL_SEQUENTIAL–临时顺序编号目录节点 与临时目录节点相同，只是多了ZK对节点的顺序编号 通知机制ZK还提供了类似于观察这模式的通知机制，称为watcher事件，可以观察到znode的变化，来通知客户端，之后客户端再做相应的业务逻辑 使用场景命名服务这里命名服务指的是通过指定名字获取对应的资源，将资源存储在特定路径的znode中，根据路径就可以找到资源，类比目录结构来说，拿到文件的地址就能通过地址来找到文件，有点像是URL的意思，但是由于ZK数据结构设计的因素ZK不能存放较大的数据；微服务框架中的注册中心需要存放provider和consumer的信息，并且consumer要能够感知provider的实时状态，ZK可以根据provider和consumer的地址映射成临时znode结构，这样既保存了provider和consumer的信息还能感知彼此的状态 配置管理一句话解释—-动态下发配置文件变化；通过ZK客户端watch配置文件，一旦配置文件发生变化马上通知客户端做对应的处理 分布式锁多个客户端再ZK的同一个目录下尝试创建临时znode，成功创建znode意味着获得锁成功，下个客户端发现目录下已经存在znode则对该znode添加watch机制，当znode消失即为释放锁后，通知客户端尝试创建znode来获取锁，这是公平锁；非公平锁的则创建临时有序的znode，相当于一个队列，后面的节点watch前一个节点的znode的状态，队头的znode为获得锁成功的几点 选举算法ZK节点的状态 LOOKING–当前节点不知道leader是谁，正在搜索 LEADING–当前节点为集群的leader FOLLOWING–目前已有leader，当前节点负责与leader节点同步 选举过程在两种情况下会进行选举，1.服务器初始化启动 2.集群中leader节点故障 起初集群中的节点没有leader或者不知道leader是谁，此时节点的状态为LOOKING，如果当前集群存在leader（该节点新加入集群），此节点发送投票信息想要选举leader会被告知当前leader的信息，此节点只需和leader节点建立连接，并进行状态同步即可； 如果当前集群不存在leader节点，则需要投票进行选举 此时所有节点皆为LOOKING状态，并编辑投票信息发送给集群的其他节点，投票信息的格式为（SID,ZXID）（服务器的唯一标识，事务ID），SID是自己配置的，ZXID理解为当前节点数据的版本； 集群中的节点会受到其他节点的投票信息，加上自己的那一票会根据一个规则会投出第二轮的选票 节点会在自己收到的选票中，选择ZXID最大的作为第二轮的选票发送给集群中其他节点 如果ZXID相同则选择SID最大的作为第二轮的选票发送给集群中其他节点 集群中的节点在接收到第二轮选票后进行统计（包含自己的一票），获得集群中一半以上（&gt;n/2）数量投票的节点当选leader进入LEADING状态，其余节点进入FOLLOWING状态 总结一下，集群中要获得一半以上的投票才能当选leader，所以集群最少为3台，并且数量是奇数；集群中ZXID越大的节点（当前节点数据版本越新）优先当选leader 安装与启动整个过程没有难度也很好理解，跟着这篇文章做就完事了 最后本文是对于Zookeeper的扫盲，大致了解ZK的基本原理，为了更好的理解工作中的项目，具有目的性，一些细节没有去研究，下回再补，😋 参考资料ZooKeeper典型应用场景一览 笔记：Mac上zookeeper的安装与启动 zookeeper面试题]]></content>
      <categories>
        <category>分布式</category>
      </categories>
      <tags>
        <tag>分布式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CAP和BASE]]></title>
    <url>%2F2019%2F08%2F26%2FCAP%E5%92%8CBASE%2F</url>
    <content type="text"><![CDATA[CAP理论Consistency（一致性） Availability（可用性） Partition tolerance（分区容错性） CAP理论的内容是在分布式系统中出现网络故障时最多只能满足CAP中的两项 Consistency 一致性 “all node see the same data at the same time” 就是指分布式系统的数据一致性，可用看出这里的一致性指的是强一致性，要求分布式系统数据发生改变后所有节点在后续的请求中都能感知到 强一致性，当数据发生改变，系统中的其他节点在下次请求都会感知到 弱一致性，保证某个时间级别（比如xx秒），数据能够达到数据一致的状态 最终一致性，弱一致性的一个特例，保证在一段时间内达到数据一致的状态 Availability 可用性 “Reads and Writes always succeed”，这里的succeed指的是请求和响应的过程成功，也每次请求都会在有限的时间内收到回复，换句话说就是服务器可用；并不是请求的返回值是成功的意思，返回值是失败也是有返回值的，同样说明请求响应的过程是成功的。 系统可用性5个9，意为分布式系统的可用水平为99.999%，全年停机时间不超过 (1-0.99999)36524*60 = 5.256 min Partition tolerance 分区容错性 “the system continues to operate despite arbitrary message loss or failure of part of the system” 分区指的是由于网络异常集群中只有部分节点能够正常通信，可能存在多个能够通信的子网络，这些子网络就是分区；又或者说集群中部分服务器宕机，其他服务器依然可用，这部分可用的服务器组成的子网络也可以称为分区。分区容错性是指当出现网络延迟或者故障的情况时系统依然能够提供服务 怎么理解呢？简单来说就是在分布式系统中发生故障时，CAP最多只能满足其中的两项，也就是CAP三选二呗，但是我们发现P（分区容错性）说白了就是指网络出问题后系统依然可用，这可是分布式系统的基础条件，应该必须满足；在满足分区容错性时有可能会存在两种问题 1.用户访问部分服务器间的网络异常，这时只需将请求转发到可用的服务器即可，这时在理想情况下（服务器间的网络通畅）是可以满足CAP的，除非和所有服务器的网络都有问题（这只是理想情况） 2.除了用户访问服务器的网络异常之外，分布式系统中不同服务器直接的网络也可能存在异常，例如分布式系统中有A、B两台服务器，假设A、B之间存在网络故障，当服务器A改变数据之后无法同步到服务器B，此时就不能保证强一致性和可用性同时满足 放弃强一致性（C），用户请求A可以得到最新的数据，用户请求B得到的是旧数据；可以保证用户每次请求都会返回结果，但不能保证数据的一致性 放弃可用性（A），为了保证数据的强一致性，数据每次修改后都需要等待所有的数据源都同步后才能进行读写，用户请求服务器A或者B，由于数据始终不能同步，最后会一直阻塞下去，不能保证用户的每次都能短时间内得到返回值甚至得不到返回值 综上，我认为的CAP理论是在分布式系统中服务器之间网络出现问题时，CAP最多只能满足其二，并不是分布式系统就只能满足CAP中的两项，理想情况下是都可满足的（虽然现在不大可能）；况且在分布式系统中P是必须满足的，也就是说CA只能满足其一，具体的取舍需要根据不同的业务场景权衡 BASE理论 Basically Available（基本可用） 系统设计中可以牺牲部分可用性，比如允许响应时间增加1-2秒，服务降级等 Soft state（软状态） 允许系统中的数据存在中间状态，允许数据同步过程存在延迟 Eventually consistent（最终一致性） 所有数据再一段时间的数据同步后都能达到一致的状态 综上，不同的业务以BASE理论为基础对可用性和一致性进行一个权衡；zk和数据库的主从都是舍弃高可用性；涉及到用户体验的场景则需要舍弃数据强一致性如12306买火车票，618和双11等对于用户的每个请求都需要给与响应，允许存在短时间数据不一致的状态 参考资料]]></content>
      <categories>
        <category>分布式</category>
      </categories>
      <tags>
        <tag>分布式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[缓存更新的套路 总结与感受]]></title>
    <url>%2F2019%2F08%2F21%2F%E7%BC%93%E5%AD%98%E6%9B%B4%E6%96%B0%E7%9A%84%E5%A5%97%E8%B7%AF-%E6%80%BB%E7%BB%93%E4%B8%8E%E6%84%9F%E5%8F%97%2F</url>
    <content type="text"><![CDATA[注： 本文是阅读 [缓存更新的套路] (https://coolshell.cn/articles/17416.html) 一文的总结，本文是以经常用到的Redis+MySQL的角度解读 经典方法 – Cache Aside Pattern 读操作：先从Redis中获取，没有命中则从MySQL中获取，最后更新到Redis中 写操作：先写MySQL，成功后删除Redis中的数据 为什么这样的方案会是经典方法呢？因为简单，有效，错误少 场景1–写操作如果先删除Redis中的数据再操作数据库 如果一个写操作和读操作并发执行，写操作删除了Redis中的数据还没来得及将数据更新到MySQL中，读操作没有在Redis中读取到数据，而从MySQL中读到旧的数据并更新到了Redis中，这样虽然MySQL中的数据是正确的，因为Redis的存在使得每次读取的数据都是脏数据。（这种情况只会发生在删除Redis数据后，写MySQL前这段时间，因为写MySQL时可以通过加悲观锁来避免问题） 场景2–写操作后增加更新Redis数据 这样读和写的操作都会更新Redis数据看似更稳健了，其实不然，更新操作变多了脏数据也会变多，比如有两个写操作a和b，按照请求的时间来说最终的状态应该是b，极端情况下ab都完成了更新数据库的操作，在更新Redis的时候，b先完成了，随后a完成又将Redis数据改成了a的状态，这样还是会存在脏数据 ，虽然出现的概率不大相对于经典方法多了产生脏数据的可能性，所以不可取 场景3–脏数据 经典方法可以避免场景1和2的问题，但也不是万无一失的，当一个读操作在Redis中没有命中时，从MySQL中获取了数据，在更新Redis数据之前，有一个写操作完成，此时MySQL的数据已经变了，而读操作会把之前的数据写入Redis中，产生脏数据。而这样的场景发生的几率非常非常小，由于MySQL锁的限制，只能发生在读操作读取数据之后读操作更新Redis数据之前，并且这段时间有一个写操作完成，同样因为锁的存在写操作一般都比读操作会耗时，并且给Redis数据增加过期时间进一步减小脏数据的产生几率 综上所述，虽然经典方法在场景3略有瑕疵，但依然经典可用，因为其简单，有效，错误少 Read/Write Through Pattern 读操作：Redis命中直接返回；没有命中从MySQL中读取后更新到Redis中 写操作：Redis中命中更新Redis,在同步的更新到MySQL；没有命中更新MySQL 这种模式写操作主要依赖一个数据源（MySQL或者Redis），读数据时在Redis中没有命中会从MySQL中读取到Redis中，长时间运行后大部分数据都会在Redis中命中，写操作也会针对于Redis并由Redis同步的进行写入MySQL，相当于是强依赖于Redis，弱依赖甚至不依赖于MySQL，至于为什么未命中不直接写Redis还没想明白~ Write Behind Caching Pattern 读操作：Redis命中直接返回；没有命中则从MySQL中获取数据返回 写操作：无论Redis命中与否都先更新Redis，接着异步更新MySQL中的数据 原文中也提到，这么做会极大的提高I/O，相当于只操作了Redis，是内存级别的读写，同时这么做也有缺点，就是在同步数据到MySQL时如果服务器宕机断电等事故将会永久性的数据丢失 精彩评论摘取了一些大佬们的评论，很有启发 一位名叫 ty 的大佬说：”Cache Aside Pattern模式，两个更新操作同时进来，也可能会有cache脏数据的问题啊顺序如下：第一个写数据库，第二个写数据库，第二个写cache，第一个写cache这样cache里是第一个数据，而数据库里是第二个“ ——–这和我想的是一样的，哈哈 一位名叫 letsgowei 的大佬说：”在做更新操作时不可以更改数据库后直接更新缓存吗？这样最多也就一两次脏数据“ ——–这位大佬的疑惑应该是为什么更新操作只是删除缓存或者把缓存设置为无效，而不是更新缓存呢？还有一位评论有同样的疑惑；这个问题我没有考虑到，觉得他们说的有道理直接更新也可以啊？ 一位名叫 longsen 的大佬做出了解答：”1. 读线程查key未在cache中；2.读线程从db读数据；3.写线程更改数据库；4.写线程看key未在cache中，无法更新cache；5.读线程将旧数据写入cache中。这种场景旧数据可能在cache存在很长时间“ ——–大佬给出的解释是cache中没有key无法更新，I don’t think so！至少在Redis的环境下是不存在的，key不存在直接set，key存在直接覆盖，Redis是有这样的命令的，所以这个回答我不同意，如果将写MySQL后将Redis中的key删除的操作，改成更新Redis的Key操作，这样一来就和我上面提到的场景2是一样的的了，读写都更新Redis增加了产生脏数据的概率，所以是不可取的 一位名叫 泪滴 的大佬说：”大神！你的这个更新顺序是建立在更新数据库，更新缓存都不会发生失败的情况下的，单独考虑并发问题得到的顺序！方案1：先更新数据库，再删除缓存，当出现并发问题概率很小(假设概率为R1)，会造成脏数据。当出现网络等问题导致删除缓存失败(假设概率为R2)，会导致之后的请求一直是脏数据。方案2：先删除缓存，再更新数据库，当出现并发问题概率较大(假设概率为R3)，会导致之后的请求一直是脏数据，当出现网络问题，删除缓存成功，更新数据库失败，只会引发一次cache miss，在业务上基本没啥影响。当然为了弥补，我们一般都会设置缓存的过期时间，来缩短出现脏数据的时间。现在问题的关键就是R1+R2和R3的大小问题了，如果大厂，网络基础设施啥的比较牛，当然R1+R2&lt;R3选择方案1比较合适，对于广大小厂来说还真的可能R1+R2&gt;R3那怎么选择，就比较清楚了。“ ——–说实话，他的评论让我眼前一亮，他的分析具体到了应用场景上，而且确实有这样的情况出现，所以说没有最完美的设计只有最合适的设计，给这位大佬点赞 还有一些则是针对于原文中Write Behind Caching Pattern部分的流程图的疑问，例如缓存未命中为什么回写数据再更新数据，直接更新数据不就好了吗？写数据未命中为什么还有判断dirty的标志？等等，这些问题我也不懂，云里雾里的，不知道为什么这么设计，不就是异步更新MySQL吗，搞这么复杂是为什么，后来我冷静的分析一下，这篇文章是缓存更新的套路，当前部分是缓存异步更新MySQL的介绍，而流程图和异步半毛钱关系都没有，为什么？ ——–因为我太垃圾了，文章中 xxPattern 指的是Linux内核中的缓存更新模式，作者是将这些模式应用到分布式环境下缓存更新中，所以说这部分的流程图是指Linux内核的缓存更新而不是分布式环境下的缓存更新，作者在文章中不止一次提到了基础很重要就体现出来了，而且作者也提到宏观的系统架构设计其实和计算机系统结构中微观的设计是相似的，所以想要设计好一个大型的分布式系统必须对计算机系统结构非常了解 综上所述–基础很重要 以上是我拜读耗子哥的《缓存更新的套路》一文后的一些总结和思考，推荐大家读原文哦！]]></content>
      <tags>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[一次Spring事务不回滚的踩坑记录]]></title>
    <url>%2F2019%2F08%2F16%2F%E4%B8%80%E6%AC%A1Spring%E4%BA%8B%E5%8A%A1%E4%B8%8D%E5%9B%9E%E6%BB%9A%E7%9A%84%E8%B8%A9%E5%9D%91%E8%AE%B0%E5%BD%95%2F</url>
    <content type="text"><![CDATA[一次Spring事务不回滚的踩坑记录Spring事务不回滚八成是不知道Spring默认在捕获到unchecked异常才会自动回滚，然而我早已踩过个坑，是一个有经验的人，当我自信满满的加上一行 1/0，并在catch中 throw new RuntimeException，debug之后我懵了，咋不回滚呢？重启Tomcat，浏览器缓存清理之后再试一次，还是不行！！！我就难受了，这和我预想的不一样，检查代码没有发现错误，那咋办呢？开始百度吧，百度的结果千篇一律，都是针对不了解Spring默认捕获unchecked异常的解决办法，这些早已在我的经验里了，有3种方法 1.手动抛出unchecked异常，让Spring去捕获，然后自动回滚数据 2.手动回滚，在发生异常的地方添加代码 TransactionAspectSupport.currentTransactionStatus().setRollbackOnly(); 3.在注解的地方添加配置rollbackFor = { Exception.class }，让Spring在捕获到特定的异常自动回滚数据 3种方法我都知道，但是我一般只用第一种，因为简单，这次我选择用第二种方法试下，竟然没问题了，我意识到是我的问题了，开始检查代码，我的代码逻辑如下（见笑） 1234567891011121314boolean result = false;try &#123; // ...业务逻辑 System.out.println(1/0); // ...业务逻辑 result = true;&#125; catch (Exception e) &#123; LOGGER.error(e.getMessage(), e); // rollback throw new RuntimeException(e); result = false;&#125; finally &#123; return result;&#125; 还是不知道错在哪里，没有办法开始Debug，惊奇的发现RuntimeException竟然被忽略了，这才发现我finally中有return，被我自己蠢哭了，基础真是太重要了，我还盲目自信的知道Spring的事务如何使用，到头来连try catch finally都没搞清楚，真是太蠢了。接着我修改了代码： 123456789101112boolean result = false;try &#123; // ...业务逻辑 System.out.println(1/0); // ...业务逻辑 result = true;&#125; catch (Exception e) &#123; LOGGER.error(e.getMessage(), e); // rollback throw new RuntimeException(e);&#125; return result; 这下确实是回滚了，但是返回值是true，想得到的时false，这又难受了，再次Debug，很多次F6后我明白了，RuntimeException是被Spring框架里的层层代理catch了————————————————————————————————————————————————————————————–我把我自己给骗了，RuntimeException抛出程序已经终止了，即使再多的catch最后也不会回到result = true那一行，最终得出原因是其他ajax请求的结果返回到了前台给的提示让我误解了 到这里我意识到自己是真的菜，补习一下try catch finally吧找到一篇好文 总结一下 如果finally中有return，try和catch中的return会失效，并且catch中即使抛出unchecked异常也同样会失效（这是今天踩的坑）；如果finally中有异常相当于整个方法有了异常，那么就没有最终的返回值了,catch中有了异常同样的效果，所以catch和finally中不要出现异常 如果finally中没有return，try和catch中走最先到达return逻辑的地方，并且在return前将返回值暂存，即使finally中修改也不会有效果；（也就是说没有异常最先到达try块中的return，返回值是try块的返回值，catch和finally修改也不会生效；如果try块有异常最先到达catch块中的return，返回值是catch块的返回值，前提是catch块中没有异常，有异常整个方法都没有返回值） 综上所述，使用Spring事务避免不出错优先使用方法2和方法3，方法1比较绕并且对有返回值的逻辑不是很友好；finally块中尽量不要return，这样会忽略try和catch中的异常；最后，基础真的很重要]]></content>
      <tags>
        <tag>Spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Optional 使用及源码]]></title>
    <url>%2F2019%2F08%2F15%2FOptional%2F</url>
    <content type="text"><![CDATA[Optional 使用及源码分析A container object which may or may not contain a non-null value. 可能包含空值的容器对象。 怎么理解呢？就把它当成是和Collection一样的容器，Collection是通过不同的数据结构和API来操作容器中的元素；Optional则是提供API来判断容器中的元素是否为空，在此基础上还能根据是否为空的不同结果给出自定义的处理逻辑。这么说还是很抽象，直接上源码就会好理解一些。 成员变量1234// 空的Optional对象private static final Optional&lt;?&gt; EMPTY = new Optional&lt;&gt;();// 容器中元素的值private final T value; 这个value是容器中元素的值，怎么理解呢，使用Optional是要通过它的API进行判空来达到避免NPE的现象，上面说到将Optional当成是一个容器，这个容器中的元素则是需要判空的对象，也就是说容器中的元素就是你传入的参数，这个value就是传参的值 构造方法无参构造，只是将value置为null 123private Optional() &#123; this.value = null;&#125; 有参构造 123private Optional(T value) &#123; this.value = Objects.requireNonNull(value);&#125; 其中返回Objects中的requireNonNull的方法，再看这个方法 12345public static &lt;T&gt; T requireNonNull(T obj) &#123; if (obj == null) throw new NullPointerException(); return obj;&#125; 很简单如果obj为空抛出异常，不为空返回本身，所以有参构造的效果就是确认value不为空并给value赋值，如果是空就抛异常 而且这两个构造函数是私有的，也就是说我们不能new出来 主要方法 empty()–返回空的Optional对象 1234public static &lt;T&gt; Optional&lt;T&gt; empty() &#123; Optional var0 = EMPTY; return var0;&#125; of(T var1)–调用了有参构造，即有值返回带有该值得Optional对象，为空则会抛异常 123public static &lt;T&gt; Optional&lt;T&gt; of(T var0) &#123; return new Optional(var0);&#125; ofNullable(T var0)–元素为null返回空的Option对象，不是null返回本身 123public static &lt;T&gt; Optional&lt;T&gt; ofNullable(T var0) &#123; return var0 == null ? empty() : of(var0);&#125; get()–从名字就可以看出是获取元素的值，也就是返回value，如果是null的话会抛异常 1234567public T get() &#123; if (this.value == null) &#123; throw new NoSuchElementException(&quot;No value present&quot;); &#125; else &#123; return this.value; &#125;&#125; isPresent()–返回value是否为null 123public boolean isPresent() &#123; return this.value != null;&#125; ifPresent(Consumer&lt;? super T&gt; var)–如果元素不是空的话执行var1中的逻辑，Consumer之前有文章写过，是接收一个参数执行一个没有返回值得逻辑 12345public void ifPresent(Consumer&lt;? super T&gt; var1) &#123; if (this.value != null) &#123; var1.accept(this.value); &#125;&#125; filter(Predicate&lt;? super T&gt; var1)–首先确保predicate对象和value不是null，然后用predicate对象对value进行筛选，满足条件返回本身，不满足条件返回空的对象（看源码是这个意思，具体怎什么情况用还想不到~） 12345678public Optional&lt;T&gt; filter(Predicate&lt;? super T&gt; var1) &#123; Objects.requireNonNull(var1); if (!this.isPresent()) &#123; return this; &#125; else &#123; return var1.test(this.value) ? this : empty(); &#125;&#125; map(Function&lt;? super T, ? extends U&gt; var1)–同样确保var1不是null，之后value为空值返回空的Optional对象，value有值执行var1中的逻辑 1234public &lt;U&gt; Optional&lt;U&gt; map(Function&lt;? super T, ? extends U&gt; var1) &#123; Objects.requireNonNull(var1); return !this.isPresent() ? empty() : ofNullable(var1.apply(this.value));&#125; flatMap(Function&lt;? super T, Optional&lt; U &gt;&gt; var1)–与map方法相同,不同的是入参，根据不同的参数结构使用不同的方法 1234public &lt;U&gt; Optional&lt;U&gt; flatMap(Function&lt;? super T, Optional&lt;U&gt;&gt; var1) &#123; Objects.requireNonNull(var1); return !this.isPresent() ? empty() : (Optional)Objects.requireNonNull(var1.apply(this.value));&#125; T orElse(T var1)–获取value的值，不为空返回本身，为空返回入参var1 123public T orElse(T var1) &#123; return this.value != null ? this.value : var1;&#125; T orElseGet(Supplier&lt;? extends T&gt; var1)–与orElse的逻辑一样，不同的是value为空返回的是supplier对象的逻辑 123public T orElseGet(Supplier&lt;? extends T&gt; var1) &#123; return this.value != null ? this.value : var1.get();&#125; T orElseThrow(Supplier&lt;? extends X&gt; var1)–同样的逻辑，不同的是value为null会抛异常 1234567public &lt;X extends Throwable&gt; T orElseThrow(Supplier&lt;? extends X&gt; var1) throws X &#123; if (this.value != null) &#123; return this.value; &#125; else &#123; throw (Throwable)var1.get(); &#125;&#125; 总结 of和ofNullable 都是取值，如果元素是null的话of会报空指针–不用，ofNullable将null转为空的对象没有空指针； get方法同样是取值，value是null也会抛异常–不用 最后，取值用ofNullable就完事了 isPresent和ifPresent isPresent返回元素是否为null，有返回值 ifPresent元素不为空执行一段逻辑，无返回值 最后，只判断用isPresent有逻辑用ifPresent filter、map和flatMap 都是将不是null的元素执行传入的逻辑，根据不同的需求选择方法 orElse、orElseGet和orElseThrow 都是将null的元素做转换，orElse返回传入的值，orElseGet返回传入的逻辑，这两个方法看需求没有逻辑有orElse有逻辑用orElseGet；orElseThrow元素为null抛异常–不用 栗子刚刚学习还不知道怎么使用，看到[一篇文章]（https://www.cnblogs.com/rjzheng/p/9163246.html） 给的栗子不错，很有借鉴意义，但是我对这篇文章中的orElse和orElseGet的栗子有不同意见。 栗子1 使用前 1234567891011public String getCity(User user) throws Exception&#123; if(user!=null)&#123; if(user.getAddress()!=null)&#123; Address address = user.getAddress(); if(address.getCity()!=null)&#123; return address.getCity(); &#125; &#125; &#125; throw new Excpetion(&quot;取值错误&quot;); &#125; 使用后 123456public String getCity(User user) throws Exception&#123; return Optional.ofNullable(user) .map(u-&gt; u.getAddress()) .map(a-&gt;a.getCity()) .orElseThrow(()-&gt;new Exception(&quot;取指错误&quot;));&#125; 栗子2 使用前 123if(user!=null)&#123; dosomething(user);&#125; 使用后 1234Optional.ofNullable(user) .ifPresent(u-&gt;&#123; dosomething(u); &#125;); 栗子3 使用前 123456789101112public User getUser(User user) throws Exception&#123; if(user!=null)&#123; String name = user.getName(); if(&quot;zhangsan&quot;.equals(name))&#123; return user; &#125; &#125;else&#123; user = new User(); user.setName(&quot;zhangsan&quot;); return user; &#125;&#125; 使用后 123456789public User getUser(User user) &#123; return Optional.ofNullable(user) .filter(u-&gt;&quot;zhangsan&quot;.equals(u.getName())) .orElseGet(()-&gt; &#123; User user1 = new User(); user1.setName(&quot;zhangsan&quot;); return user1; &#125;);&#125;]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mac 设置]]></title>
    <url>%2F2019%2F08%2F13%2Fmac-%E8%AE%BE%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[外接键盘的调整键盘设置中将control和command互换就可以达到和Windows下的复制粘贴时一样的，切换程序则由alt+tab变成了ctrl+tab需要适应一下，不过复制，粘贴，撤销，保存这些不用再去适应新的快捷键了 idea中的调整preferences中找到keymap选择Eclipse(macOS)，这样加上第一步的配置复制粘贴这些快捷键与Windows相同，不用再去适应新的快捷键 自动补全变量keymap中搜索variable 默认为：option+command+L 通过以上设置后为：Ctrl+alt+L 另一种使用方法不做任何配置，idea中使用eclipse风格的快捷键，idea中的使用不影响，但是在idea以外就得适应mac中的快捷键，感觉还是这个方法更容易接受一些]]></content>
  </entry>
  <entry>
    <title><![CDATA[Lambda表达式]]></title>
    <url>%2F2019%2F08%2F05%2FLambda%E8%A1%A8%E8%BE%BE%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[语法包含3个部分：参数 -&gt; 表达式/代码块 (params) -&gt; expression (params) -&gt; statement (params) -&gt; { statements } 与内部类相同，lambda表达式不可以修改外部变量，这点与匿名内部类相同，不同的是lambda表达式不用将变量显示的声名为final，如果是在自己的作用域中定义局部变量可以进行修改，最终保证线程安全 （踩坑）lambda表达式中的this并不是代表当前使用lambda表达式的对象，而是外部类的对象 作用可代替匿名内部类 可以代替只包含一个抽象方法的接口，也叫做函数式接口，例如；Comparator、Runnable Java8内置了四大函数式接口分别为：Consumer，Supplier，Function，Predicate jdk8中提供@FunctionalInterface 注解来检查接口是否符号函数式接口的标准 可代替迭代操作 list.forEach(n -&gt; {}); 通过Stream操作集合 list.stream().filter()…collect(); 对数据处理 与Spark相似java8可以将集合转化为流（Stream），在对流进行map和reduce操作，与Spark相同这些方法也是惰性求值的 Java8的函数式接口消费型接口 Consumer 抽象方法-void accept(T t); 参数类型-T 返回类型-void 这个还没有用过，因为返回值为空并且传递一个参数，我感觉和集合的遍历差不多 list.forEach(n -&gt; sout(n)); 通过定义多个Consumer对象相当于定义多个逻辑块，最终consumer1.addThen(consumer2) 连接，也就是说consumer1逻辑完成后执行consumer2（为什么不写在一个逻辑里呢？我猜可能需要解耦吧） 供给型接口 Supplier 抽象方法-T get(); 参数类型-无参数 返回类型-T 这个感觉很简单，没有参数但要返回一个值，可能new一个对象的时候会用到吧，声名Supplier对象后直接调用get执行定义的逻辑（箭头后面的逻辑）返回一个值 函数型接口 Function&lt;T,R&gt; 抽象方法-R apply(T t) 参数类型-T 返回类型-R 同样是创建Function对象定义一个方法逻辑，接口中有Consumer接口同样的实现方法andThen，用法也相同，不同的是Function定义中有返回值，fun1.addThen(fun2)是将fun1执行的返回值传入fun2中再执行fun2中的逻辑，除此之外该接口还有一个实现方法compose，用法和andThen相反，fun1.compose(fun2) 是先执行fun2中的逻辑将返回值作为参数传入fun1中再执行fun1中的逻辑 断言型接口 Predicate 抽象方法-boolean test(T t) 参数类型-T 返回类型-boolean 定义的Predicate对象相当于筛选条件的对象，最终通过stream中的filter进行过滤，多个条件可以用and和or来进行组合相当于运算符 &amp;&amp; 和 || 多用做集合筛选 eg: 1234// 筛选大于18岁的女性用户Predicate&lt;User&gt; matchAge = u -&gt; u.age &gt; 18;Predicate&lt;User&gt; matchSex = u -&gt; u.sex.equals(&quot;f&quot;);resultList = userList.stream().filter(matchAge.and(matchSex)).collect(Collectors.toList()); 我的理解是在定义Predicate的对象时，-&gt; 前传入参数， -&gt; 后定义test的方法体，最终补充抽象方法test，通过stream的filter筛选相当于将集合中的每个元素都调用一次test方法，将返回值为true的筛选出来。]]></content>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[StringUtils]]></title>
    <url>%2F2019%2F07%2F26%2FStringUtils%2F</url>
    <content type="text"><![CDATA[StringUtils 工作中很多操作字符串的操作，使用到了工具类这里总结下，org.apache.commons.lang3包下的 split(String str, String separatorChars)–&gt;切分字符串123public static String[] split(String str, String separatorChars) &#123; return splitWorker(str, separatorChars, -1, false);&#125; 参数： int max -&gt;the maximum number of elements to include in the array. A zero or negative value implies no limit.这个参数代表返回的字符串的最大长度，0或者-1代表不限制长度 boolean preserveAllTokens -&gt; if {@code true}, adjacent separators are treated as empty token separators; if {@code false}, adjacent separators are treated as one separator. 这个参数是连续分隔符规则的标志，如果为true连续的分隔符都会匹配，最终得到的字符串数组会有空的值，jdk中的split就是这个规则；如果为false，连续的分隔符只会匹配一次，最终得到的数组不会有空值。eg(“1,2,3,,4,5”切分后，true得到[1,2,3,,4,5]而false得到[1,2,3,4,5])， 这也是与jdk中的split方法的区别，如果需要使用与jdk相同的规则，工具类中的splitPreserveAllTokens方法可以实现，该方法会调用splitWorker方法且最后的参数为true 所以split方法默认参数为-1和false表示数组长度不收限制，及使用第二个规则进行切割，确保得到的字符串数组没有空值原理： 先将字符串与分隔符做匹配 匹配到之后将分隔符之前的子串分割add到一个list集合中 最后使用list.toArray返回最终的数组 join 待续]]></content>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Arrays]]></title>
    <url>%2F2019%2F07%2F26%2FArrays%2F</url>
    <content type="text"><![CDATA[ArrayscopyOf123456789public static &lt;T,U&gt; T[] copyOf(U[] original, int newLength, Class&lt;? extends T[]&gt; newType) &#123; @SuppressWarnings(&quot;unchecked&quot;) T[] copy = ((Object)newType == (Object)Object[].class) ? (T[]) new Object[newLength] : (T[]) Array.newInstance(newType.getComponentType(), newLength); System.arraycopy(original, 0, copy, 0, Math.min(original.length, newLength)); return copy;&#125; 先看要被拷贝到的数组长度是不是够用，够用的话直接调用System.arraycopy方法；不够用创建一个新的与源数组同样长度的数组进行拷贝如果数组中是引用类型，Arrays.copy拷贝的是引用，不会新创建对象，如果要对拷贝的数组做修改操作源数组同样会受到影响，而字符串数组由于字符串常量池的存在，当修改字符串的时候会新创建一个字符串并将新的引用付给数组，所以源数组对应的字符串并不会发生变化 System.arraycopy123public static native void arraycopy(Object src, int srcPos, Object dest, int destPos, int length); 这是一个本地方法，就看一下参数吧 src—-the source array. srcPos—-starting position in the source array. dest—-the destination array. destPos—-starting position in the destination data. length—-the number of array elements to be copied. asList将字符串转成ArrayList集合 123public static &lt;T&gt; List&lt;T&gt; asList(T... a) &#123; return new ArrayList&lt;&gt;(a);&#125; 这里的ArrayList是Arrays中的一个内部类，继承了AbstractList方法，内部值实现了部分方法，简单点说这个集合是只读的，不能进行修改和删除操作，因为没有重写相关的方法。 copyOfRange按照范围拷贝数组 [from,to) 左开右闭123public static &lt;T&gt; T[] copyOfRange(T[] original, int from, int to) &#123; return copyOfRange(original, from, to, (Class&lt;? extends T[]&gt;) original.getClass());&#125; sort集合工具类 Collections.sort 其实就是调用 Arrays.sort 方法对集合进行排序的，该方法先调用 toArray 方法将集合转成object数组，然后再调用 Arrays.sort 方法对数组进行排序，最后再将排序号的数组通过迭代器set到新的集合中去。 123456public static void sort(Object[] a) &#123; if (LegacyMergeSort.userRequested) legacyMergeSort(a); else ComparableTimSort.sort(a, 0, a.length, null, 0, 0);&#125; 可以看到sort方法是通过userRequested的标志来选中排序的方式，从jdk7以后默认为false，使用TimSort的方式排序，（通过System.setProperty(“java.util.Arrays.useLegacyMergeSort”, “true”)修改） userRequested为true使用LegacyMergeSort的方式进行排序，当数组长度小于7时使用插入排序，当数组长度大于7时使用归并排序，归并到长度小于7的长度再次使用插入排序 userRequested为false采用TimSort的方式排序 TimSort 1.数组长度小于32时，首先在数组中从开头开始寻找升序的子数组，没有的话找降序的子数组再反转，然后将数组中的剩余元素使用二分查找的方式插入到子数组中 2.数组长度大于32时，将数组切分若干个长度在[16,32)的区块（jdk里叫run，我理解为区块） 3.每个区块再使用第一步的方式进行排序排序后将每个区块进行合并，合并的过程有两点优化 a.合并区块的过程中通过限制条件来完成将连续的三个区块中较小的两个优先合并降低复杂度 b.两个区块合并时，先将区块1的头元素和尾元素插入到区块2中，相当于缩小了插入区块2的范围降低复杂度 12345678910111213141516171819202122232425262728293031323334353637383940414243444546static void sort(Object[] a, int lo, int hi, Object[] work, int workBase, int workLen) &#123; assert a != null &amp;&amp; lo &gt;= 0 &amp;&amp; lo &lt;= hi &amp;&amp; hi &lt;= a.length; int nRemaining = hi - lo; if (nRemaining &lt; 2) return; // Arrays of size 0 and 1 are always sorted // If array is small, do a &quot;mini-TimSort&quot; with no merges if (nRemaining &lt; MIN_MERGE) &#123; int initRunLen = countRunAndMakeAscending(a, lo, hi); binarySort(a, lo, hi, lo + initRunLen); return; &#125; /** * March over the array once, left to right, finding natural runs, * extending short natural runs to minRun elements, and merging runs * to maintain stack invariant. */ ComparableTimSort ts = new ComparableTimSort(a, work, workBase, workLen); int minRun = minRunLength(nRemaining); do &#123; // Identify next run int runLen = countRunAndMakeAscending(a, lo, hi); // If run is short, extend to min(minRun, nRemaining) if (runLen &lt; minRun) &#123; int force = nRemaining &lt;= minRun ? nRemaining : minRun; binarySort(a, lo, lo + force, lo + runLen); runLen = force; &#125; // Push run onto pending-run stack, and maybe merge ts.pushRun(lo, runLen); ts.mergeCollapse(); // Advance to find next run lo += runLen; nRemaining -= runLen; &#125; while (nRemaining != 0); // Merge all remaining runs to complete sort assert lo == hi; ts.mergeForceCollapse(); assert ts.stackSize == 1;&#125;]]></content>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ArrayList]]></title>
    <url>%2F2019%2F07%2F26%2FArrayList%2F</url>
    <content type="text"><![CDATA[ArrayListtoArray(T[] a)123456789public &lt;T&gt; T[] toArray(T[] a) &#123; if (a.length &lt; size) // Make a new array of a&apos;s runtime type, but my contents: return (T[]) Arrays.copyOf(elementData, size, a.getClass()); System.arraycopy(elementData, 0, a, 0, size); if (a.length &gt; size) a[size] = null; return a;&#125; 使用了Arrays.copyOf方法]]></content>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MyBatis入门（续）-CRUD]]></title>
    <url>%2F2019%2F07%2F12%2FMyBatis%E5%85%A5%E9%97%A8%E7%BB%AD-CRUD%E6%B5%8B%E8%AF%95%2F</url>
    <content type="text"><![CDATA[根据用户名查询 123&lt;select id=&quot;findUserByName&quot; parameterType=&quot;java.lang.String&quot; resultType=&quot;com.example.mybatisdemo.bean.User&quot;&gt; SELECT * FROM users WHERE name = #&#123;VALUE&#125; &lt;/select&gt; 1sqlSession.selectOne(&quot;test.findUserByName&quot;, &quot;yywang&quot;) 模糊查询，返回多个值 123&lt;select id=&quot;findUserLikeName&quot; parameterType=&quot;java.lang.String&quot; resultType=&quot;com.example.mybatisdemo.bean.User&quot;&gt; SELECT * FROM users WHERE name like #&#123;VALUE&#125; &lt;/select&gt; 1sqlSession.selectList(&quot;test.findUserLikeName&quot;, &quot;%yy%&quot;); 查询的resutlType分三种情况 基本类型：resultType=”基本类型” List类型：resultType=”List集合中的元素类型” Map类型： 单条记录 resultType=”java.util.Map” 多条记录 resultType=”Map中value的类型” 添加数据 123456&lt;insert id=&quot;insertUser&quot; parameterType=&quot;com.example.mybatisdemo.bean.User&quot;&gt; &lt;selectKey keyProperty=&quot;id&quot; order=&quot;AFTER&quot; resultType=&quot;int&quot;&gt; SELECT LAST_INSERT_ID() &lt;/selectKey&gt; INSERT into users(uname,sex,age,udesc) values (#&#123;uname&#125;,#&#123;sex&#125;,#&#123;age&#125;,#&#123;udesc&#125;) &lt;/insert&gt; 12User user = new User(&quot;bangni&quot;,&quot;female&quot;,22,&quot;tc&quot;);sqlSession.commit(); // 必加 tips selectKey 用来配置返回主键 keyProperty 表中主键的名称 order 表示SELECT LAST_INSERT_ID()在insert语句发生的顺序，after意为insert执行之后返回，用于自增主键，UUID的方式可以配置为before resultType 返回值类型 注1：sql语句中有多个参数，占位符#{}也需要指定不同的表示方式，如上#{uname},#{sex}等 注2：sql没问题运行报错，因为之前的数据表设计问题，name和desc是关键字，这里开始做了修改 注3：修改之后运行通过，数据库查不到记录，想到之前测试Junit回自动回滚，于是添加@Rollback注解导入依赖后还是无果，最终加上session.commit()解决，由于MyBatis接管了JDBC的事务管理器，JDBC回自动提交而MyBatis不会，这里需要自行手动提交，修改删除同样 删除 123&lt;delete id=&quot;delUserById&quot; parameterType=&quot;int&quot;&gt; delete from users where id = #&#123;id&#125; &lt;/delete&gt; 12sqlSession.delete(&quot;test.delUserById&quot;,3); sqlSession.commit(); 更新 123&lt;update id=&quot;updateUserById&quot; parameterType=&quot;int&quot;&gt; update users set age = 0 where id = #&#123;id&#125; &lt;/update&gt; 12sqlSession.update(&quot;test.updateUserById&quot;,8); sqlSession.commit(); 查看最后执行的SQL只需在配置文件中添加配置即可打印查询语句12345&lt;configuration&gt; &lt;settings&gt; &lt;setting name=&quot;logImpl&quot; value=&quot;STDOUT_LOGGING&quot; /&gt; &lt;/settings&gt;&lt;/configuration&gt;]]></content>
      <categories>
        <category>MyBatis</category>
      </categories>
      <tags>
        <tag>MyBatis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[IDEA配置Junit测试]]></title>
    <url>%2F2019%2F07%2F12%2FIDEA%E9%85%8D%E7%BD%AEJunit%E6%B5%8B%E8%AF%95%2F</url>
    <content type="text"><![CDATA[看了很多博客后感觉还是比较乱，这篇还不错马一下https://blog.csdn.net/hanchao5272/article/details/79197989 1.安装插件File-&gt;setting-&gt;Plugins-&gt;搜索并安装Junit Generator 2.0-&gt;重启IDEA 2.配置插件File-&gt;setting-&gt; OtherSettings-&gt;Junit Generator-&gt;properties 修改Output Path[输出路径]为${SOURCEPATH}/../../test/java/${PACKAGE}/${FILENAME} 修改 Default Template[默认模板]为JUnit4 选中JUnit4页签，将package test.$entry.packageName; 修改成package $entry.packageName; 3.配置测试的目录File-&gt;Project Structure-&gt;Modules中将测试目录设置为Test Source Floder 4.生成测试类 在要测试的类中用快捷键 alt+insert -&gt; Junit Test -&gt; Junit4 5.测试 鼠标右键菜单 将鼠标光标放在方法相关代码中，右键弹出菜单中会显示运行此测试方法的菜单，点击就会运行方法单独测试。将鼠标光标放在方法之外的代码中，右键弹出菜单中会显示运行此类的所有测试方法的菜单，点击就会运行所有测试方法。 快捷键 将鼠标光标放在方法相关代码中，通过快捷键Ctrl+Shift+F10，运行当前测试方法。 将鼠标光标放在方法之外的代码中，通过快捷键Ctrl+Shift+F10，运行当前类的所有测试方法。 快捷按钮 点击方法左侧的Run Test按钮，运行当前测试方法。 点击类左侧的Run Test按钮，运行当前类的所有测试方法。 6.测试结果 1.方法测试成功 2.方法测试失败 3.测试用时（毫秒） 4.期望值 5.实际值 6.异常信息 7.异常 原因：4.11以上版本不在包含hamcrest 解决：改用4.10 ^_^]]></content>
      <categories>
        <category>IDEA</category>
      </categories>
      <tags>
        <tag>IDEA</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MyBatis入门]]></title>
    <url>%2F2019%2F07%2F12%2FMyBatis%E5%85%A5%E9%97%A8%2F</url>
    <content type="text"><![CDATA[MyBatis环境首先准备数据库表 对应的实体类为 class User &#123;123456 private int id; private String name; private String sex; private int age; private String desc;&#125; 数据库配置文件 SqlMapConfig.xml 配置数据库环境相关 1234567891011&lt;environments default=&quot;development&quot;&gt; &lt;environment id=&quot;development&quot;&gt; &lt;transactionManager type=&quot;JDBC&quot;/&gt; &lt;dataSource type=&quot;POOLED&quot;&gt; &lt;property name=&quot;driver&quot; value=&quot;com.mysql.jdbc.Driver&quot;/&gt; &lt;property name=&quot;url&quot; value=&quot;jdbc:mysql://localhost:3306/test?characterEncoding=utf-8&quot;/&gt; &lt;property name=&quot;username&quot; value=&quot;root&quot;/&gt; &lt;property name=&quot;password&quot; value=&quot;root&quot;/&gt; &lt;/dataSource&gt; &lt;/environment&gt; &lt;/environments&gt; sql映射文件 user.xml 123456789&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot; ?&gt;&lt;!DOCTYPE mapper PUBLIC &quot;-//mybatis.org//DTD Mapper 3.0//EN&quot; &quot;http://mybatis.org/dtd/mybatis-3-mapper.dtd&quot;&gt;&lt;mapper namespace=&quot;test&quot;&gt; &lt;select id=&quot;findUserById&quot; parameterType=&quot;int&quot; resultType=&quot;com.example.mybatisdemo.bean.User&quot;&gt; SELECT * FROM user WHERE id =#&#123;VALUE&#125; &lt;/select&gt;&lt;/mapper&gt; 将sql映射添加到SqlMapConfig.xml中 最终的配置文件为 1234567891011121314151617181920&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot; ?&gt;&lt;!DOCTYPE configuration PUBLIC &quot;-//mybatis.org//DTD Config 3.0//EN&quot; &quot;http://mybatis.org/dtd/mybatis-3-config.dtd&quot;&gt;&lt;configuration&gt; &lt;environments default=&quot;development&quot;&gt; &lt;environment id=&quot;development&quot;&gt; &lt;transactionManager type=&quot;JDBC&quot;/&gt; &lt;dataSource type=&quot;POOLED&quot;&gt; &lt;property name=&quot;driver&quot; value=&quot;com.mysql.jdbc.Driver&quot;/&gt; &lt;property name=&quot;url&quot; value=&quot;jdbc:mysql://localhost:3306/test?characterEncoding=utf-8&quot;/&gt; &lt;property name=&quot;username&quot; value=&quot;root&quot;/&gt; &lt;property name=&quot;password&quot; value=&quot;root&quot;/&gt; &lt;/dataSource&gt; &lt;/environment&gt; &lt;/environments&gt; &lt;mappers&gt; &lt;mapper resource=&quot;mapper/user.xml&quot;/&gt; &lt;/mappers&gt;&lt;/configuration&gt; 测试 123456789String resource = &quot;SqlMapConfig.xml&quot;; InputStream inputStream = Resources.getResourceAsStream(resource); SqlSessionFactory factory = new SqlSessionFactoryBuilder().build(inputStream); SqlSession sqlSession = factory.openSession(); // 参数1 sql映射中的 namespace + &quot;.&quot; + sqlId // 参数2为sql的参数 User user = sqlSession.selectOne(&quot;test.findUserById&quot;, 1); System.out.println(user.toString()); sqlSession.close(); 理解基于sql语句的轻量级ORM框架，将sql语句写入配置文件映射中，进一步解耦，但是多了一步操作感觉比hibernate繁琐一些，但是比hibernate要快，有舍有得吧（为什么快还不知道，后续再看吧╮(╯▽╰)╭ ）]]></content>
      <tags>
        <tag>MyBatis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringMVC入门]]></title>
    <url>%2F2019%2F07%2F11%2FSpringMVC%2F</url>
    <content type="text"><![CDATA[SpringMVC配置注解&amp;配置文件 注解web.xml ①指定Spring配置文件的位置 ②配置Listener，初始化SpringIOC容器 ③配置前端控制器servlet，其中可以自定义配置文件位置，不配置默认寻找xxxx-servlet.xml的配置文件 url-pattern中/和/*区别 /* 匹配所有url 有后缀或者无后缀都会匹配 .jsp .css .js / 只匹配无后缀的url 注：截图为项目中的配置 自己测试时改为 / 项目中拦截所有页面应该会有拦截器或者过滤器做处理，demo中如果配置成截图这样会报错 springmvc-servlet.xml 指定基础包名scan，将指定的包名注入SpringIOC容器（先要添加context的xsd约束） 1xmlns:context=&quot;http://www.springframework.org/schema/context&quot; xsi中添加“http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd&quot; exclude-filter 指定类与Spring容器分开加载（先这么理解） 配置视图解析器（前缀和后缀） 方法中使用@RequestMapping(value=”search”) 理解为匹配URL中search的字样 方法return “iface/manage”; 从匹配的前后缀中寻找应该返回的视图，例如通过上图的配置找到/iface/manage.vm 在Controller类上添加@Controller，方法上添加@RequestMapping(“xxxx”)，即可完成映射 配置完成访问报错 没有jstl标签库，导入依赖即可 1234&lt;dependency&gt; &lt;groupId&gt;javax.servlet&lt;/groupId&gt; &lt;artifactId&gt;jstl&lt;/artifactId&gt; &lt;/dependency&gt; 配置文件web.xml 和注解方式一样springmvc-servlet.xml ①配置处理器映射器 ②配置处理器适配器 ③配置视图解析器（同注解方式） ④配置映射（相当于注解中的@RequestMapping） 相较于注解方式该配置文件中多了对 处理器映射器、处理器适配器 以及映射的配置 实现方面在controller类中不添加任何注解，实现Controller接口，重写方法即可 demo：https://github.com/panniyuyu/frameworkdemo.git 理解通过使用不同方式对springMVC进行配置，感觉对SpringMVC框架大致的原理有一些认识 SpringMVC使将MVC的模式进一步拆分解耦，整个过程主要包含4个主要的部分依次是 前端控制器（DispatcherServlet）、处理器映射器（HandlerMapping）、处理器适配器（HandlerAdapter）、视图解析器（ViewResolver） 1.用户发起请求，被前端控制器（DispatcherServlet）拦截，并根据请求内容询问处理器映射器（HandlerMapping）改请求应该由哪个Controller处理，处理器映射器将匹配到的Controller信息返回给前端控制器 2.前端控制器知道该请求应该由哪个Controller处理，但不会自己处理，将Controller信息交给处理器适配器（HandlerAdapter）处理，返回ModelAndView对象 3.前端控制器得到ModelAndView对象将其转发给视图解析器，将对象解析成view页面返回 4.前端控制器将view页面相应给浏览器]]></content>
      <tags>
        <tag>SpringMVC</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[org.apache.tomcat.util.bcel.classfile.ClassFormatException]]></title>
    <url>%2F2019%2F07%2F11%2F%E5%BC%82%E5%B8%B8%2F</url>
    <content type="text"><![CDATA[org.apache.tomcat.util.bcel.classfile.ClassFormatException 原因：jdk版本不兼容 原环境 jkd8+tomcat7+spring4 解决：tomcat7换tomcat8]]></content>
      <tags>
        <tag>exception</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[IDEA使用笔记]]></title>
    <url>%2F2019%2F07%2F11%2FIDEA%E4%BD%BF%E7%94%A8%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[配置TomcatRun-&gt;Edit Configurations-&gt;Telplates中配置后在该页面左上角添加-&gt;选中Tomcat的Deployment点击部署(选用Artifacts方式) 配置文件取消Unicode编码File-&gt;Setting-&gt;搜索file encoding-&gt;勾选Transparent native-to-ascii conversion 文件目录变红色 解除版本控制即可 file-&gt;setting-&gt;version control-&gt;右上角加号-&gt;添加项目目录即可 新建的maven项目没有web项目的目录结构，也没有web.xml 增加main目录下增加/webapp/WEB-INF目录 File-&gt;Project Structure-&gt;facets-&gt;加号-&gt;选中目录 确认路径depolyment路径为…./webapp/WEB-INF/web.xml 确认路径resource路径为 …./webapp/ 直接创建maven web项目最为简单 createProject-&gt;maven-&gt;勾选Creater from archetype-&gt;选择 maven-archetype-webapp 右键没有new package修改目录性质，在该目录右键-&gt;Mark Directory as-&gt;Source Root 发布方式（参考https://www.cnblogs.com/dpl9963/p/10075456.html） jar：Java ARchrive，仅仅是编译好的Java类的聚合 war：Web application ARchrive，除Java类之外还包含jsp，config等静态资源的聚合 exploded：理解为展开不压缩，jar和war是压缩的目录节后，exploded表示不压缩的文件目录，开发是用该方式较好，文件更改后不用重新启动服务器看到效果 Debug模式 快捷键改为eclipse后，F5，F6不变，eclipse的F8变为F9（程序放行） 修改文件后没有效果必须重启tomcat 热部署 runConfigurations中配置 部署项目到tomcat上，这里的url一定要改成 / 启动tomcat日志输出乱码 淇℃伅（https://www.cnblogs.com/Yin-BoKeYuan/p/10320622.html）打开到tomcat安装目录下的conf/文件夹 修改logging.properties文件，找到 java.util.logging.ConsoleHandler.encoding = utf-8更改为 java.util.logging.ConsoleHandler.encoding = GBK Java应用热启动配置方法1.修改之后手动选择 Run-&gt;Reload Changed Classes 不能设置快捷键 方法2.我选择使用Jrebel插件，安装重启后要填激活码 (这里有人搞好了，拿来用^&amp;^ ) 使用的时候原来是点run或者debug run，现在点旁边两个带jrebel的run和debug run即可 修改代码后 ctrl+F9 快速编译就能查看效果，相当于给方法1加了快捷键 import的类不识别，显示红色这个类是存在的，其他类中引用同样的类就正常，编译无数次还是没解决，缓存问题 解决方法： file -&gt; Invalidate Caches / Restart… -&gt; Invalidate and Restart]]></content>
      <categories>
        <category>IDEA</category>
      </categories>
      <tags>
        <tag>IDEA</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[知识点复习]]></title>
    <url>%2F2019%2F07%2F09%2F%E7%9F%A5%E8%AF%86%E7%82%B9%E5%A4%8D%E4%B9%A0%2F</url>
    <content type="text"><![CDATA[整理一些在看项目时候遇到的小的知识点，先写个大概，后续再做详细的补充 HTTP和TCPHttp是在Tcp的基础之上的，也就是说Http的请求和相应是在建立Tcp链接之后发生的 幂等性一次或者多次请求同一个资源得到的结果是一样的，多次请求不会影响最终的结果。（增加去重的逻辑则无需满足幂等性） synchronized 关键字 在方法中锁住的是该类的实例对象 在静态方法中锁住的是类对象 代码块中（this）锁住的是该类的实例对象 代码块中（xxx.class）锁住的是类对象 volatile保证线程数据可见 transient 关键字不做序列化和反序列化操作 synchronized在方法中声名为什么还用线程安全的数据结构来存放变量该变量可能在其他地方被调用，如果该变量只在synchronized关键字声名在方法中使用，则无需使用线程安全的数据结构。 TPS （Transaction Per Second）服务器每秒处理的事务个数，一个事务是从向服务器发送请求开始，客户端接收到响应结束 QPS （Query Per Second）服务器每秒处理查询的次数，查询开始到返回结果结束 Git克隆分支命令git clone -b [分支名称] [git地址] Git提交代码到GitHub 创建仓库，在本地clone 本地在.git所在的目录打开git bansh 指定远程仓库 git remote add origin https://github.com/panniyuyu/frameworkdemo.git 会提示 remote origin already exists 执行删除命令后再重新指定远程仓库 git remote rm origin 添加文件git add * 提交改动git commit -m “xxxx” 推到远程仓库git push origin master wait()方法 会暂停当前线程，让出CPU时间，同时让出锁，等待notify()或者notifyAll()唤醒后重新获得锁执行 sleep()方法同样会暂停当前线程，让出CPU时间，与 wait()方法不同的是，sleep()方法不会释放锁，会阻塞当前的线程，且sleep()是Thread类中的方法, wait()是Object的方法 守护线程 Java中优先级低的线程，用来服务于用户线程的，当Java程序退出或者jvm退出时，守护线程自动退出，jvm运行时只需关注用户线程即可。 Jvm中的垃圾收集器可以理解为守护线程，当jvm退出时会自动退出 使用 thread.setDaemon(true)设置，要在start()方法之前 Class的isAssignableFrom方法 Class中的方法，如：a.isAssignableFrom(b) 在a是b的父类或接口，亦或是a、b是同一个类或者接口的情况下返回true，其他情况返回false Class的getFields和getDeclaredFields 都是获取类中的字段，getFields获取类中public的字段，getDeclaredFields获取类中所有声名的字段，不包含父类中的字段 Field的getModifiers 获取字段的修饰符，返回值为int型对应不同的类型 PUBLIC: 1 PRIVATE: 2 PROTECTED: 4 STATIC: 8 FINAL: 16 SYNCHRONIZED: 32 VOLATILE: 64 TRANSIENT: 128 NATIVE: 256 INTERFACE: 512 ABSTRACT: 1024 STRICT: 2048 Field的setAccessible(true) 字段被声名是私有的，在取值前必须设置accessible为true，不然会报错 field的getGenericType和getType 都是获取字段的类型，getGenericType返回的是Type类型，getType返回的是Class类型 还有其他不同，暂时没有理解http://www.51gjie.com/java/793.html]]></content>
  </entry>
  <entry>
    <title><![CDATA[第一篇博客]]></title>
    <url>%2F2019%2F05%2F11%2F%E7%AC%AC%E4%B8%80%E7%AF%87%E5%8D%9A%E5%AE%A2%2F</url>
    <content type="text"><![CDATA[时光匆匆，三年的研究生生涯马上就要结束。这是我毕业论文致谢里的第一句话，虽然很老套但是非常应景，在毕业之前的这段时间没有那么多的事情，突然想到做一个自己的博客，把自己的学习和生活记录下来，不用每次遇到问题的时候再去问度娘，而且很多都是重复的问题，虽然自己也在做笔记但很少回头看，打算以前的笔记不再管了，当初为了图省事写的非常简单有些已经想不起来是做什么的了，现在想想非常懊悔，这个坏毛病一定要改。今日在我的博客搭建完成之际，开始将今后所学习的技术记录在此，沉淀下去，和大家做交流，同时，在此也将记录我的生活，有趣的所见所闻什么的，朋友圈发的频繁遭人厌。马上就要入职了，心里知道要回归到工程中了，不然入职后的压力会很大，但是也不知道自己工作内容是什么，浏览了一些博客发现需要学习的东西实在是太多了无从下手，而且就我自己而言没有在工程中应用过的技术即使理解了最后也会忘掉，所以学习的情绪很down，想找一些有趣的东西搞一下，于是本站诞生了。emmm……第一篇博客就到这了，自己小学语文水平只能写到这了，给自己加油！]]></content>
      <categories>
        <category>生活杂谈</category>
      </categories>
      <tags>
        <tag>生活杂谈</tag>
      </tags>
  </entry>
</search>
